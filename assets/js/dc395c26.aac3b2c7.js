"use strict";(self.webpackChunkeki_lab=self.webpackChunkeki_lab||[]).push([[8122],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>d});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},c=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},u="mdxType",h={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),u=p(a),m=r,d=u["".concat(s,".").concat(m)]||u[m]||h[m]||i;return a?n.createElement(d,o(o({ref:t},c),{},{components:a})):n.createElement(d,o({ref:t},c))}));function d(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,o=new Array(i);o[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[u]="string"==typeof e?e:r,o[1]=l;for(var p=2;p<i;p++)o[p]=a[p];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},9751:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>l,toc:()=>p});var n=a(87462),r=(a(67294),a(3905));const i={title:"Deploying your Data Science app to the Cloud",author:"Axel Richier",author_title:"Tech Lead Data Engineering & Architecture",author_url:"mailto:inno@ekimetrics.com",header_image_url:"./img/blog/annie-spratt-unsplash.jpg",tags:["DevOps","DataOps","Containers","CI/CD","Azure","Docker"],draft:!1,description:"Let's explore how we, at Ekimetrics, automate the deployment of our data apps on the cloud. This article will gather elements from our internal & external workshops presented at Datacraft and also the video presenting some docker best practices for industrialization. ",keywords:["Data Science","EkiLab","Ekimetrics","Eki.Lab","Eki","Machine Learning","Artificial Intelligence","Data Engineering","App and Web Development","Data Science for business"]},o=void 0,l={permalink:"/blog/2022/04/21/docker",source:"@site/blog/2022-04-21-docker.md",title:"Deploying your Data Science app to the Cloud",description:"Let's explore how we, at Ekimetrics, automate the deployment of our data apps on the cloud. This article will gather elements from our internal & external workshops presented at Datacraft and also the video presenting some docker best practices for industrialization. ",date:"2022-04-21T00:00:00.000Z",formattedDate:"April 21, 2022",tags:[{label:"DevOps",permalink:"/blog/tags/dev-ops"},{label:"DataOps",permalink:"/blog/tags/data-ops"},{label:"Containers",permalink:"/blog/tags/containers"},{label:"CI/CD",permalink:"/blog/tags/ci-cd"},{label:"Azure",permalink:"/blog/tags/azure"},{label:"Docker",permalink:"/blog/tags/docker"}],readingTime:10.92,hasTruncateMarker:!0,authors:[{name:"Axel Richier",title:"Tech Lead Data Engineering & Architecture",url:"mailto:inno@ekimetrics.com"}],frontMatter:{title:"Deploying your Data Science app to the Cloud",author:"Axel Richier",author_title:"Tech Lead Data Engineering & Architecture",author_url:"mailto:inno@ekimetrics.com",header_image_url:"./img/blog/annie-spratt-unsplash.jpg",tags:["DevOps","DataOps","Containers","CI/CD","Azure","Docker"],draft:!1,description:"Let's explore how we, at Ekimetrics, automate the deployment of our data apps on the cloud. This article will gather elements from our internal & external workshops presented at Datacraft and also the video presenting some docker best practices for industrialization. ",keywords:["Data Science","EkiLab","Ekimetrics","Eki.Lab","Eki","Machine Learning","Artificial Intelligence","Data Engineering","App and Web Development","Data Science for business"]},prevItem:{title:"Newsletter for April 2022",permalink:"/blog/2022/05/02/newsletter_April-2022"},nextItem:{title:"Newsletter for March 2022",permalink:"/blog/2022/03/30/newsletter_March-2022"}},s={authorsImageUrls:[void 0]},p=[{value:"TL;DR",id:"tldr",level:4},{value:"Data Science storytelling with Streamlit",id:"data-science-storytelling-with-streamlit",level:2},{value:"Running the app",id:"running-the-app",level:3},{value:"Docker, the cloudy whale",id:"docker-the-cloudy-whale",level:2},{value:"Creating your container",id:"creating-your-container",level:3},{value:"Write Dockerfile",id:"write-dockerfile",level:4},{value:"Choosing the base image",id:"choosing-the-base-image",level:4},{value:"Efficient Build Instructions",id:"efficient-build-instructions",level:3},{value:"Run your Streamlit container",id:"run-your-streamlit-container",level:4},{value:"Live Reload",id:"live-reload",level:4},{value:"Ship it to the Cloud !",id:"ship-it-to-the-cloud-",level:2},{value:"Log into Azure",id:"log-into-azure",level:3},{value:"Container registry",id:"container-registry",level:3},{value:"Linux App Service Plan",id:"linux-app-service-plan",level:3},{value:"The Web App",id:"the-web-app",level:3},{value:"Let&#39;s Automate!",id:"lets-automate",level:2},{value:"Bitbucket Pipelines",id:"bitbucket-pipelines",level:3},{value:"What&#39;s next ?",id:"whats-next-",level:2},{value:"Alternatives",id:"alternatives",level:3},{value:"Web App framework",id:"web-app-framework",level:5},{value:"Containers",id:"containers",level:5},{value:"Web App Hosting",id:"web-app-hosting",level:4},{value:"Credits",id:"credits",level:2}],c={toc:p},u="wrapper";function h(e){let{components:t,...i}=e;return(0,r.kt)(u,(0,n.Z)({},c,i,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("div",{align:"center"},(0,r.kt)("p",null,"  ",(0,r.kt)("img",{alt:"screenshot-app ",src:a(71122).Z,width:"1920",height:"1083"}))),(0,r.kt)("div",{align:"justify"},(0,r.kt)("h4",{id:"tldr"},"TL;DR"),(0,r.kt)("p",null,"Using optimized containers images in your favourite CI/CD pipeline will help you deploy your Data Science app quickly & easily. Check out the replay of our ",(0,r.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=C7v5lY2G4Os"},"workshop")," at Datacraft and our Mastercraft video about",(0,r.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=lkL3Ve7sDfc&t=97s&ab_channel=datacraft"}," container best practices"),".  "),(0,r.kt)("h2",{id:"data-science-storytelling-with-streamlit"},"Data Science storytelling with Streamlit"),(0,r.kt)("p",null,"Over the past year, ",(0,r.kt)("a",{parentName:"p",href:"https://streamlit.io/"},"Streamlit")," has become one of our favourite tools to share data insights through a web app. It's a low-code, data science oriented Python framework that makes your scripts shine in a web app. You can use it to quickly build beautiful visualizations but as data is even better when shared, we would like to help you make it easily accessible to your teammates and colleagues. We will deploy one of the apps in the Streamlit Gallery : ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/streamlit/demo-uber-nyc-pickups/"},"NYC Uber Ridesharing Data"),"."),(0,r.kt)("h3",{id:"running-the-app"},"Running the app"),(0,r.kt)("p",null,"Let's keep it simple and follow these steps to get the code and use venv to create a virtual environment with the following steps:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-zsh"},"> git clone git@github.com:streamlit/demo-uber-nyc-pickups.git\n> cd demo-uber-nyc-pickups\n> py -3.8 -m venv .venv\n> .venv/scripts/activate\n> pip install -r requirements.txt\n")),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"We are showcasing ",(0,r.kt)("a",{parentName:"p",href:"https://docs.python.org/3/library/venv.html"},"venv")," here as it is included in Python itself. We invite you to explore other tools such as ",(0,r.kt)("a",{parentName:"p",href:"https://python-poetry.org/"},"Poetry"),", ",(0,r.kt)("a",{parentName:"p",href:"https://pipenv.pypa.io/en/latest/"},"pipenv")," or ",(0,r.kt)("a",{parentName:"p",href:"https://docs.conda.io/en/latest/"},"conda")," depending on your needs and preferences and to always make use of them, especially when collaborating on multiple projects as it will save you from conflicts in your installations.")),(0,r.kt)("p",null,"Now, you should be able to run it locally:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"streamlit run index.py \n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"screenshot-app",src:a(88051).Z,width:"1859",height:"807"})),(0,r.kt)("h2",{id:"docker-the-cloudy-whale"},"Docker, the cloudy whale"),(0,r.kt)("p",null,"Docker is one of the most popular containerization tools and is widely used in the context of cloud-based solutions. In this article, we will review how to set up your environment so that you can leverage this tool and level up your development workflow! "),(0,r.kt)("p",null,"The advantage we will explore in this article is the ability to package your environment with all its dependencies and be 99.99% sure that it will be able to run on your target environment. "),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},'"If it runs on Docker, it will run everywhere." - one hopeful DataOps')),(0,r.kt)("p",null,"You can safely share your app and be sure that it will run in the same conditions as you worked on and ensure reproducibility of your results. "),(0,r.kt)("h3",{id:"creating-your-container"},"Creating your container"),(0,r.kt)("h4",{id:"write-dockerfile"},"Write Dockerfile"),(0,r.kt)("p",null,"The Dockerfile is the recipe of your container. It contains all the instructions to produce & reproduce it identically everywhere it will be run: on another laptop, maybe with a different OS, in the cloud."),(0,r.kt)("p",null,"Some quick definitions:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"The Docker image is the result of the build of the Dockerfile."),(0,r.kt)("li",{parentName:"ul"},"The Docker container is the result of running the image."),(0,r.kt)("li",{parentName:"ul"},"You can pull and push images to a container registry.")),(0,r.kt)("div",{align:"center"},(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Docker definitions schema",src:a(64766).Z,width:"724",height:"317"}))),(0,r.kt)("h4",{id:"choosing-the-base-image"},"Choosing the base image"),(0,r.kt)("p",null,"It always starts with a ",(0,r.kt)("strong",{parentName:"p"},"FROM")," instruction that defines what is the base image which can be either:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"a linux-based OS: ",(0,r.kt)("a",{parentName:"li",href:"https://hub.docker.com/layers/ubuntu/library/ubuntu/latest/images/sha256-31cd7bbfd36421dfd338bceb36d803b3663c1bfa87dfe6af7ba764b5bf34de05?context=explore"},"ubuntu"),", ",(0,r.kt)("a",{parentName:"li",href:"https://hub.docker.com/layers/debian/library/debian/stable/images/sha256-7ec7bef742f919f7cc88f41b598ceeb6b74bcb446e9ce1d2d7c31eb26ccba624?context=explore"},"debian"),", ",(0,r.kt)("a",{parentName:"li",href:"https://hub.docker.com/layers/centos/library/centos/latest/images/sha256-a1801b843b1bfaf77c501e7a6d3f709401a1e0c83863037fa3aab063a7fdb9dc?context=explore"},"centos"),"..."),(0,r.kt)("li",{parentName:"ul"},"an OS with preinstalled tools: ",(0,r.kt)("a",{parentName:"li",href:"https://hub.docker.com/layers/python/library/python/3.8/images/sha256-71d10e809efb1733e2743fb7be3417db18070e10a2276e727216f245f7418592?context=explore"},"python-3.8"),", ",(0,r.kt)("a",{parentName:"li",href:"https://hub.docker.com/layers/mongo/library/mongo/5.0.7/images/sha256-5b5263a7d25d06d5149904eaaacdb359edcd4f26a3d971265f85362dd2406655?context=explore"},"mongo-5.0.7"),", ",(0,r.kt)("a",{parentName:"li",href:"https://hub.docker.com/layers/node/library/node/17.9.0/images/sha256-c1336669570df673e44d5a2152eb4eff99f4c23bb3d19361c69f861b1bd5ffd3?context=explore"},"node-17.9.0")),(0,r.kt)("li",{parentName:"ul"},"a ready-to-use image of a project like the ",(0,r.kt)("a",{parentName:"li",href:"https://hub.docker.com/r/docker/getting-started"},"Docker Tutorial"),".")),(0,r.kt)("p",null,"Choosing your base image is important as it can help you reduce the amount of steps to get ready. If you chose Ubuntu as your base image for a Python project, you will need to write the instructions to install the Python version you want to install and your image will also come with many other packages that are preinstalled in the OS that you may not need for your projet. This is why Python images are available. It comes with Python already installed and some images (like slim images) also remove packages that aren't necessary for Python development. This strongly impacts the size of your image as shown here:"),(0,r.kt)("div",{align:"center"},(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Python Docker images size comparison",src:a(77738).Z,width:"698",height:"200"}))),(0,r.kt)("p",null,"These are official Docker images and depending on which version you pull, you can see the size difference is quite noticeable."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"python\xa03.8 is almost 1GB."),(0,r.kt)("li",{parentName:"ul"},"python 3.8-slim reduces it by 86%."),(0,r.kt)("li",{parentName:"ul"},"python 3.8-alpine even goes down to <50MB.")),(0,r.kt)("p",null,"Alpine is not recommended for Python development as standard PyPi wheels don't work on Alpine and you have to compile them for every package, which can lead to additional research to properly achieve it. In some instances, compiling can also be very lengthy, like matplotlib that takes more than 25min to build:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"matplotlib-build-alpine",src:a(1098).Z,width:"1073",height:"395"})),(0,r.kt)("p",null,"Nobody ain't got time for that. "),(0,r.kt)("h3",{id:"efficient-build-instructions"},"Efficient Build Instructions"),(0,r.kt)("p",null,"So let's build our image using a small, ready-to-python image like ",(0,r.kt)("inlineCode",{parentName:"p"},"python:3.8-slim"),". We first need to install all our app requirements. So we add our ",(0,r.kt)("inlineCode",{parentName:"p"},"requirements.txt")," file and install just like we would do locally :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Dockerfile"},"FROM python:3.8-slim\n\n# We place ourself in a dedicated folder\nWORKDIR /app\n# Installing requirements\nADD ./requirements.txt /app/requirements.txt\nRUN pip3 install -r requirements.txt --no-cache-dir\n")),(0,r.kt)("p",null,"Adding the file alone and installing the requirements right after allows you to create a layer that will be cached and you will not have to reuse this step in a future build. It is generally a good practice to use the cache when in development mode as you don't want to spend 10 minutes at every build of your requirements (you know it can take a while). The way Docker cache works is that by default it will reuse the highest unmodified layers."),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"docker-cache-example",src:a(97848).Z,width:"1192",height:"669"})),(0,r.kt)("p",null,"Here are the commands that generate a layer and which you want to be able to cache and/or gather in a single instruction."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"FROM")," creates a layer from the base image."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"COPY")," adds files from your Docker client\u2019s current directory."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"RUN")," builds your application with make."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"CMD")," specifies what command to run within the container.")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://docs.docker.com/develop/develop-images/dockerfile_best-practices/"},"Source")),(0,r.kt)("p",null,"Then, we add the different required files with the ",(0,r.kt)("em",{parentName:"p"},"ADD")," or ",(0,r.kt)("em",{parentName:"p"},"COPY")," instructions. In our example, we need the python main code, the data and one image."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Dockerfile"},"ADD streamlit_app.py  uber-raw-data-sep14.csv.gz  uber_demo.png /app/\n")),(0,r.kt)("p",null,"To access the app, we need to open port 8051 on the container. Otherwise, even if the app is running, it will not be accessible from outside the container by a browser. Instruction is :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Dockerfile"},"EXPOSE 8051\n")),(0,r.kt)("p",null,"The last instruction is the ",(0,r.kt)("em",{parentName:"p"},"RUN"),", which tells Docker which command needs to be run at the start of the container. For us, it means starting the Streamlit app with the command ",(0,r.kt)("inlineCode",{parentName:"p"},"streamlit run /index.py"),", which in Docker syntax is:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Dockerfile"},'CMD ["streamlit", "run" ,"/index.py"]\n')),(0,r.kt)("p",null,"The final Dockerfile should look like this:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Dockerfile",metastring:'title="Dockerfile"',title:'"Dockerfile"'},'FROM python:3.8-slim\n\nWORKDIR /app\n\nEXPOSE 8501\n\nADD requirements.txt /app/requirements.txt\nRUN pip install -r requirements.txt\n\nADD streamlit_app.py  uber-raw-data-sep14.csv.gz  uber_demo.png /app/\n\nCMD ["streamlit","run","streamlit_app.py"]\n')),(0,r.kt)("h4",{id:"run-your-streamlit-container"},"Run your Streamlit container"),(0,r.kt)("p",null,"To build your image, just run the command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"docker build --tag ekilab-demo-container .\n")),(0,r.kt)("p",null,"Once built, you can run the container with the command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"docker run -dp 8501:8501 ekilab-demo-container\n")),(0,r.kt)("p",null,"Your app should now be running and available at ",(0,r.kt)("a",{parentName:"p",href:"http://localhost:8501"},"http://localhost:8501"),"."),(0,r.kt)("h4",{id:"live-reload"},"Live Reload"),(0,r.kt)("p",null,"The issue with the current setup is that if you make a change to your app, you will need to rebuild and re-run the container to see the changes in your browser. We don't want to rebuild the whole environment, and to do that we will use the ",(0,r.kt)("a",{parentName:"p",href:"https://docs.docker.com/storage/volumes/"},"volume")," feature of Docker, and make it easy with ",(0,r.kt)("a",{parentName:"p",href:"https://docs.docker.com/compose/"},"docker-compose"),".\nDocker-compose is a powerful tool to orchestrate multiple containers. But in our case, we will only use it to make our life easier. "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yml",metastring:'title="docker-compose.yml"',title:'"docker-compose.yml"'},'version: "3.9"\nservices:\n  ekilab-demo-container: \n    build: .\n    ports:\n      - "8501:8501"\n    volumes:\n      - ./:/app \n')),(0,r.kt)("p",null,"Now, you only need to remember one single command: ",(0,r.kt)("inlineCode",{parentName:"p"},"docker compose up"),". It will build your image, run it with the correct parameters and link it to the correct volume."),(0,r.kt)("h2",{id:"ship-it-to-the-cloud-"},"Ship it to the Cloud !"),(0,r.kt)("p",null,"If you don't have an Azure account, you can create one for ",(0,r.kt)("a",{parentName:"p",href:"https://azure.microsoft.com/en-us/free/"},"free")," and get 200$ of credits for trying out the platform. "),(0,r.kt)("h3",{id:"log-into-azure"},"Log into Azure"),(0,r.kt)("p",null,"Log into your account using the Azure CLI with the ",(0,r.kt)("inlineCode",{parentName:"p"},"az login")," command.\nThen, we will need a container registry. At Ekimetrics, we usually build our infrastructure using an Infrastructure-As-Code tool such as ",(0,r.kt)("a",{parentName:"p",href:"https://terraform.io"},"Terraform"),". But for the sake of simplicity, let's use simple CLI\xa0commands to create our resources."),(0,r.kt)("h3",{id:"container-registry"},"Container registry"),(0,r.kt)("p",null,"The container registry will store the different versions of our container. It can also be used to store other images. You can consider it as your private DockerHub."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"az acr create --name ekilabhub --resource-group ekimetrics-demo --sku basic --admin-enabled true\n")),(0,r.kt)("h3",{id:"linux-app-service-plan"},"Linux App Service Plan"),(0,r.kt)("p",null,"To run our app, we need a Linux-based resource. This is what the App Service Plan offers.\nB1 is a free instance that you can use for your small apps and Proof Of Concept."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"az appservice plan create --resource-group ekimetrics-demo -n ekimetrics-lasp -l westeurope --is-linux --sku B1\n")),(0,r.kt)("p",null,"Now, we have several options :"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Option 1 - build the image locally and push it to the container registry"),(0,r.kt)("li",{parentName:"ul"},"Option 2 - build the image directly from the registry"),(0,r.kt)("li",{parentName:"ul"},"Option 3 - build and push the image from a CI/CD pipeline")),(0,r.kt)("p",null,"Let's try :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"# log into the container registry\ndocker login ekilabhub.azurecr.io --username ekilabhub --password its4secr\u20act!\n\n# Option 1 - push the new Docker image to the registry\ndocker push ekilabhub.azurecr.io/ekilab/ekilab-demo-container:latest\n\n# Option 2 - directly build on Azure Container Registry\naz acr build --registry ekilabhub --resource-group ekimetrics-demo-rg --image ekilab-demo-container .\n")),(0,r.kt)("h3",{id:"the-web-app"},"The Web App"),(0,r.kt)("p",null,"Finally we can create the web app, based on our previously created App Service Plan, and by retrieving the image from the Container Registry."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"az webapp create --resource-group ekimetrics-demo-rg -p ekimetrics-lasp -n ekilab-demo-app -i ekilabhub.azurecr.io/ekilab/ekilab-demo-container:latest\n")),(0,r.kt)("h2",{id:"lets-automate"},"Let's Automate!"),(0,r.kt)("p",null,"It's all been fun but we don't want to do this every time we update the code. It would be easy to make a mistake and you may want to collaborate with other Data Scientists on your team and have their updates deployed without your help!"),(0,r.kt)("div",{align:"center"},(0,r.kt)("p",null,(0,r.kt)("img",{alt:"automate-all-the-things",src:a(59405).Z,width:"660",height:"400"}))),(0,r.kt)("h3",{id:"bitbucket-pipelines"},"Bitbucket Pipelines"),(0,r.kt)("p",null,"In this example we are using ",(0,r.kt)("a",{parentName:"p",href:"https://bitbucket.org/product/fr/features/pipelines"},"Bitbucket Pipelines")," to automate these deployment steps but the logic is very similar in other tools such as ",(0,r.kt)("a",{parentName:"p",href:"https://dev.azure.com/"},"Azure DevOps"),", ",(0,r.kt)("a",{parentName:"p",href:"https://cloud.google.com/build"},"Cloud Build"),", ",(0,r.kt)("a",{parentName:"p",href:"https://docs.gitlab.com/ee/ci/introduction/"},"Gitlab CI/CD"),", ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/features/actions"},"GitHub Actions"),", ",(0,r.kt)("a",{parentName:"p",href:"https://www.jenkins.io/"},"Jenkins"),"..."),(0,r.kt)("p",null,"The common concept behind these tools is to store all the instructions in a YAML file and execute them at every commit to a given branch. In our example, the master branch gathers the code that will be delivered to production."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yml",metastring:'title="bitbucket-pipelines.yml"',title:'"bitbucket-pipelines.yml"'},"image: python:3.8\n\npipelines:\n  branches:\n    master:\n\n      - step:\n          name: Build and Push the image         \n          services:\n          - docker\n          script: \n          # build the image\n          - docker build -t ekilabhub.azurecr.io/ekilab/ekilab-demo-container:$BITBUCKET_BUILD_NUMBER .\n\n          # authenticate with the Azure Container Registry \n          - docker login ekilabhub.azurecr.io --username ekilabhub --password  $AZURE_CONTAINER_REGISTRY_PASSWORD\n\n          # push the new Docker image to the registry\n          - docker push ekilabhub.azurecr.io/ekilab/ekilab-demo-container:$BITBUCKET_BUILD_NUMBER\n      \n\n      - step:\n          name: Deploying App to Azure\n          script:\n          # Install the Azure CLI\n          - curl -sL https://aka.ms/InstallAzureCLIDeb | bash \n          \n          # login with a Service Principal / store the credentials in a secured area\n          - az login --service-principal --username $AZURE_APP_ID --password $AZURE_PASSWORD --tenant $AZURE_TENANT_ID \n\n          # Set the correct image version to the web app \n          - az webapp config container set  --resource-group $AZURE_RESOURCE_GROUP  --name ekilab-demo-app  --docker-custom-image-name ekilab-demo-container:$BITBUCKET_BUILD_NUMBER  --docker-registry-server-url ekilabhub.azurecr.io --docker-registry-server-user ekilabhub --docker-registry-server-password $AZURE_CONTAINER_REGISTRY_PASSWORD\n\n")),(0,r.kt)("h2",{id:"whats-next-"},"What's next ?"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Congratulations !")," You should now be able to automate the deployment of your app to the cloud and focus only on updating its content without worrying about how to publish your updates. Now, you might need to have a scalable app to ensure it can handle high loads of visits. You could require tools like ",(0,r.kt)("a",{parentName:"p",href:"https://kubernetes.io"},"Kubernetes"),", ",(0,r.kt)("a",{parentName:"p",href:"https://docs.docker.com/engine/swarm/"},"Docker Swarm"),"."),(0,r.kt)("h3",{id:"alternatives"},"Alternatives"),(0,r.kt)("p",null,"We presented one of the workflow we are using at Ekimetrics, but it's not the only one ! We also work with GCP, AWS, Alibaba, sometimes on-premise infrastructure that will prevent us from using Docker or Azure for example."),(0,r.kt)("h5",{id:"web-app-framework"},"Web App framework"),(0,r.kt)("p",null,"Soe alternavites to streamlit that are also offering low-code, minimalist, ",(0,r.kt)("em",{parentName:"p"},"straight-to-the-data")," python framework that you can package in a container."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://plotly.com/dash/"},"Dash Plotly")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://gradio.app/"},"Gradio.app"))),(0,r.kt)("h5",{id:"containers"},"Containers"),(0,r.kt)("p",null,"Docker is not the only containerization tool. Here are some alternatives we invite you to check out if Docker doesn't suit you."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://podman.io/"},"podman")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://containerd.io/"},"containerd")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://coreos.com/rkt/docs/latest/"},"CoreOS rkt")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"http://mesos.apache.org/documentation/latest/mesos-containerizer/"},"Mesos Containerizer")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://linuxcontainers.org/"},"LXC Linux Containers")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://openvz.org/"},"OpenVZ"))),(0,r.kt)("h4",{id:"web-app-hosting"},"Web App Hosting"),(0,r.kt)("p",null,"There are many others ways to deploy your apps, even free tiers on some providers that can help you get your hands-on with smaller, non-sensitive apps."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://streamlit.io/cloud"},"Streamlit Cloud")," offers a free tier to host one private app and ",(0,r.kt)("strong",{parentName:"li"},"unlimited")," public apps! Deployment is ",(0,r.kt)("a",{parentName:"li",href:"https://s3-us-west-2.amazonaws.com/assets.streamlit.io/videos/streamlit_sharing_silent.mp4"},"very simple with GitHub")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://azure.microsoft.com/en-us/services/container-apps/"},"Azure Container App")," a new offer from Microsoft that helps you simply deploy scalable apps."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://cloud.google.com/run"},"GCP Cloud Run"),", similar to Azure Apps, is a serverless service that helps easily deploy pre-built containerized apps."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://www.heroku.com/"},"Heroku")," offers a free tier to deploy small apps, Proof Of Concept and also a very simple deployment process.")),(0,r.kt)("h2",{id:"credits"},"Credits"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Cover Photo by ",(0,r.kt)("a",{href:"https://unsplash.com/@anniespratt?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText"},"Annie Spratt")," on ",(0,r.kt)("a",{href:"https://unsplash.com/s/photos/rainbow-cake?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText"},"Unsplash")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://cloud.google.com/architecture/best-practices-for-building-containers#package_a_single_application_per_container"},"Google's Best Practices for building Containers")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://pythonspeed.com/articles/base-image-python-docker-images/"},"The best Docker base image for your Python application (August 2021)")))))}h.isMDXComponent=!0},59405:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/automate-b4b2aaa382f4c26530ad030ace0cfb08.png"},97848:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/docker-cache-example-18ec05ab2a069080c94be26d3cb1aab1.gif"},64766:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/docker-definitions-schema-742ad3f8ebb9c6e95b4f6b99bcc6601c.gif"},71122:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/annie-spratt-unsplash-45fe35c2ca54f29fb0b4c11941253d90.jpg"},77738:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/python-docker-images-size-comparison-8648b2ea9f9ef5fbaace2501f6fee442.png"},1098:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/python-matplotlib-79daf5b8811d2475b4ebc732d659ec16.png"},88051:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/screenshot-app-144427ee5ac05be241dfd0d8c9140c69.png"}}]);