"use strict";(self.webpackChunkeki_lab=self.webpackChunkeki_lab||[]).push([[2721],{3905:(e,n,t)=>{t.d(n,{Zo:()=>s,kt:()=>m});var a=t(67294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var g=a.createContext({}),c=function(e){var n=a.useContext(g),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},s=function(e){var n=c(e.components);return a.createElement(g.Provider,{value:n},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},p=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,i=e.originalType,g=e.parentName,s=l(e,["components","mdxType","originalType","parentName"]),u=c(t),p=r,m=u["".concat(g,".").concat(p)]||u[p]||d[p]||i;return t?a.createElement(m,o(o({ref:n},s),{},{components:t})):a.createElement(m,o({ref:n},s))}));function m(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var i=t.length,o=new Array(i);o[0]=p;var l={};for(var g in n)hasOwnProperty.call(n,g)&&(l[g]=n[g]);l.originalType=e,l[u]="string"==typeof e?e:r,o[1]=l;for(var c=2;c<i;c++)o[c]=t[c];return a.createElement.apply(null,o)}return a.createElement.apply(null,t)}p.displayName="MDXCreateElement"},21019:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>g,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var a=t(87462),r=(t(67294),t(3905));const i={slug:"Blind_Language_Model",title:"How to give sight to a blind language model",authors:["francois.guerillon"],header_image_url:"img/blog/Blind_Language_header.jpg",image:"img/blog/Blind_Language_header.jpg",tags:["GenAI","Generative AI","Deep Learning","Machine learning","Data Science","AI Models","LLM","Multimodal","Object Detection","Computer Vision"],draft:!1,description:"Get a good technical understanding of how vision-language models are built and trained.",keywords:["GenAI","Generative AI","Deep Learning","Machine learning","Data Science","AI Models","LLM","Multimodal","Object Detection","Computer Vision","VLM","Vision Language Models","Transformers","Attention"]},o=void 0,l={permalink:"/blog/Blind_Language_Model",source:"@site/blog/2025-07-23-Blind_Language_Model.md",title:"How to give sight to a blind language model",description:"Get a good technical understanding of how vision-language models are built and trained.",date:"2025-07-23T00:00:00.000Z",formattedDate:"July 23, 2025",tags:[{label:"GenAI",permalink:"/blog/tags/gen-ai"},{label:"Generative AI",permalink:"/blog/tags/generative-ai"},{label:"Deep Learning",permalink:"/blog/tags/deep-learning"},{label:"Machine learning",permalink:"/blog/tags/machine-learning"},{label:"Data Science",permalink:"/blog/tags/data-science"},{label:"AI Models",permalink:"/blog/tags/ai-models"},{label:"LLM",permalink:"/blog/tags/llm"},{label:"Multimodal",permalink:"/blog/tags/multimodal"},{label:"Object Detection",permalink:"/blog/tags/object-detection"},{label:"Computer Vision",permalink:"/blog/tags/computer-vision"}],readingTime:14.14,hasTruncateMarker:!0,authors:[{name:"Fran\xe7ois GUERILLON",title:"Multimodal Specialist",url:"https://www.linkedin.com/in/fguerillon/",imageURL:"/img/authors/francois_guerillon.jpg",key:"francois.guerillon"}],frontMatter:{slug:"Blind_Language_Model",title:"How to give sight to a blind language model",authors:["francois.guerillon"],header_image_url:"img/blog/Blind_Language_header.jpg",image:"img/blog/Blind_Language_header.jpg",tags:["GenAI","Generative AI","Deep Learning","Machine learning","Data Science","AI Models","LLM","Multimodal","Object Detection","Computer Vision"],draft:!1,description:"Get a good technical understanding of how vision-language models are built and trained.",keywords:["GenAI","Generative AI","Deep Learning","Machine learning","Data Science","AI Models","LLM","Multimodal","Object Detection","Computer Vision","VLM","Vision Language Models","Transformers","Attention"]},prevItem:{title:"CLAIR.bot: One Year of Responsible AI Serving Public Debate",permalink:"/blog/clair_anniversary"},nextItem:{title:"Under the Hood: Technical Blueprint of a GenAI-Powered ESG Due Diligence Tool",permalink:"/blog/Under_The_Hood"}},g={authorsImageUrls:[void 0]},c=[],s={toc:c},u="wrapper";function d(e){let{components:n,...t}=e;return(0,r.kt)(u,(0,a.Z)({},s,t,{components:n,mdxType:"MDXLayout"}))}d.isMDXComponent=!0}}]);