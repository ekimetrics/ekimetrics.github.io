"use strict";(self.webpackChunkeki_lab=self.webpackChunkeki_lab||[]).push([[5498],{3905:(e,n,t)=>{t.d(n,{Zo:()=>m,kt:()=>f});var a=t(67294);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,a,i=function(e,n){if(null==e)return{};var t,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var s=a.createContext({}),c=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},m=function(e){var n=c(e.components);return a.createElement(s.Provider,{value:n},e.children)},p="mdxType",g={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},u=a.forwardRef((function(e,n){var t=e.components,i=e.mdxType,r=e.originalType,s=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),p=c(t),u=i,f=p["".concat(s,".").concat(u)]||p[u]||g[u]||r;return t?a.createElement(f,o(o({ref:n},m),{},{components:t})):a.createElement(f,o({ref:n},m))}));function f(e,n){var t=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var r=t.length,o=new Array(r);o[0]=u;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l[p]="string"==typeof e?e:i,o[1]=l;for(var c=2;c<r;c++)o[c]=t[c];return a.createElement.apply(null,o)}return a.createElement.apply(null,t)}u.displayName="MDXCreateElement"},86192:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>o,default:()=>g,frontMatter:()=>r,metadata:()=>l,toc:()=>c});var a=t(87462),i=(t(67294),t(3905));const r={slug:"Semifactual_Explanations",title:"Rethinking \u201cWhat If?\u201d A Look at Semifactual Explanations in AI",authors:["benjamin.wong","milan.bhan"],header_image_url:"img/blog/Semifactuals_header.jpg",image:"img/blog/Semifactuals_header.jpg",tags:["XAI","explainability","Machine Learning","Semifactuals"],draft:!1,description:"Discover what semifactuals are, \u201ceven if\u201d scenarios that expose AI\u2019s strengths and limits while informing optimized decision-making.",keywords:["XAI","Explainability","Interpretability","Machine learning","Data science","Deep learning","Innovation","Transparency","AI","Model optimisation","Fairness,","Actionability","Code"]},o=void 0,l={permalink:"/blog/Semifactual_Explanations",source:"@site/blog/2025-09-08-Semifactual_Explanations.md",title:"Rethinking \u201cWhat If?\u201d A Look at Semifactual Explanations in AI",description:"Discover what semifactuals are, \u201ceven if\u201d scenarios that expose AI\u2019s strengths and limits while informing optimized decision-making.",date:"2025-09-08T00:00:00.000Z",formattedDate:"September 8, 2025",tags:[{label:"XAI",permalink:"/blog/tags/xai"},{label:"explainability",permalink:"/blog/tags/explainability"},{label:"Machine Learning",permalink:"/blog/tags/machine-learning"},{label:"Semifactuals",permalink:"/blog/tags/semifactuals"}],readingTime:17.19,hasTruncateMarker:!0,authors:[{name:"Benjamin Wong",title:"Senior Consultant",url:"https://www.linkedin.com/in/benjamin-wong-62a5b7189/",key:"benjamin.wong"},{name:"Milan Bhan",title:"Domain Specialist",url:"https://www.linkedin.com/in/milan-bhan-43133a102/",imageURL:"/img/authors/milan.bhan.png",key:"milan.bhan"}],frontMatter:{slug:"Semifactual_Explanations",title:"Rethinking \u201cWhat If?\u201d A Look at Semifactual Explanations in AI",authors:["benjamin.wong","milan.bhan"],header_image_url:"img/blog/Semifactuals_header.jpg",image:"img/blog/Semifactuals_header.jpg",tags:["XAI","explainability","Machine Learning","Semifactuals"],draft:!1,description:"Discover what semifactuals are, \u201ceven if\u201d scenarios that expose AI\u2019s strengths and limits while informing optimized decision-making.",keywords:["XAI","Explainability","Interpretability","Machine learning","Data science","Deep learning","Innovation","Transparency","AI","Model optimisation","Fairness,","Actionability","Code"]},prevItem:{title:"Foundation models for time series forecasting (1/2)",permalink:"/blog/Foundations_Models_Time_Series_1"},nextItem:{title:"CLAIR.bot: One Year of Responsible AI Serving Public Debate",permalink:"/blog/clair_anniversary"}},s={authorsImageUrls:[void 0,void 0]},c=[],m={toc:c},p="wrapper";function g(e){let{components:n,...t}=e;return(0,i.kt)(p,(0,a.Z)({},m,t,{components:n,mdxType:"MDXLayout"}))}g.isMDXComponent=!0}}]);