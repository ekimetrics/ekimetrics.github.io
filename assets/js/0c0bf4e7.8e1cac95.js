"use strict";(self.webpackChunkeki_lab=self.webpackChunkeki_lab||[]).push([[8025],{3905:(e,n,a)=>{a.d(n,{Zo:()=>u,kt:()=>f});var t=a(67294);function r(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function i(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function o(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?i(Object(a),!0).forEach((function(n){r(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function l(e,n){if(null==e)return{};var a,t,r=function(e,n){if(null==e)return{};var a,t,r={},i=Object.keys(e);for(t=0;t<i.length;t++)a=i[t],n.indexOf(a)>=0||(r[a]=e[a]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(t=0;t<i.length;t++)a=i[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var c=t.createContext({}),s=function(e){var n=t.useContext(c),a=n;return e&&(a="function"==typeof e?e(n):o(o({},n),e)),a},u=function(e){var n=s(e.components);return t.createElement(c.Provider,{value:n},e.children)},p="mdxType",g={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},m=t.forwardRef((function(e,n){var a=e.components,r=e.mdxType,i=e.originalType,c=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),p=s(a),m=r,f=p["".concat(c,".").concat(m)]||p[m]||g[m]||i;return a?t.createElement(f,o(o({ref:n},u),{},{components:a})):t.createElement(f,o({ref:n},u))}));function f(e,n){var a=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var i=a.length,o=new Array(i);o[0]=m;var l={};for(var c in n)hasOwnProperty.call(n,c)&&(l[c]=n[c]);l.originalType=e,l[p]="string"==typeof e?e:r,o[1]=l;for(var s=2;s<i;s++)o[s]=a[s];return t.createElement.apply(null,o)}return t.createElement.apply(null,a)}m.displayName="MDXCreateElement"},6104:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>g,frontMatter:()=>i,metadata:()=>l,toc:()=>s});var t=a(87462),r=(a(67294),a(3905));const i={slug:"Counterfactual_Explanations",title:"Counterfactual Explanations: Enhancing Machine Learning Transparency and Delivering Actionable Insights",authors:["benjamin.wong","milan.bhan"],header_image_url:"img/blog/Counterfactual_header.jpg",image:"img/blog/Counterfactual_header.jpg",tags:["XAI","explainability","Machine Learning","Counterfactuals"],draft:!1,description:"Discover what counterfactual explanations are and how illustrating changes that lead to different model outcomes enhances transparency, fairness, and actionable decision-making in machine learning.",keywords:["XAI","Explainability","Interpretability","Machine learning","Data science","Deep learning","Innovation","Transparency","AI","Model optimisation","Fairness,","Actionability","Code"]},o=void 0,l={permalink:"/blog/Counterfactual_Explanations",source:"@site/blog/2025-04-16-Counterfactual_Explanations.md",title:"Counterfactual Explanations: Enhancing Machine Learning Transparency and Delivering Actionable Insights",description:"Discover what counterfactual explanations are and how illustrating changes that lead to different model outcomes enhances transparency, fairness, and actionable decision-making in machine learning.",date:"2025-04-16T00:00:00.000Z",formattedDate:"April 16, 2025",tags:[{label:"XAI",permalink:"/blog/tags/xai"},{label:"explainability",permalink:"/blog/tags/explainability"},{label:"Machine Learning",permalink:"/blog/tags/machine-learning"},{label:"Counterfactuals",permalink:"/blog/tags/counterfactuals"}],readingTime:10.205,hasTruncateMarker:!0,authors:[{name:"Benjamin Wong",title:"Senior Consultant",url:"https://www.linkedin.com/in/benjamin-wong-62a5b7189/",key:"benjamin.wong"},{name:"Milan Bhan",title:"Domain Specialist",url:"https://www.linkedin.com/in/milan-bhan-43133a102/",imageURL:"/img/authors/milan.bhan.png",key:"milan.bhan"}],frontMatter:{slug:"Counterfactual_Explanations",title:"Counterfactual Explanations: Enhancing Machine Learning Transparency and Delivering Actionable Insights",authors:["benjamin.wong","milan.bhan"],header_image_url:"img/blog/Counterfactual_header.jpg",image:"img/blog/Counterfactual_header.jpg",tags:["XAI","explainability","Machine Learning","Counterfactuals"],draft:!1,description:"Discover what counterfactual explanations are and how illustrating changes that lead to different model outcomes enhances transparency, fairness, and actionable decision-making in machine learning.",keywords:["XAI","Explainability","Interpretability","Machine learning","Data science","Deep learning","Innovation","Transparency","AI","Model optimisation","Fairness,","Actionability","Code"]},nextItem:{title:"MMM Opportunities of Using Causal Inference",permalink:"/blog/Causal_Inference"}},c={authorsImageUrls:[void 0,void 0]},s=[],u={toc:s},p="wrapper";function g(e){let{components:n,...a}=e;return(0,r.kt)(p,(0,t.Z)({},u,a,{components:n,mdxType:"MDXLayout"}))}g.isMDXComponent=!0}}]);