<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Building a datalake - Part 2 - Smart storage &amp; computing strategies for better usability and usefulness | Eki.Lab</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://ekimetrics.github.io/blog/2023/02/28/building_datalake_part_2"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Building a datalake - Part 2 - Smart storage &amp; computing strategies for better usability and usefulness | Eki.Lab"><meta data-rh="true" name="description" content="For this second part of datalake building, we’ll go deeper into the journey of data, more specifically expand on storage and compute strategies."><meta data-rh="true" property="og:description" content="For this second part of datalake building, we’ll go deeper into the journey of data, more specifically expand on storage and compute strategies."><meta data-rh="true" name="keywords" content="Data Science,EkiLab,Ekimetrics,Eki.Lab,Eki,Machine Learning,Artificial Intelligence,Data Science for business,Datalake,Data Engineering,Lakehouse,Data Architecture,Data Governance,Data Validation,Data Mesh,Azure,AWS,GCP"><meta data-rh="true" property="og:image" content="https://ekimetrics.github.io/img/blog/overview_datalake_part_2_v2.png"><meta data-rh="true" name="twitter:image" content="https://ekimetrics.github.io/img/blog/overview_datalake_part_2_v2.png"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2023-02-28T00:00:00.000Z"><meta data-rh="true" property="article:author" content="mailto:inno@ekimetrics.com"><meta data-rh="true" property="article:tag" content="Datalake,Data Engineering,Architecture,Data Governance,Data Mesh"><link data-rh="true" rel="icon" href="/img/favicon.png"><link data-rh="true" rel="canonical" href="https://ekimetrics.github.io/blog/2023/02/28/building_datalake_part_2"><link data-rh="true" rel="alternate" href="https://ekimetrics.github.io/blog/2023/02/28/building_datalake_part_2" hreflang="en"><link data-rh="true" rel="alternate" href="https://ekimetrics.github.io/blog/2023/02/28/building_datalake_part_2" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Eki.Lab RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Eki.Lab Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-124520099-9","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>




<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-124520099-9"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-124520099-9",{anonymize_ip:!0}),gtag("config","G-MQNYE0E8GE",{anonymize_ip:!0})</script><link rel="stylesheet" href="/assets/css/styles.97279a6c.css">
<link rel="preload" href="/assets/js/runtime~main.291f8b78.js" as="script">
<link rel="preload" href="/assets/js/main.a88940ab.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title text--truncate">Eki.Lab</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">About us</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/about">Ekilab</a></li><li><a class="dropdown__link" href="/about/ekimetrics">Ekimetrics</a></li><li><a class="dropdown__link" href="/about/stack">Technology stack</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Resources</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/resources/">Hackathons</a></li><li><a class="dropdown__link" href="/resources/trainings">Trainings</a></li></ul></div><a href="https://ekimetrics.com/fr/carrieres/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Careers</a></div><div class="navbar__items navbar__items--right"><a href="https://ekimetrics.com/fr/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Ekimetrics website</a><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Contact us!<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="searchBox_ZlJk"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input type="search" id="search_input_react" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><main class="col col--9 col--offset-1" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="image" content="https://ekimetrics.github.io/img/blog/overview_datalake_part_2_v2.png"><header><h1 class="title_f1Hy" itemprop="headline">Building a datalake - Part 2 - Smart storage &amp; computing strategies for better usability and usefulness</h1><div class="container_mt6G margin-vert--md"><time datetime="2023-02-28T00:00:00.000Z" itemprop="datePublished">February 28, 2023</time> · <!-- -->9 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Emilien BOUCAUD</span></a></div><small class="avatar__subtitle" itemprop="description">Data Engineering &amp; Architecture Consultant</small></div></div></div></div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><div align="center"><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/overview_datalake_part_2_v2-2239a71ec2a5454c6e79ec8ed9c3ad48.png" width="5464" height="3640" class="img_ev3q"></p></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="article-scope">Article Scope<a href="#article-scope" class="hash-link" aria-label="Direct link to Article Scope" title="Direct link to Article Scope">​</a></h2><div align="justify"><p>In a previous article - <a href="https://ekimetrics.github.io/blog/2022/02/07/building_datalake_part_1/" target="_blank" rel="noopener noreferrer">Building a datalake - Part 1 - Usable, Useful, Used, or how to avoid dataswamp and empty shell traps | Eki.Lab</a> - we took a look at the foundation architecture used at Ekimetrics when building a datalake. Its focus was to present design elements to ensure your datalake is useful and usable at its core, as well as best practices to avoid falling into the so-called data swamp and empty shell traps.</p><p>For this second part, we’ll go deeper into the journey of data, more specifically expand on storage and compute strategies, and see how the organisation of data and the way it is transformed impact a datalake’s usability &amp; usefuleness.</p></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">​</a></h2><div align="justify"><p>The overview of data’s journey through a datalake or data platform can be broken down into five steps, represented below from left to right.</p><p><img loading="lazy" alt="screenshot-app" src="/assets/images/img1_data_journey-b88b0c7ad94bd8652615a4bdb7ae128a.png" width="1803" height="693" class="img_ev3q"></p><div align="center"> Data’s journey, from source to usage</div><br><p>A data platform is highly versatile in providing technical options the five steps above. Getting your data from one step to the next means applying a strategy for how the data input is stored, how it is processed and how the output is exposed for the next step.</p><p>These strategies will vary depending on the use case and platform, taking business as well as technical constraints in consideration. Designing your datalake’s strategies to be versatile and homogeneous is essential. It allows your data platform to grow fast, in terms of data content as well as use case possibilities. It also ensures that the datalake is under control with a common way of treating data, where its only varying specifities are the entry point (data sources) and output (serving layer). </p><p>At Ekimetrics, we’ve developed versatile strategies that are applicable to most common use cases, easily reproducible. These strategies help build new capabilities and provide a better understanding of your data platform.</p></div><br><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="where-designing-storage--compute-strategies-really-matters">Where designing storage &amp; compute strategies really matters<a href="#where-designing-storage--compute-strategies-really-matters" class="hash-link" aria-label="Direct link to Where designing storage &amp; compute strategies really matters" title="Direct link to Where designing storage &amp; compute strategies really matters">​</a></h2><div align="justify"><p>In most datalake architectures, the data journey’s step where the most impactful design decisions can be made is <em>Data storage and processing</em>. The other steps are more straightforward:</p><ul><li>Data sources are usually out of the architect or data engineer’s control, as they often sit outside of the data platform (e.g. on a third-party server).</li><li>Ingestion is a step for which design questions around data validation &amp; organization processes may be worth considering. We’ve talked about these processes in the first part of our “Building a datalake” articles. As for streaming vs batch, it is only dependent on the source: if the source system is streaming data, a resource to ingest that is necessary ; otherwise, recurrent batch ingestion is the go-to.</li><li>Serving will depend on the target use case, so even if there are important design decisions to make, they will only be impactful in the scope of their use case, not for the whole datalake.</li><li>Usage will most of the time be outside the datalake and depend on the use case. The few design decisions that may be necessary here won’t be as impactful to the datalake’s usability and usefulness either.</li></ul><p>Of course, this is not to say that designing relevant strategies and architecture for these steps doesn’t matter: they must be tailored to the business case and technical constraints.</p><p>On the flipside, the <em>Data storage and processing</em> step is the central piece in the datalake puzzle. It is where storage and compute strategies will be the most impactful. </p><p>What could it look like, then ? Inside this central step, data transits through four zones, from its raw form to fully processed for a particular use case, ready to serve to your businesses. These four zones are detailed below, in between ingestion and serving.</p><p><img loading="lazy" alt="screenshot-app" src="/assets/images/img2_data_storage-905c99d1d5a0c6e5421ba02084e2063e.png" width="1803" height="500" class="img_ev3q"></p><div align="center"> Data storage and processing - storage zones</div><br><p>These zones can be found under various names: Landing - Bronze - Silver - Gold, or Temp - Raw - Cleaned - Conformed, etc. The intent is the same, where data becomes more and more usable and business use case oriented with each zone.</p><p>In between each storage zone, organization and transformation processes are applied to organize and extract insights out of data. This is where our storage and computing strategies come in.</p></div><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="going-from-source-to-raw-storage-strategy">Going from source to raw: storage strategy<a href="#going-from-source-to-raw-storage-strategy" class="hash-link" aria-label="Direct link to Going from source to raw: storage strategy" title="Direct link to Going from source to raw: storage strategy">​</a></h3><div align="justify"><p>An ingested source will usually be exposed in one of two possible ways: </p><ul><li>Incremental changes, where only what is new or updated is exposed.</li><li>Full datasets, where all of the up-to-date data (or a new timeframe of data) is exposed.</li></ul><p>In these two cases, the ingestion strategy we recommend results in the same outcome. Here the strategy is to historize all received data, adding metadata about its reception date (or validity date) through organization in the storage architecture or in the dataset itself. The RAW storage zone becomes a source of historical knowledge about all data points and their changes through time. Doing this, we’re also able to add a “slowly changing dimension” / “change data capture” aspect to our data, where we can easily find a data point’s values at any moment in time.</p><p><img loading="lazy" alt="screenshot-app" src="/assets/images/img3_computing_1-cef3f81042eb0c848b50f0d4c4451404.png" width="1803" height="1297" class="img_ev3q"></p><div align="center"> Fig. 1: Computing &amp; storage strategies in between Landing and Raw zones</div><br><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>There are limitations to historizing all received data, notably storage costs: this is where the data’s lifecycle must be discussed. Keeping all older versions of a single dataset may start to become expensive as the data piles up, outweighing the pros if only the latest values are used.</p><p>In this case, a solution can be to keep only the latest values of the source’s data points, or just one version of the source every N periods on top of the latest ones. We can then archive older and unused versions in cold, less costly storage resources. The archived data enters a different lifecycle, where it could be removed at some point in the future if it doesn’t serve any business purpose.</p></div></div><p>The “historize everything” strategy ensures RAW storage is the most useful it can be: use case agnostic, your businesses can use and explore the data at its full potential. It also helps unify the way RAW storage is meant to be read by your later processes, improving usability while allowing for costs optimization without sacrificing the underlying principle.</p></div><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="going-from-raw-input-to-refined-output-computing-strategy">Going from raw input to refined output: computing strategy<a href="#going-from-raw-input-to-refined-output-computing-strategy" class="hash-link" aria-label="Direct link to Going from raw input to refined output: computing strategy" title="Direct link to Going from raw input to refined output: computing strategy">​</a></h3><div align="justify"><p>By applying this highly inclusive storage strategy for our RAW storage, we’re then able to fetch the necessary data for our business cases, whether it’s using the full history of a source, its latest version or the latest changes only.</p><p>The most common computing strategy will be to generate an up-to-date view of the data: at the time of computing, what are the insights’ state ? We’re also able to use older data to track changes and generate insights from these.</p><p>Refined data can then be exposed in two ways, acting as the source for another system: </p><ul><li>Exposing the full dataset, where all data is up-to-date</li><li>Exposing incremental changes, where only what is new or updated is sent to the serving layer</li></ul><p><img loading="lazy" alt="screenshot-app" src="/assets/images/img4_computing_2-dcc7a76dc859f9bae73bb079498fd3eb.png" width="1803" height="1561" class="img_ev3q"></p><div align="center"> Fig. 2: computing and storage strategies in between Raw, Trusted and Refined zones</div><br><p>For some use cases, you can generate “frozen in time” views of the data, only updating the current timeframe’s view. For instance, we could update the current month’s exposed insights each day, then stop updating it at the end of the month, writing a new one for the next month’s computed insights, and so on.</p><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>Historizing our transformations and results is useful for debugging and business exploration, but iterations may start to pile up, so defining a lifecycle for Trusted (TRD) and Refined (RFD) storage is important as well: do our technical processes or business use cases need all the iterations history stored in trusted TRD ? Can our business use cases work with a simplification of RFD storage, similar to the Delta historization for RAW zone in figure 1 ? </p></div></div><p>You may have noticed, our exposed Refined storage looks strangely similar to what we had in the data source: we’re exposing either the full up-to-date version of our insights, or just updates and new ones, just like our sources. The datalake is now a source for your business’ use cases, so it makes sense that it would be able to expose data in a similar way.</p><p>The “up-to-date view” strategy is highly useful for most use cases, and through smart use of historization, still allows for your businesses to get insights on the data’s evolution through time. It also ensures versatility in making your datalake a usable source for other systems when exposing data.</p><p>From there, the serving layer can leverage this source in a wide range of solutions, be it a database, reporting, CRM, AI models, etc. </p></div><br><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2><div align="justify">In essence, storage &amp; compute strategies can be sumarized in three questions:<ul><li>Why are these strategies necessary: to ensure versatility for businesses and technical processes, all the while improving usability.</li><li>How do they do that: by capturing and organizing data’s history efficiently, unifying the way we look at data while allowing for versatility in its usage.</li><li>What they mean: a unified, highly useful and usable storage, and computing that help the datalake become the source for a wide range of systems and use cases.</li></ul><p>As data engineers and architects, we’re always looking for ways to improve our data products. In the context of building a datalake, this means finding ways to make data easy to find, explain and extract insights from. The strategies we’ve talked are key answers to these challenges ; as we use them to grow data platforms and apply them to new use cases, these storage &amp; compute strategies have proved themselves to be highly useful for other data challenges, providing new capabilities and solutions for our clients.</p></div></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/datalake">Datalake</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/data-engineering">Data Engineering</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/architecture">Architecture</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/data-governance">Data Governance</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/data-mesh">Data Mesh</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/2023/03/07/level_car_analytics"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Does your company level with your car in terms of Analytics?</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/2023/02/21/creative_execution_and_marketing_effectiveness_part_V"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Exploring the links between creative execution and marketing effectiveness - Part V: Key Paths to Success and Common Pitfalls to Avoid</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#article-scope" class="table-of-contents__link toc-highlight">Article Scope</a></li><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#where-designing-storage--compute-strategies-really-matters" class="table-of-contents__link toc-highlight">Where designing storage &amp; compute strategies really matters</a><ul><li><a href="#going-from-source-to-raw-storage-strategy" class="table-of-contents__link toc-highlight">Going from source to raw: storage strategy</a></li><li><a href="#going-from-raw-input-to-refined-output-computing-strategy" class="table-of-contents__link toc-highlight">Going from raw input to refined output: computing strategy</a></li></ul></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">About us</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://ekimetrics.com/who-we-are/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Who we are ?</a></li><li class="footer__item"><a href="https://ekimetrics.com/our-team/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Our team</a></li><li class="footer__item"><a href="https://ekimetrics.us13.list-manage.com/subscribe?u=85b8ce42caa0a733e98233bc4&amp;id=6355d0a6f9" target="_blank" rel="noopener noreferrer" class="footer__link-item">Subscribe to our newsletter</a></li></ul></div><div class="col footer__col"><div class="footer__title">Find us</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/ekimetrics" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://ekimetrics.com/careers/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Careers<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.welcometothejungle.com/fr/companies/ekimetrics" target="_blank" rel="noopener noreferrer" class="footer__link-item">Eki on Welcome to the jungle<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Contact</div><ul class="footer__items clean-list"><li class="footer__item"><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Get in touch with our teams<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div></div></footer></div>
<script src="/assets/js/runtime~main.291f8b78.js"></script>
<script src="/assets/js/main.a88940ab.js"></script>
</body>
</html>