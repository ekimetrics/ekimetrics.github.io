<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Solving the Traveling Salesman Problem with Reinforcement Learning | Eki.Lab</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://ekimetrics.github.io/blog/2021/11/03/tsp"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Solving the Traveling Salesman Problem with Reinforcement Learning | Eki.Lab"><meta data-rh="true" name="description" content="A practical use of Reinforcement Learning and the Q-Learning algorithm to solve the Traveling Salesman Problem"><meta data-rh="true" property="og:description" content="A practical use of Reinforcement Learning and the Q-Learning algorithm to solve the Traveling Salesman Problem"><meta data-rh="true" name="keywords" content="Data Science,EkiLab,Ekimetrics,Eki.Lab,Eki,Machine Learning,Artificial Intelligence,Reinforcement Learning,Logistics,Supply Chain,Data Science for business"><meta data-rh="true" property="og:image" content="https://ekimetrics.github.io/img/blog/tsp.jfif"><meta data-rh="true" name="twitter:image" content="https://ekimetrics.github.io/img/blog/tsp.jfif"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2021-11-03T00:00:00.000Z"><meta data-rh="true" property="article:author" content="mailto:inno@ekimetrics.com"><meta data-rh="true" property="article:tag" content="Reinforcement Learning,Logistics"><link data-rh="true" rel="icon" href="/img/favicon.png"><link data-rh="true" rel="canonical" href="https://ekimetrics.github.io/blog/2021/11/03/tsp"><link data-rh="true" rel="alternate" href="https://ekimetrics.github.io/blog/2021/11/03/tsp" hreflang="en"><link data-rh="true" rel="alternate" href="https://ekimetrics.github.io/blog/2021/11/03/tsp" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Eki.Lab RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Eki.Lab Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-124520099-9","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>




<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-124520099-9"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-124520099-9",{anonymize_ip:!0}),gtag("config","G-MQNYE0E8GE",{anonymize_ip:!0})</script><link rel="stylesheet" href="/assets/css/styles.8553c126.css">
<link rel="preload" href="/assets/js/runtime~main.0995dcc9.js" as="script">
<link rel="preload" href="/assets/js/main.b03e3f5a.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title text--truncate">Eki.Lab</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">About us</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/about">Ekilab</a></li><li><a class="dropdown__link" href="/about/ekimetrics">Ekimetrics</a></li><li><a class="dropdown__link" href="/about/stack">Technology stack</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Resources</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/resources/">Hackathons</a></li><li><a class="dropdown__link" href="/resources/trainings">Trainings</a></li></ul></div><a href="https://ekimetrics.com/fr/carrieres/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Careers</a></div><div class="navbar__items navbar__items--right"><a href="https://ekimetrics.com/fr/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Ekimetrics website</a><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Contact us!<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="searchBox_ZlJk"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input type="search" id="search_input_react" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><main class="col col--9 col--offset-1" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="image" content="https://ekimetrics.github.io/img/blog/tsp.jfif"><header><h1 class="title_f1Hy" itemprop="headline">Solving the Traveling Salesman Problem with Reinforcement Learning</h1><div class="container_mt6G margin-vert--md"><time datetime="2021-11-03T00:00:00.000Z" itemprop="datePublished">November 3, 2021</time> · <!-- -->14 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Théo Alves Da Costa</span></a></div><small class="avatar__subtitle" itemprop="description">Head of AI For Sustainability</small></div></div></div></div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><div align="center"><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/tsp-6a6c73c13104c2c80f047a36eb607d39.jfif" width="1484" height="840" class="img_ev3q"></p></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="summary">Summary<a href="#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary">​</a></h2><div align="justify"><p>Reinforcement Learning (RL) is usually applied for state of the art AI research and often make the headlines. Yet it still fails to deliver on concrete business topics. At Ekimetrics we strive to transfer AI innovations into the business world and Reinforcement Learning is a unbelievable playground to find disruptive solutions to complex real-world problems. In particular, there are many optimization problems that could be solved using RL.</p><p>The Traveling Salesman Problem (TSP) has been solved for many years and used for tons of real-life situations including <strong>optimizing deliveries</strong> or <strong>network routing</strong>. This article will show a simple framework to <strong>apply Q-Learning to solving the TSP</strong>, and discuss the pros &amp; cons with other optimization techniques. It&#x27;s a perfect introduction for beginners in Reinforcement Learning and does not require heavy computational capabilities.</p><blockquote><p>You can find all the code open sourced <a href="https://github.com/TheoLvs/reinforcement-learning/tree/master/5.%20Delivery%20Optimization" target="_blank" rel="noopener noreferrer">here on Github</a></p></blockquote><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="the-traveling-salesman-problem">The Traveling Salesman Problem<a href="#the-traveling-salesman-problem" class="hash-link" aria-label="Direct link to The Traveling Salesman Problem" title="Direct link to The Traveling Salesman Problem">​</a></h2><div align="center"><p><img loading="lazy" src="/assets/images/tsp_example-a3af33433166558228c6bd765c1aeb5e.png" width="900" height="482" class="img_ev3q"></p></div><p>The Traveling Salesman Problem (or TSP) is a typical optimization problem, where one has to find the shortest route to visit different cities. There are many different ways to solve this problem using discrete optimization techniques. </p><p>Like many optimization problems, it&#x27;s a NP-hard problem, which in short means that it&#x27;s easy (in terms of speed) to solve for 5 cities, already impossible to brute force for 50. And almost impossible for most algorithms for  5,000 cities. Even for 15 cities, it&#x27;s already 1 trillion permutations to compute (15!), there are optimization techniques that are more adequate : dynamic programming, branch and bound algorithms, nearest neighbors approximations, or ant colonies optimizations.</p><p>Furthermore, the problem described here is too simple to describe a real-life delivery situation. It does not take into account multiple vehicle fleet, electric vehicle charging, time window constraints, capacity constraints, aleatory perturbations, etc... Hence, each variant of the TSP has its own optimization frameworks (in terms of variables and constriants), and the more you complexify the problem, the more difficult it is of course. That&#x27;s why in practice delivery companies use combinations of those variants coupled with heuristics. The most advanced companies today add Machine Learning techniques on top of those algorithms, in particular to replace manual heuristics and better estimate in-context durations.    </p><p>In Python, the easiest way to get started with TSP and its variants is probably the great open source library <a href="https://developers.google.com/optimization/routing" target="_blank" rel="noopener noreferrer">OR-Tools by Google</a>. And if you want to learn more about discrete optimization, I can only recommend the great MOOC on <em>Discrete Optimization by the University of Melbourne</em> you can find on <a href="https://www.coursera.org/learn/discrete-optimization" target="_blank" rel="noopener noreferrer">Coursera</a>. </p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="applying-reinforcement-learning-to-the-tsp">Applying Reinforcement Learning to the TSP<a href="#applying-reinforcement-learning-to-the-tsp" class="hash-link" aria-label="Direct link to Applying Reinforcement Learning to the TSP" title="Direct link to Applying Reinforcement Learning to the TSP">​</a></h2><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="why-bother-using-reinforcement-learning">Why bother using Reinforcement Learning?<a href="#why-bother-using-reinforcement-learning" class="hash-link" aria-label="Direct link to Why bother using Reinforcement Learning?" title="Direct link to Why bother using Reinforcement Learning?">​</a></h3><p>If it&#x27;s already solved by classical optimization techniques, why bother using Reinforcement Learning? Well several answers: </p><ul><li>It&#x27;s fun and I personally love practicing RL. Curiosity is a great driver for innovation, and here I was really wondering if it could be applied for such a problem.</li><li>RL is rarely used in real-life problems. Playing games or manipulating robot hands is awesome, but when it comes to business problems, RL often fails compared to simple heuristics or algorithms. At Ekimetrics, we always look for applying state-of-the-art AI research to the business problems we encounter in the real-world. </li></ul><p>However, Reinforcement Learning (in theory) would hold many advantages compared to classical optimization techniques : </p><ul><li><strong>Offering a general framework for all problems</strong>, indeed instead of tweaking the constraints and defining extra variables, you can change the reward, and defining a multi agent problem if needed for fleet optimization. Adding extra information like delivery time estimation is also eased if you can integrate the prediction algorithm with a similar ML techniques (e.g. Neural Networks)</li><li><strong>Having a &quot;live&quot; decision making algorithm</strong>. Because you would train a RL alorithm by making the next delivery decision at each stop, compared to &quot;offline&quot; optimization algorithms that study the problem with no unknowns, you inherently would be able to take different decisions if something happened during the experience, whereas you would need to recalculate with classical techniques</li><li><strong>Being robust to unknowns and aleatory perturbations</strong></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="transforming-the-tsp-to-a-rl-problem">Transforming the TSP to a RL problem<a href="#transforming-the-tsp-to-a-rl-problem" class="hash-link" aria-label="Direct link to Transforming the TSP to a RL problem" title="Direct link to Transforming the TSP to a RL problem">​</a></h3><p>Before jumping into the TSP variants, let&#x27;s take the most simplest version: <em>a delivery man who has to deliver 50 packages</em>. Between each stop can be defined a distance or a duration (or a more complex metric). </p><p>To transform it to a RL problem, we need to define: </p><ul><li><strong>Agent</strong>: the delivery man</li><li><strong>Environment</strong>: the different packages to deliver (and their destination) and the city where to navigate</li><li><strong>States</strong>: the location where the delivery guy currently stops </li><li><strong>Actions</strong>: at each location, the decisions to make (modeled as a Markov process) are: &quot;where to go next&quot; (or &quot;which location do I chose next&quot;)</li><li><strong>Reward</strong>: Between two locations (states), how long (or how far) it is</li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="creating-the-routing-environment">Creating the routing environment<a href="#creating-the-routing-environment" class="hash-link" aria-label="Direct link to Creating the routing environment" title="Direct link to Creating the routing environment">​</a></h3><p>Creating a simple version of the environment is quite simple in pure Python. Indeed, you can store the position of the stops in a 2D virtual world as a numpy array or a Pandas DataFrame. Distances between stops can be calculated with an euclidean distance, but it could be complexified to account for durations or represent any distance/duration metric you would see in a routing network. </p><div align="center"><p><img loading="lazy" src="/assets/images/env2-8887c8a80fd93eab07028f70b2a38dc3.png" width="404" height="408" class="img_ev3q"></p></div><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> scipy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">spatial</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">distance </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> cdist</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ENV_SIZE </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">10</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">N_STOPS </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">100</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Creating the stops using numpy random points generator</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">xy </span><span class="token operator">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">random</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">rand</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">N_STOPS</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token number">2</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token operator">*</span><span class="token plain">ENV_SIZE</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Computing the distances between each points</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Here use euclidean distances, but any metric would do</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># This distance matrix can actually represent a time, a distance or something else</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">distance_matrix </span><span class="token operator">=</span><span class="token plain"> cdist</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">xy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">xy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Then we want to define the starting position, the route, and the end position. Meaning that if we have to traverse A, B, C, D, E, possible routes would be for example <code>A-&gt;C-&gt;B-&gt;E-&gt;D</code> or <code>B-&gt;D-&gt;E-&gt;C-&gt;A</code>. </p><p>By the way with 5 stops you have 5! possible routes or 120 possible routes. For 10 stops you already have 3.6 million possible routes. For 100 stops it&#x27;s 10 to the 158th power routes. It&#x27;s called the combinatory explosion, and that explains why this simple problem is impossible to brute force for a high number of stops. </p><p>We can visualize routes by drawing lines between each stop</p><div align="center"><p><img loading="lazy" src="/assets/images/env1-ce256f64cdffdbd7e5143d792d7867ad.png" width="404" height="408" class="img_ev3q"></p></div><p>We can also already imagine more complex and realistic situations. For example, one experiment I wanted to do was to stress test the RL algorithm to aleatory events. For example a known environment with unknown perturbations, like traffic. To model this interaction, we add a &quot;traffic zone&quot; inside our environment, where routes are much slower if taken. To account for the extra duration, we calculate the intersection points of the route within the &quot;traffic zone&quot; and measure the distance of the formed segment, we then use that distance weighed with a traffic intensity factor. </p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">i1,i2 = intersections</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">distance_traffic = np.sqrt((i2[1]-i1[1])**2 + (i2[0]-i1[0])**2)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">additional_reward = distance_traffic * traffic_intensity * np.random.rand()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div align="center"><p><img loading="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZQAAAGYCAYAAABlBxTbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3X9sXFfd5/HPjO144pngNiqVaBcELZCiR0kp24pEAlJSVW15wHHiBLVpnz4BtlrSZdMfAiUpqdsa0oWQRoG0hW2JtNknZGkgIYlA/acUKioShBDCqXb3SUkjUVKQQhplPZ7Yjj2zfzjjOvadO2PPufecc+/79Rd0EvvGnrnfe873x8lUKpWKAABoUtb2BQAAkoGAAgAwgoACADCCgAIAMIKAAgAwgoACADCi1fYFAJP99a9/1a233qoPf/jDkqRyuax8Pq97771Xn/nMZ+r+/WXLlum73/2uJOn555/X9773vUivd6oDBw5oz549Gh0d1djYmD760Y9q48aNmjdvnt58801t3bpVO3fujPWagLgQUOCcXC6nQ4cOTfz/U6dOae3atWppadFtt93W0NdYuHBh7MGkv79fzzzzjPbv36/LLrtMY2NjeuKJJ/T444/rqaee0ltvvaWTJ0/Gek1AnNjygvOuvvpqrV+/Xrt27ZIkjYyM6Mknn9SKFSvU1dWljRs3qlgsXvJ3fve73+mzn/2sBgYG9LGPfUynT5+eeG316tV65ZVXQr/OsmXL9OCDD+qOO+7Q97//fd18880ql8uSpPPnz2vJkiV6++23L/mep0+fVqVS0dDQkCSppaVFDzzwgFavXq2xsTFt3rxZf/nLX/SlL31JkvTSSy+pu7tbXV1duuuuu9Tf3y9J2rlzp7761a/qnnvu0W233aYHHnhg4rr27t2rrq4u9fT0aM2aNfrzn/9s+scNzBoBBV647rrrdPz4cUnSc889p5aWFh04cECHDx/WlVdeqW3btgX+vXnz5unWW2/V4cOHJUknTpzQP/7xD33yk5+s+3U+9KEP6cUXX9S6devU2dmp3/zmN5KkX/ziF1qyZInmz59/yff61Kc+pRtuuEHLli3TihUr1NfXp2PHjunjH/+4Wlpa9M1vflPve9/7tGvXLp04cUKPPfaYdu7cqcOHD2v9+vW6//77JwLH73//e+3YsUMvvviiWltb9cwzz2hsbExPPvmkfvjDH2r//v36/Oc/rz/84Q/Gf9bAbBFQ4IVMJqNcLidJ+vWvf62XX35Z3d3dWr58uV566SWdOHGi5t9dvXq1Dh48KEnav3+/enp6lM1m636dG2+8ceJ/33333dq3b58k6YUXXtBdd9017fu0tbXpqaee0q9+9St94Qtf0IULF7RhwwY99NBD0/7s0aNHtXjxYr33ve+VpIkA9dprr0mSbr/9dl1xxRXKZrNatWqVXn31VbW0tOj222/XnXfeqb6+Pr3rXe/SqlWrZvqjBCJDDgVeOHbs2CWJ+kceeURLly6VJA0ODmp4eLjm373xxhs1Ojqq/v5+/fznP9cLL7zQ0Nfp6OiY+N+f+9zntH37dh09elSlUkk33XTTtO/z05/+VJdffrluueUWdXV1qaurS+vWrdOyZcumbY+Vy2VlMplL/lulUtHo6Kik8e2yyX82mx1/9tu2bZuOHz+u3/72t3ruued06NChiSIEwDZWKHDeyZMn9eyzz+qLX/yiJOkTn/iEfvSjH2lkZETlclmPPvqotm/fHvo1Vq9erW984xtasGCB3vOe98z468ydO1ddXV165JFHdOeddwb+mWw2q23btunvf//7xH97/fXXddVVV6mzs1MtLS26cOGCpPEVyauvvqo333xTknTkyBH97W9/0/XXXy9J+uUvf6mBgQGVy2Xt27dPn/70p/X2229r6dKluuyyy7R27Vo9+OCDOnbs2Ax+kkC0WKHAOUNDQ1q+fLmk8Zt0e3u7Hn74Yd18882SpPvvv1/f/va3tWLFCo2NjekjH/mINm7cGPo1u7u7tX379ksCxky/zsqVK7Vv3z51d3fXfP38+fO67777NDIyokwmo/e///3atWuXWlpa9MEPflDt7e1atWqVfvKTn+ixxx7TV77yFY2NjSmXy+kHP/iB5s2bJ0m64oordN999+ns2bO66aab9OUvf1m5XE7r1q3T2rVrlcvlJvIygCsyjK8H6qtUKnr++ed16tQpPfHEE5F+r507d+rs2bPq7e2N9PsAprFCARpwyy236Morr9Szzz5r+1IAZ7FCAQAYQVIeAGAEAQUAYERoDuX06YG4rgMA4Il3v3te4H9nhQIAMIKAAgAwgoACADCCgAIAMIKAAgAwgoACADCCgAIAMIKAAgAwgoACADCCgAIAMIKAAgAwgoACADCCgAIAMIITG9GQTHFA7QcPqOWNExq75loNd69UpRA8cRRAOoWe2Mj4ekhS69Ej6lzTI5XLypZKKnd0SNmszu3dr9HFS2xfHoCY1RpfT0BBqExxQPMXLVC2WJz2WrlQ0Jn+41KhYOHKANjCeSiYlfaDB6RyOfjFclm5QwfivSAAziKHglAtb5xQtlQKfC1bKil78o2YrwhRIleGZhBQEGrsmmtV7ugIDCrljg6VP3CNhatCFIJyZfneTeTK0DByKAhFDiUd+D1jJsihYFYqhXk6t3e/yoXCeHWXLq5MCgWd27ufm0xCkCuDCWx5oa7RxUt0pv+4cocOKHvyDZU/cI2Glq8kmCQIuTKYQEBBYwoFDd19r+2rQETSnCujEMEccigAUptDoWl3dsihAKgpjbmyTHFAnWt6lC0WJ1Zm2VJJ2WJxPMgEBFeEY8sLgKT05coaKURgm3dmCCgA3pGiXBmFCOax5QUglaqFCEGSXogQFZLyAFIpTYUIpivZmDaMWFGKCR+kocorin8jAQWxScOHFAlSLCa2ECGqVVitgEJSHkZNLsWsqiY+O9f0JGobAQmR4EKEuCvZSMrDKGZCAe6Iu5KNgAKjKMUE3BF3JRsBBUZRigm4Y7h7pZStcZvPZsfzRQYRUGBU3G9gALXFPVKHKi8YR5UX4BjDlWyUDSNeCS7FBNKOgAIAMILx9QCASBFQAABGEFAAAEYwegUNYdgjgHpIyqOuaWXAc+YoU6mo9J//i84//DUCC5AyVHlhVsKmlVYkVfIFnftf9JcAaUKVF2YlbNhjRlJ2sDi+egkIOADSJfaAkikOKLdnt/J9vcrt2a1MkVWQy8KGPU5gijAAxZyUDxrJke/dxEgOh1WHPYYFFaYIA5BiXKFMPnipenPKlkrKFtkycVnosMeLmCIMQIoxoHDwkp8mppXm86pZvcEUYQCKMaBw8JK/Rhcv0Zljr+v8f31IlbY2VebMkRTtGGwA/okthxK2F8+WiQcKBQ0++oQGH/pa7FOEaaoE/BBbH0pYP0O5UNCZ/uM85WIazlYB3ONEY6OpmwNPrOnAQwjgploBJday4dHFS3Sm/3hTWyaUHqdHI4UcQ3ffG+9FAagp/uGQhcKsbwKTS4+rqjmZzjU9PLFaZnrlSCEH4Bevpg3zxOquKFaOFHIAfvFqlhdPrG6Kqmk1tKmS3hdEiBFRs+NVQKk+sQbhidWeqJpWJ5oqC4WJ3zu9L4ha69Ejmr9ogfKbN6jj6R3Kb96g+YsWqPXoEduX5jyvtryGu1cq37sp+EWeWK2JcuVoopADaBR52uZ4FVCqT6y1So/5RdsRea6jiUIOYCbI0zbHq4Ai8cTqIlaOSArytM3xLqBI4onVMUlYOdIsC4nKwmZxBDDMKRa9XDky3sU+VwI60xka48ToFde48iaGPdxA7HMtoNu+Hh/uSwSUKWy/aeCG3J7dym/eUHOLY/DRPqm93ekPt8+cDeiWVtu+3JcIKJM4+yZG7PJ9vep4ekfN1yttbaq0tTHMNCJ1A/qWranJl/p0X6oVULxqbDSF0yNRFdYsW5GUuXChqe5/muTCUVX1jiTcl1IZUHgToyp0vEstDX64oxpJE/b9fBsX4uL0C1s/xyTcl1IZUFx8E8OOWuNdKm1tytT4O41+uON84vR1JeTavDabP8ck3JdSGVBcexPDrmqz7OCWrRpc/7AGt2xVse+/Nf3hjuuJM+6VkEkuzWuz/XNMwn3Jz8bGJiWhEQ+GTWmWzRQHlN/yeOAfzVy4IA0NKVMcCE2ux9Uk5/u4EFemX9j+OSbhvpTKKq8JnjbiIR5TSzirH5SM1FDFV9RVO9Xqsdy//Q+1/fEPNf/c4PqHVdr8+Ky/T1rUq/iL7efowX3JiSOAncMIF4SYeHJ+Ya8KvZvGVyYXNTKBNsonzqBgF5Tz8WXv3QXOjF3x+L6U7oAC1FMoSO3t40n6SQFlQp2tkCi2c4JGrNcqIPBl790FDDltHgEFqKPp5LrhJ86wvf7qSsW3vXcXJCGHYRsBBajDma2Qi8ICXEbSyH+8ScP3/KuTe++uc6VAwFcEFKAO17ZC6gW44Xv+1ds9eCd4nMOwLZV9KMBMuNQrISWjXwHJlO6yYWAmHCrn9GUqbZoleSgo04YdkeQ3GWLmUIDDpZIe8AkoDkj6mwyAX2PoZ4vx9ZaZmhPk40RZIE2SMIZ+tqjyiomJOUFBK5x87yZWOIBDkjCGfrZYocSk2TeZ7UmoABqThDH0s0VAiUmzb7I0L6MBn6S5rJuAEpNm32RpXkYDPnGtbylO5FCmaP3THyP72sW+b6nw9a9JlYqyQ0Mq53JSJqNi37fUeuL10L9baWtTOZdTdmho2mvlXE5qbY302hGt0etvsH0JM0YJfG1pHeHiVNmwC2/QyG/KpfOa88rLyr51SuWrrtbI0mVSx9wG/l5JnXeuVPb8+WkvlefO1bkf/6yxrwMn+RZQKIFPN+f7UFx5g7r8lN9y7FjwCmfLdzS2cKHty0MTfAooaeizQDinD9gKOt+hkQOM0mZs4UKd+/HPZrfCAQyxfVQu3OVEQOENOgMdczVyxz/bvgqkGAUiqMVaQJmcL2n536/xBgU84dr5MHCHlYAyLV8yZw5nYgOecO18GLgj9j6UwI7vkRHOxAY8keY+C4SLfYVS7zxszZmjzMgIZzkDDktrnwXCxR5Q6p2HPfzJpRr9p4W8QQHXcVQupog9oNRL6I18djlvUgDwUOw5lDQPTgOAJIs9oJDQA4BkslI2TEIPAJLHXqc8CT0ASBTOQwEAGEFAAQAYQUABABjhxLRhAIA5tg4rJKAASAwXTn21LeiwwnzvplgOK3TmxEZXuHxiI5LLpxMbXeXKqa82xXWaZq0TG8mhAPBe4BTzUknZYnE8yATcYJOokcMKo0RAAeA92zdSV9g+TZOAAsB7tm+krqgO3w0Sx2GFBBQA3rN9I3WF7eG7BBQA3rN9I3WF7eG7lA0D8F71RlqryitNg2dtDt+lbHgKyoZhA2XDhhSLTDGPQa2yYVYoAJKDKeZWEVCAFKGTHFEioAApYXMkB9KBKi8gBegkRxwIKEAK0EmOOBBQgBSgkxxxIIcCpEC1kzwoqNjuJKdQIDnoQ5mCPhTYEHUfSlxjzWeKkfN+Ynw9kGK2R3IEoVAgeVK15cXSGmlmcyRHkEYKBXxqUuT+kqKAQg0+IKc6yZNUKMD9ZVwqAsrkpXVV9Y3cuabH2v4xkGamCwVsrRC4v7wjFTkUavAB95gcOd969IjmL1qg/OYN6nh6h/KbN2j+ogVqPXrE0NXWxv3lHakIKElaWgNJYapQwHZyn/vLO1Kx5eVyDT4wWdoSuyYKBWwn97m/vCMVAWW4e6XyvZuCX0zRaW5wW2oTu00WCtheIXB/eUcqtrxcrMEHJrO9beMz2+fJc395R7o65Rs4zY1OedjQeqxf+c0bam6bDG7Z6ky5r2ucmQKQotMiObFRcqoGH5jM9raNz5w5T577S8oCCuAoErvNcW0KwEwkqRAjXVteDWDLCzaMXftBN7ZtECtfh2MyHBJwGInd9EliIQZbXoAjZrJtk6RtkrSy3T8TBQIK4JIGErup7VeJURwBO4mFGAQUwCMMIoxeXAE7iYUY5FAAj0QxiDBTHFBuz27l+3qV27NbmWL6inGq4sxrmByO6YpIVyjs8wJmmd4mYfvsUnHmNZzpnzEosoDCGxUwz+Q2Cdtn08Wd1/C5fyZIJAHFhTcqqyMkkclBhEmsMmqWlbxGgjrsI8mh2D5wxuZhO0CUTParJLHKqFlJzGvEKZIVis03qgurIyBKprZJklhl1Kwk5jXiFElAsflGZRmPVDCwTcI5HsGSlteIUyQBxeYblWU80BiexkMkKK8Rp0gCis03Kst4oHE8jcOkaKcNWzhwptnDdpg2DBtGr7/B9iUADbNzwJaFZSPLeABJ4GPrQ3LPQ5nl6ogVCmxghYLJXD8npdYKJbkBZZYIKLCBgIKqZrft48ABWwDgAduN4c0goACAQ3xufeA8FACx8zHhHBefWx/IoUxBDgU2mMih+HKTdj3hbJvPORQCyhQEFNjQbEDx5Sbtw83SBa7/Pu30oQCInE8DUZm11xhfJxgQUADP+XST9jnhPFXkW4wezhMjoACe8+kmHUXC2UbuiBNpg1E2DHiuepMO4lpVkOkDrGwcpjd5i7EaGLOlkrLF4niQCcgPpQUBBfCcT6cMmjxx0taN3efGw6ix5QV4zreBqKYSzrZyRz5tMcaNgAIkgHdVQQYSzrZu7D43HkaNgAIkhYdVQc2wdWPn6OTayKEA8JKt3JHJPFDSpGKF4stICsCkpL/vbeaOvNtijEniR6/MdIQBo1dgg+nzUFwf3WHUDA7TS3qQjUsqZ3nNZm4QAQU2mAwozMsKlqogG7FUHrBFvTjSiPf9dDQjxiPRAYV6caQR7/vpCLLxSHRA8WkkBWAK7/vpCLLxSHRA8WkkBWAK7/vpCLLxSHRAoV4cacT7fjqCbDwSXeU1YQZlhVR5wQbTZcOSZvS+TwOqvMxJZdnwbBBQYEMkAaUBqevLIMgaQUBpEAEFNtgIKDyxY7ZS2YcCIBh9GYgCAQVIIfoyEAUCCpBC9GUgCgQUIIXoy0AUCCiABzLFAeX27Fa+r1e5PbuVKTZXMENfBqKQivNQAJ8FVWPlezc1VY3l2zn08ANlw1NQNgwbapUNRz6Knr4MzEKtsmFWKIDDGqnGauoc+ZSdQ49okUMBHEY1FnzixAoldeMfgAZVq7GCggrVWHCN1RxKpjigju3f0dz//oyUySgzMmJ9/AM5FNhgLYcCzIJzo1dajx7R/IUf1tyndyhz4YIyIyPjF8T4B2ACo+jhEytbXhNzhAYHa/8hEwlHIAFGFy/Rmf7jVGPBeVYCSmjlykUkHIFJqMaCB6xseYVVrlSRcAQAv1gJKGFzhCYw/gEAvGIloITNEapIKudJOAKAb6wElMDKlTlzVGlrU+krD+nMseOcGAfAGtPDONPC7iwvB+cI0YcCG2ydKY/pOBq5Ps6UbxABBTYkIaAkYeIFjaSNYTgkgMg0OmLf9aAT+TDOhCOgAGjKRKPypKf6altA55qeiaf6KM51MY1hnM1h2jCApjTyVD856FRv2C6OWeJo5OYQUAA0pZGn+kaCjgs4Grk5BBQATWnkqd6XrSSGcTaHHAqApgx3r1S+d1Pwixef6nMH93tzrgvDOGePsuEpKBuGDb6XDdfr3aAcN1koGwYQmXpP9dWtpFpBh2CSDKxQpmCFAht8X6E0zMHpGJg5VigA7ONcl0SjygsAYAQBBQBgBAEFAGAEAQUAYAQBBQBgBAEFAGAEAQUAYAQBBQBgBAEFAGAEAQUAYAQBBQBgBAEFAGAEAQUAYAQBBQBgBAEFAGAEAQUAYAQBBQBgBCc2AmhIpjig9oMH1PLGCY1dc62Gu1eqUgg+ChbpREABUFfr0SPqXNMjlcvKlkoqd3Qo37tJ5/bu1+jiJbYvL5F8DOCZSqVSqfXi6dMDcV6LE1r/9Efbl4AUGr3+BtuXUFOmOKD5ixYoWyxOe61cKOhM/3GpULBwZckVFMCVzToTwN/97uDARg4FQKj2gwekcjn4xXJZuUMHIr+GTHFAuT27le/rVW7PbmWKyX3YzRQH1LmmR9liUdlSSZKULZWULRbHg0xAYHcFW14AQrW8cWLixjZVtlRS9uQbkX7/tG23NRLAh+6+N96LahArFAChxq65dnzLJUC5o0PlD1wT2ff2+Wl9tmwH8GYQUACEGu5eKWVr3CqyWQ0tXxnZ93Zhuy1uNgN4swgoAEJVCvN0bu9+lQuFiRtduaND5UJB5/bujzQh7/PT+mQzyQHZDODNIocCoK7RxUt0pv+4cocOKHvyDZU/cM34jS3i6q7q03pQUHH9ab1qpjmgagCvVeXlckUdZcNTUDYMG1wuG7bJ95Llpq6/WIw9gDeqVtkwKxQAzvL5aV1qsmKrUHC2mquWWAKKjx2fANxga7vNhKTkgBoVeUBJWw05gAg0+LTu2sNrEnJAMxFpDsXH/U9yKLCBHErzXBxX4uM9sBFWRq+ksYYcQPxcbYC0WXJtQ6RbXmnbPwRgh8vjSnzOAc1UpAElbfuHAOxw/uF1FhVbruWDGhHplpfPHZ8A/OHzuJIgrUePaP6iBcpv3qCOp3cov3mD5i9aoNajR2xfWqhIA0ra9g8B2JGkh1dX80GNiLxsOE37hwDs8L0BcjKX80H1xNMp72HHJwC/JOXh1fl8UAhGrwBIjgQ8vPpczMT4egBwiM/5oFSvUILK8gDAJp/zQakdX19rTEOx71saW7jQ9uUhZRi9gmk8HF+fyoASOl9n7lyd+/HPpI65Fq4MaUVAgU+sn4fiUtdnaFlepaI5r7yskTv+Od6LAgDPxRJQXBthH1qWNzSk7FunYr4iAPBf5FVeLnZ9ho5pyOVUvurqmK8IAPwXeUBxcYR9aFleJqORpcvivSDAU5nigHJ7divf16vcnt3KFJOZd0VjIt/ycrHrM6wsr9j3LRLyQANc28qGfZEHFFe7PmuNaWg98bqV6wF8Mnkru6r6Ge9c0+PtSYRoTuQBZbh7pfK9m4JftN31mYAxDYANPg8wRHQiz6Ewwh5IHhe3smFfLGXDSZkCCmCcq1vZsCuVnfJhWv/0R9uXgBTyrVM+dNpEoUAOJeFqdcozbRjAjLGVjSCpnjacKKWS5vz6ZWVP/VXlq/+DRm5eJtVo3gRMYCvbHpdGWV1yXWx5XcrHLa+WY8dU+PrXpEpF2aEhlXM5KZNRcct3mJzsCd+2vGBPrUnpcfb/MG04odjLBtLDlc87OZSEcnG0DYBouP55J6B4jn4AID1c/7wTUDwXOjmZfgAgUVz/vBNQPBc6Odn2aBsARrn+eSegeI5+ACA9XP+8U+WVFMUi/QBAWlj+vFM2DAAwgrJhAECkCCgAACMIKAAAIwgoAAAjCCgAACMIKAAAIzgPBajB1TMnAFfRhwIEcOHMCcBVNDYCDXLlzAnAVTQ2Ag1y/cwJwFUEFGAK18+cAFxFQAGmcP3MCcBVBBRgCtfPnABcRUABpnD9zAnAVVR5AbVwxgwQyMuyYRrLAMA93gUUGsuSiYcEwH9eBRQay5KJhwQgGbxqbKSxLHkyxQF1rulRtlic6PHIlkrKFovjQSbg4QGAX5wMKDSWJQ8PCUDyORlQaCxLHh4SgORzMqDQWJY8PCQAyedkQKGxLHl4SACikykOKLdnt/J9vcrt2a1M0VJBlYtVXhNoLEsUqrwA82x8rrwqG0Y4r3s5eEgAjLHVYlEroHAEsGeCnkbyvZv8ecovFDR09722rwIe8/qByrD2gweUuTAa+Frmwqhyhw7E+nkjoHhkci9HVbVyqnNNT2wNn3ygYYv3D1SGtfz7/1FmeCjwtczwkLL//n9jvR4Cikca6eWI+mmEDzRsceWByiXZs2dVkZQJeK0iqeXs2/FeT6zfzSOuVE1MZruXg2532ERz7HTlyy4PDCbSeJAZu3x+nJfDCiWIq0/h1V6OoKBiopej3laWCyskpJftByoXjV33EZXb25UdHp72Wrm9XeUF18V6PaxQpnD5KTzKXo7Wo0c0f9EC5TdvUMfTO5TfvEHzFy1Q69EjE3+GDzRsojl2uuHulVJbW/CLbW2x93cRUKZweVkdVcNno0GUDzRsojl2OteawFO95RW0xeP6U/jo4iU60388sJdjttVXjW5lDXevVL53U/CfS+kHGvGp3jxrNfG5npCPqjoy7J4Qt9QGlFp5kvNr/9OM8hRWSmgDejmayfs0GkR9/0DDfy7dPGci8rysI/1dqeyUD+0uzeclZZQdrN956sookWa7ZXN7diu/eUPNIDq4Zeulb1a63YGG2TwwMKoHXq8O2Ipa6BZPpaKhL95Xd0/SpeR9s3mfGe9NX3waKm1+fDzQEEyAmmzlZRsptDH+PSP7yg6rt8VTyWTqLqtdKqFtNu/DVhYQHRt5WVtNoKkMKA31c9TZk3QpeT+b/pSgpbCPe9OA66LuHwti64E3lQHFRLWSjTdJLTP994QlCF1I7AG+CnpQs1EdaeuBN5U5FBO12y7VxM/k3+NS7gdIklo5i5bXXou9V8RWz1gqq7wm1KlWqlch4UqVV6P/HmkWFV0A6mqokkuKbUs56soyzkMJEpInaaRu3Lma+AZq0V3K/QBJ0WjOIq6HNVuFNukOKDXMqELCkYaiRrmU+wGSwqUHtck7K4Nff0xSRtm/vRXLAy8BJYBLJcGmMT4FMM+VBzXb2/DOJ+VtnEvi0tOGaa4NkwOSwIUiHRcKbpxeodg6l8SVp42oOJf7ATznQnOwCzsrzlZ52Z5/Y+t7A/CYxTl3+b5edTy9o+brg+sfVmnz40a+l3dVXjajrQtPGwA8ZLFIx4WdFWcDiu08BttCAKIQ1QRgFwpunA0oLkRb30qCAZOsnPWTcFHmhV3YWSGHAmAa2+WnSRTbPS2GPI53ORQXoi2QRrZGn7vI5CottrywxZ0VZwOKRB4DsMGF8lMXmN6esp0XjoPTAUUSeQwgZmm48dUTxSrNibxwxJzvlAcQL1ujz10SxbG9LnTTR42AAuASabjx1RPFKi0NY4/c3/ICECsKYqLbnkp6XtjZsmEAllkcI2IbbQvhapUNE1AAIAC9OLURUABgplK8SgtDQAEAGFEroFDlBQAwgoACADCCgALmplcFAAACy0lEQVQAMIKAAgAwgoACADCCgAIAMIKAAgAwgoACADCC4ZAA4BmTJ0kavS465QHAPbWChgszxhi9AgCeqBU0/t+uf9O7vvQv1qcgE1AscHVZCsBdYaPzK+3tqmSzyp4/P+21ckeHBrdsjeXI9FoBhRxKRIKeMPK9mxh9DSBU6PHDY2Vlh4cDX5rtSZImEVAikCkOqHNNzyVPGNWT3zrX9KT+cB7ANpd3D8KOH86MXlCltVWZ0dFprzVzkqQpBJQIhD5hlMvKHToQy7IUwHSu7x6EHT9cmduhSnksMKAomx0/r8Ui+lAiEPaE4cKyFEirybsH1c9otlRStlgcDzIBeYu4DXevlLLBt+ZKS1bn/ucLKhcK44l6XVyZFAo6t3e/9Z0PVigRCHvCcGFZCqSVD7sHlcI8ndu7P7Q0+Ez/cSdPkiSgRGC4e6XyvZuCX3RgWQqklS+7B3WDRqFgPfAFIaBEoN4ThgtPEkAaubJ70FBRgKNBIwx9KBdFUvVRLDq5LAXSKqzHI67GQBc63ZtFY2OIJPyCATTG5ufdhYBmAo2NNdAzAqSLzaS2D0UBzUh9QEn6LxhAAEv5CV+KAmYr9X0oSf8FA3BHtSggSBJaClIfUJL+CwbgjrCmxSS0FKQ+KZ+UJBnc4PKMKJ8k+eeYhCIgqrxCJOEXDPt4H5mRip+j5y0FBJR6PP8Fwy5Wumbwc/QDZcP1eNiVCndQLWgGP0e/pT4pD5hAtaAZ/Bz9RkABDKBa0Ax+jn4joAAGJL0cNC78HP1GQAEMqE6YdvXgI1/wc/QbVV6ASVQLmsHP0WmUDQMAjKgVUNjyAgAYQUABABhBQAEAGEFAAQAYQUABABhBQAEAGEFAAQAYQUABABhBQAEAGEFAAQAYQUABABhBQAEAGBE6HBIAgEaxQgEAGEFAAQAYQUABABhBQAEAGEFAAQAYQUABABjx/wEwhzj811dS/wAAAABJRU5ErkJggg==" width="404" height="408" class="img_ev3q"></p></div>Now that we have the overal idea, we have to design an environment object in Python to be fed to a Reinforcement Learning agent. We use the typical design framework inspired from OpenAI Gym:<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">class</span><span class="token plain"> </span><span class="token class-name">DeliveryEnvironment</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">reset</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">&quot;&quot;&quot;Restart the environment for experience replay</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">        Returns the first state</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">        &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">pass</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">step</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">&quot;&quot;&quot;Takes an action in a given state</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">        Returns:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">            s_next: the next state</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">            reward: the reward for such action</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">            done: if the simulation is done</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">        &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">pass</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">render</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">&quot;&quot;&quot;Visualize the environment state</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">        &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">pass</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="designing-the-q-learning-algorithm">Designing the Q-Learning algorithm<a href="#designing-the-q-learning-algorithm" class="hash-link" aria-label="Direct link to Designing the Q-Learning algorithm" title="Direct link to Designing the Q-Learning algorithm">​</a></h3><p>Before jumping into complex Deep Learning, I wondered if a simple <strong>Q-Learning framework would work</strong>. Basically with Q-Learning you want to evaluate a matrix mapping states, actions and rewards. Indeed to make a decision in a given state about the best actions to do, you would love to have an estimate if the decision was the best in the long term. This is represented by the Q values. </p><p>In our case, the rows are the different states (all the stops) and the columns the possible actions to take in this state, hence the next stop to go. The values are the estimated long-term reward you would get by taking this action. So, if you are found in a state A, you would like to take the action with the maximum Q value. </p><p>For our TSP problem for example, we would have a Q-Matrix of 50 by 50 if we have 50 stops. </p><p>Because we want to inform the routing algorithm with as much unbiased data we can find, we can actually initalize the Q matrix (also called Value function because it maps out states and actions to rewards - the values) with the distance matrix between all stops. Indeed, if you would not consider a long-term decision making strategy, you would apply a greedy one where you would chose the closest stop as a next destination. Yet it would definetely be better than random. </p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> scipy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">spatial</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">distance </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> cdist</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Q </span><span class="token operator">=</span><span class="token plain"> cdist</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">xy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">xy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Ok, but how to update those values and incorporate long-term planning? This is exactly the goal of the Q-Learning algorithm.
Imagine you are delivering pizzas every day all across the city, you have an old GPS to help you decide the shortest route between your stops. But your city is much more complicated than what you and your GPS know. What would happen? </p><ul><li>The first day, you would chose the closest stop first and then jump to the next closest one. You will quickly realize that it&#x27;s not optimized. You should maybe have gone first to another neighborhood and deliver everything in the area before jumping to another one. </li><li>So the next day, you commit to another strategy, armed with yesterday&#x27;s experience. Definitely, looking ahead and avoiding single deliveries in remote areas even if they are closest is a better idea. But while you are exploring the best routes, you pass through the city center and get blocked into traffic that terribly slows you down. </li><li>The 3rd day, you will try to apply the same general strategy, but definitely if possible you will never go through the city center, and try circling around the city to save some precious time. </li></ul><p>This <strong>trial-and-error behavior is basically how experience replay works in the Reinforcement Learning framework</strong>. </p><p>If we code an agent abstraction, it could look like this:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">class</span><span class="token plain"> </span><span class="token class-name">QAgent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">Agent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">__init__</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">states_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">actions_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">epsilon </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">1.0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    epsilon_min </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">0.01</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">epsilon_decay </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">0.999</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">gamma </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">0.95</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">lr </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">0.8</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">states_size </span><span class="token operator">=</span><span class="token plain"> states_size</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">actions_size </span><span class="token operator">=</span><span class="token plain"> actions_size</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">epsilon </span><span class="token operator">=</span><span class="token plain"> epsilon</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">epsilon_min </span><span class="token operator">=</span><span class="token plain"> epsilon_min</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">epsilon_decay </span><span class="token operator">=</span><span class="token plain"> epsilon_decay</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">gamma </span><span class="token operator">=</span><span class="token plain"> gamma</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">lr </span><span class="token operator">=</span><span class="token plain"> lr</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">build_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">states_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">actions_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">build_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">states_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">actions_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        Q </span><span class="token operator">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">zeros</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">states_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">actions_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> Q</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">r</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">s_next</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">+</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">lr </span><span class="token operator">*</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">r </span><span class="token operator">+</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">gamma</span><span class="token operator">*</span><span class="token plain">np</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token builtin" style="color:rgb(189, 147, 249)">max</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s_next</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">-</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">epsilon </span><span class="token operator">&gt;</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">epsilon_min</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">epsilon </span><span class="token operator">*=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">epsilon_decay</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">act</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        q </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> np</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">random</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">rand</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">&gt;</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">epsilon</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            a </span><span class="token operator">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">argmax</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">else</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            a </span><span class="token operator">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">random</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">randint</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">actions_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> a</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The most important line is this one:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">+</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">lr </span><span class="token operator">*</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">r </span><span class="token operator">+</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">gamma</span><span class="token operator">*</span><span class="token plain">np</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token builtin" style="color:rgb(189, 147, 249)">max</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s_next</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">-</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This is the update rule in basic Q-Learning, where you increment the Q-value for each action in each experience replay (simulating a day of delivery hundreds of time) by the current reward + the reward for the best possible action you would take in the future. This recursive equation is a variation of the famous Bellman equation for Q value functions. </p><p>Notice two factors: </p><ul><li>The learning rate <code>lr</code> control the learning speed (like in Deep Learning)</li><li>The gamma factor <code>gamma</code> is the discount factor, and control long-term planning. Indeed if gamma = 0, you will only get the next action reward (your agent is &quot;short sighted&quot; only seeking current rewards), if gamma = 1 you will be more oriented towards the future rewards (above 1 it may diverge)</li></ul><p>Those two factors are our most important hyperparameters to tune during training (there are others like the epsilon variables defined in the initialization, if you are curious take a look at epsilon-greedy methods, a super simple way of tackling the exploration-exploitation dilemma in Reinforcement Learning)</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="writing-the-training-loop">Writing the training loop<a href="#writing-the-training-loop" class="hash-link" aria-label="Direct link to Writing the training loop" title="Direct link to Writing the training loop">​</a></h3><p>Once we have define the environment, the Q-Agent and the update rules for the value function, we only need the final step: the training loop. We will apply <strong>experience replay</strong> to our poor delivery guy stucked in an infinite time loop. </p><div align="center"><p><img loading="lazy" src="/assets/images/drstrange-9a522bfeff0b9cdcc50a5ba4c85f8c2f.gif" width="500" height="200" class="img_ev3q"> </p></div><p>Every day, over and over, he will try to deliver our 50 packages, find the best routes and do it all over the next day. In Reinforcement Learning we call each day an <strong>episode</strong>, where we simply:</p><ul><li>Reset the environment</li><li>Make a decision of the next state to go to</li><li>Remember the reward gained by this decision (minimum duration or distance elapsed)</li><li>Train our agent with this knowledge</li><li>Make the next decision until all stops are traversed</li></ul><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">run_episode</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">env</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">agent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">verbose </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    s </span><span class="token operator">=</span><span class="token plain"> env</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reset</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    agent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reset_memory</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    max_step </span><span class="token operator">=</span><span class="token plain"> env</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">n_stops</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    episode_reward </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    i </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">while</span><span class="token plain"> i </span><span class="token operator">&lt;</span><span class="token plain"> max_step</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Remember the states</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        agent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">remember_state</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Choose an action</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        a </span><span class="token operator">=</span><span class="token plain"> agent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">act</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Take the action, and get the reward from environment</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        s_next</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">r</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">done </span><span class="token operator">=</span><span class="token plain"> env</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">step</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Tweak the reward</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        r </span><span class="token operator">=</span><span class="token plain"> </span><span class="token operator">-</span><span class="token number">1</span><span class="token plain"> </span><span class="token operator">*</span><span class="token plain"> r</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> verbose</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">s_next</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">r</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">done</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Update our knowledge in the Q-table</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        agent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">r</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">s_next</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Update the caches</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        episode_reward </span><span class="token operator">+=</span><span class="token plain"> r</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        s </span><span class="token operator">=</span><span class="token plain"> s_next</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># If the episode is terminated</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        i </span><span class="token operator">+=</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> done</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">break</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> env</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">agent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">episode_reward</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="results">Results<a href="#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results">​</a></h2><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="q-learning-for-a-simple-tsp">Q-Learning for a simple TSP<a href="#q-learning-for-a-simple-tsp" class="hash-link" aria-label="Direct link to Q-Learning for a simple TSP" title="Direct link to Q-Learning for a simple TSP">​</a></h3><p>When you start training and experiencing the same problem overtime, your agent learns about the environment, this is shown by the episode rewards values for each experience replay. </p><div align="center"><p><img loading="lazy" src="/assets/images/training-31d61ed9f6a9a6693dd40a6c4dfe151e.png" width="882" height="204" class="img_ev3q"></p></div><ul><li>In the first phase, until the 400th episode, you are still exploring the different routes. Indeed with the epsilon decay method (with <code>epsilon_decay=0.999</code>), you are taking random actions at each step. </li><li>In the second phase, epsilon is lowering, and you start exploiting what you have learnt, and take less and less random actions to be more driven by Q values. </li></ul><p>What&#x27;s tricky with epsilon-greedy methods, is that it kind of forces of the convergence. So did it work? Let&#x27;s see. </p><div align="center"><h5 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="50-stops-experiment">50 stops experiment<a href="#50-stops-experiment" class="hash-link" aria-label="Direct link to 50 stops experiment" title="Direct link to 50 stops experiment">​</a></h5><p><img loading="lazy" src="/assets/images/training_50_stops-f0073a10e627a6f50a17b55a2c32eeac.gif" width="504" height="504" class="img_ev3q"></p><h5 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="100-stops-experiment">100 stops experiment<a href="#100-stops-experiment" class="hash-link" aria-label="Direct link to 100 stops experiment" title="Direct link to 100 stops experiment">​</a></h5><p><img loading="lazy" src="/assets/images/training_100_stops-af172053854703e0125a1b6bf4fe81f8.gif" width="504" height="504" class="img_ev3q"></p><h5 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="500-stops-experiment">500 stops experiment<a href="#500-stops-experiment" class="hash-link" aria-label="Direct link to 500 stops experiment" title="Direct link to 500 stops experiment">​</a></h5><p><img loading="lazy" src="/assets/images/training_500_stops-3529ca589990add491164cb5925bfd81.gif" width="504" height="504" class="img_ev3q"></p></div><p>In each experiment, the algorithm converges quite fast to a seamingly acceptable route. After exploring a lot of options it not only gives one route but variations of the accepted strategy, which can already be interesting to find alternatives. </p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="q-learning-for-a-tsp-with-traffic-zones">Q-Learning for a TSP with traffic zones<a href="#q-learning-for-a-tsp-with-traffic-zones" class="hash-link" aria-label="Direct link to Q-Learning for a TSP with traffic zones" title="Direct link to Q-Learning for a TSP with traffic zones">​</a></h3><p>Now that we have our environment, agent and framework defined, what&#x27;s great with RL is that we don&#x27;t have to change anything but the reward to model a different situation. Indeed because we tweaked the reward when you drove through a traffic zone, the agent will learn the same way to optimize his holistic route. </p><div align="center"><h5 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="100-stops-experiment-with-traffic-zones">100 stops experiment with traffic zones<a href="#100-stops-experiment-with-traffic-zones" class="hash-link" aria-label="Direct link to 100 stops experiment with traffic zones" title="Direct link to 100 stops experiment with traffic zones">​</a></h5><p><img loading="lazy" src="/assets/images/training_100_stops_traffic-2f1b2933055b3023670ec5f1e577afad.gif" width="504" height="504" class="img_ev3q"></p></div><p>Eureka, the agent will avoid as much as possible the traffic zones</p><div align="center"><h5 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="500-stops-experiment-with-traffic-zones">500 stops experiment with traffic zones<a href="#500-stops-experiment-with-traffic-zones" class="hash-link" aria-label="Direct link to 500 stops experiment with traffic zones" title="Direct link to 500 stops experiment with traffic zones">​</a></h5><p><img loading="lazy" src="/assets/images/training_500_stops_traffic-0467ef757724ee8f0377f56c6f8b7b14.gif" width="504" height="504" class="img_ev3q"></p></div><p>With more points, it&#x27;s even more interesting, the agent will really circle around the traffic zone and prefer longer but faster routes. </p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="next-steps">Next steps<a href="#next-steps" class="hash-link" aria-label="Direct link to Next steps" title="Direct link to Next steps">​</a></h2><p>I hope this simple experiment has highlighted how to apply (non-Deep Learning) Reinforcement Learning techniques to real-life problems. I haven&#x27;t had time to benchmark the resolution against other optimization techniques (which I should have done I confess), but let&#x27;s try to draw some pros and cons for the approach. </p><h5 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="-cons">⛔ Cons:<a href="#-cons" class="hash-link" aria-label="Direct link to ⛔ Cons:" title="Direct link to ⛔ Cons:">​</a></h5><ul><li>Probably slower</li><li>Definitely less accurate than a discrete optimization technique</li></ul><h5 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="-pros">✅ Pros:<a href="#-pros" class="hash-link" aria-label="Direct link to ✅ Pros:" title="Direct link to ✅ Pros:">​</a></h5><ul><li>General framework to be updated in real-life situations (eg: the traffic) and extended to more complex problems</li><li>Alternative routes are proposed</li><li>&quot;Online&quot; decision making (meaning that you have an algorithm armed with a next-best decision recommendation system)</li></ul><p>Next steps is to extend the work to an even more global framework to account for multiple vehicle fleets, charging stations and more. The latter idea will require to use Deep Reinforcement Learning because states could not be represented as a matrix, and will probably be more difficult (impossible?) to train, but that&#x27;s a topic for a next article!  </p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="references">References<a href="#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References">​</a></h2><ul><li>All the code is open sourced <a href="https://github.com/TheoLvs/reinforcement-learning/tree/master/5.%20Delivery%20Optimization" target="_blank" rel="noopener noreferrer">here</a> on Github</li><li>OR-Tools <a href="https://developers.google.com/optimization/routing" target="_blank" rel="noopener noreferrer">open source library</a> by Google</li><li>MOOC on <a href="https://www.coursera.org/learn/discrete-optimization" target="_blank" rel="noopener noreferrer">discrete optimization</a> by the University of Melbourne on Coursera</li><li>The timeless <a href="https://www.youtube.com/watch?v=2pWv7GOvuf0&amp;ab_channel=DeepMind" target="_blank" rel="noopener noreferrer">MOOC on Reinforcement Learning</a> by David Silver at Deepmind</li></ul></div></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/reinforcement-learning">Reinforcement Learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/logistics">Logistics</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/introduction-pyepidemics"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Introduction to Pyepidemics - epidemiological modeling in Python</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/dash-deployment"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Deploying a Python Dash application for beginners</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#summary" class="table-of-contents__link toc-highlight">Summary</a></li><li><a href="#the-traveling-salesman-problem" class="table-of-contents__link toc-highlight">The Traveling Salesman Problem</a></li><li><a href="#applying-reinforcement-learning-to-the-tsp" class="table-of-contents__link toc-highlight">Applying Reinforcement Learning to the TSP</a><ul><li><a href="#why-bother-using-reinforcement-learning" class="table-of-contents__link toc-highlight">Why bother using Reinforcement Learning?</a></li><li><a href="#transforming-the-tsp-to-a-rl-problem" class="table-of-contents__link toc-highlight">Transforming the TSP to a RL problem</a></li><li><a href="#creating-the-routing-environment" class="table-of-contents__link toc-highlight">Creating the routing environment</a></li><li><a href="#designing-the-q-learning-algorithm" class="table-of-contents__link toc-highlight">Designing the Q-Learning algorithm</a></li><li><a href="#writing-the-training-loop" class="table-of-contents__link toc-highlight">Writing the training loop</a></li></ul></li><li><a href="#results" class="table-of-contents__link toc-highlight">Results</a><ul><li><a href="#q-learning-for-a-simple-tsp" class="table-of-contents__link toc-highlight">Q-Learning for a simple TSP</a></li><li><a href="#q-learning-for-a-tsp-with-traffic-zones" class="table-of-contents__link toc-highlight">Q-Learning for a TSP with traffic zones</a></li></ul></li><li><a href="#next-steps" class="table-of-contents__link toc-highlight">Next steps</a></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">About us</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://ekimetrics.com/who-we-are/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Who we are ?</a></li><li class="footer__item"><a href="https://ekimetrics.com/our-team/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Our team</a></li><li class="footer__item"><a href="https://ekimetrics.us13.list-manage.com/subscribe?u=85b8ce42caa0a733e98233bc4&amp;id=6355d0a6f9" target="_blank" rel="noopener noreferrer" class="footer__link-item">Subscribe to our newsletter</a></li></ul></div><div class="col footer__col"><div class="footer__title">Find us</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/ekimetrics" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://ekimetrics.com/careers/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Careers<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.welcometothejungle.com/fr/companies/ekimetrics" target="_blank" rel="noopener noreferrer" class="footer__link-item">Eki on Welcome to the jungle<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Contact</div><ul class="footer__items clean-list"><li class="footer__item"><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Get in touch with our teams<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div></div></footer></div>
<script src="/assets/js/runtime~main.0995dcc9.js"></script>
<script src="/assets/js/main.b03e3f5a.js"></script>
</body>
</html>