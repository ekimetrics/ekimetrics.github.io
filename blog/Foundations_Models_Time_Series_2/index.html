<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Foundation models for time series forecasting (2/2) | Eki.Lab</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://ekimetrics.github.io/blog/Foundations_Models_Time_Series_2"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Foundation models for time series forecasting (2/2) | Eki.Lab"><meta data-rh="true" name="description" content="Time series foundation models enhance conformal prediction through higher forecasting accuracy and more stable calibration, especially in low-data scenarios."><meta data-rh="true" property="og:description" content="Time series foundation models enhance conformal prediction through higher forecasting accuracy and more stable calibration, especially in low-data scenarios."><meta data-rh="true" name="keywords" content="Time series,Foundations Models,Generative AI,Conformal Prediction,Zero-shot forecasting"><meta data-rh="true" property="og:image" content="https://ekimetrics.github.io/img/blog/Foundation_Models_2_header.jpg"><meta data-rh="true" name="twitter:image" content="https://ekimetrics.github.io/img/blog/Foundation_Models_2_header.jpg"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2025-10-17T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://www.linkedin.com/in/sami-achour-624358184/,https://www.linkedin.com/in/duong-nguyenn/"><meta data-rh="true" property="article:tag" content="Time series,Foundations Models,Generative AI,Conformal Prediction,Zero-shot forecasting"><link data-rh="true" rel="icon" href="/img/favicon.png"><link data-rh="true" rel="canonical" href="https://ekimetrics.github.io/blog/Foundations_Models_Time_Series_2"><link data-rh="true" rel="alternate" href="https://ekimetrics.github.io/blog/Foundations_Models_Time_Series_2" hreflang="en"><link data-rh="true" rel="alternate" href="https://ekimetrics.github.io/blog/Foundations_Models_Time_Series_2" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Eki.Lab RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Eki.Lab Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-124520099-9","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>




<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-124520099-9"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-124520099-9",{anonymize_ip:!0}),gtag("config","G-MQNYE0E8GE",{anonymize_ip:!0})</script><link rel="stylesheet" href="/assets/css/styles.47419826.css">
<link rel="preload" href="/assets/js/runtime~main.d1e0badd.js" as="script">
<link rel="preload" href="/assets/js/main.bd7b7e3c.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title text--truncate">.</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/publications">Publications</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">About us</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/about">Ekilab</a></li><li><a class="dropdown__link" href="/about/ekimetrics">Ekimetrics</a></li><li><a class="dropdown__link" href="/about/stack">Technology stack</a></li></ul></div><a href="https://www.ekimetrics.com/fr/join-ekimetrics" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Careers</a></div><div class="navbar__items navbar__items--right"><a href="https://ekimetrics.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Ekimetrics website</a><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Contact us!<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="searchBox_ZlJk"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input type="search" id="search_input_react" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><main class="col col--9 col--offset-1" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="image" content="https://ekimetrics.github.io/img/blog/Foundation_Models_2_header.jpg"><header><h1 class="title_f1Hy" itemprop="headline">Foundation models for time series forecasting (2/2)</h1><div class="container_mt6G margin-vert--md"><time datetime="2025-10-17T00:00:00.000Z" itemprop="datePublished">October 17, 2025</time> · <!-- -->11 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/sami-achour-624358184/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/authors/sami_achour.png" alt="Sami ACHOUR"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/sami-achour-624358184/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Sami ACHOUR</span></a></div><small class="avatar__subtitle" itemprop="description">Consultant</small></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/duong-nguyenn/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/authors/duong_nguyen.jpg" alt="Duong NGUYEN"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/duong-nguyenn/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Duong NGUYEN</span></a></div><small class="avatar__subtitle" itemprop="description">Time Series Specialist</small></div></div></div></div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><div align="justify"><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="application-of-foundation-models-in-conformal-prediction">Application of foundation models in conformal prediction<a href="#application-of-foundation-models-in-conformal-prediction" class="hash-link" aria-label="Direct link to Application of foundation models in conformal prediction" title="Direct link to Application of foundation models in conformal prediction">​</a></h2><p>In our <a href="https://ekimetrics.github.io/blog/Foundations_Models_Time_Series_1/" target="_blank" rel="noopener noreferrer">previous blog post</a>, we saw that foundation models offer a powerful alternative for time series forecasting, boosting accuracy and reliability across diverse applications.</p><p>In this article, we investigate a novel application of foundation models (FMs) in the field of time series forecasting - specifically, their integration with Conformal Prediction (CP) for uncertainty quantification. CP, introduced in 2007, is a powerful statistical framework that generates predictive intervals with a user-defined confidence level. These intervals are designed to contain the true values a specified proportion of the time (e.g., 90%), based on model calibration using a separate dataset.</p><p>While CP offers robust uncertainty estimates, its reliance on a separate calibration set in addition to the traditional training and testing sets can be a drawback, especially when data is limited. This requirement often forces a trade-off between model training and calibration accuracy. However, the zero-shot capabilities of foundation models (FMs) for time series forecasting present a promising opportunity for conformal prediction, as they allow most of the available data to be dedicated to calibration rather than training.</p><p>This study evaluates the performance of Time Series Foundation Models (TSFMs) against traditional approaches, including statistical models and gradient boosting methods, within a conformal prediction framework. Our results reveal two main advantages of TSFMs. First, in low-data scenarios, TSFMs produce more reliable conformalized prediction intervals due to their superior forecasting accuracy. Second, the calibration process becomes more stable because a larger portion of the data can be used for it. These benefits become even more significant as data availability decreases, since traditional models require a substantial amount of data for effective training. Overall, the findings highlight the strong potential of foundation models to enhance the reliability of conformal prediction in time series applications, particularly when data is limited.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="conformal-prediction">Conformal prediction<a href="#conformal-prediction" class="hash-link" aria-label="Direct link to Conformal prediction" title="Direct link to Conformal prediction">​</a></h2><p>Conformal Prediction represents a highly effective statistical approach for quantifying uncertainty that can be applied to any forecasting model. It leverages a subset of historical data - known as the calibration set - to compute a conformity score, which evaluates how well the model&#x27;s predictions align with observed outcomes. This score is then used to construct prediction intervals that adapt to the underlying data distribution. </p><p>In time series forecasting, CP offers a reliable way to generate prediction intervals with a specified confidence level over time.
There are several methods for constructing conformalized prediction intervals for time series forecasting, including Split Conformal Prediction (SCP), Adaptive Conformal Inference (ACI), and Ensemble Batch Prediction Intervals (EnbPI). These approaches differ primarily in how they handle the temporal dependencies inherent in sequential data when forming the calibration set. In this work, we adopt SCP due to its simplicity, computational efficiency, and broad applicability.</p><p>Given a user-defined miscoverage parameter α∈<!-- -->[0,1]<!-- --> and N data points, SCP constructs the predictions intervals that cover the true values at least ((1-α)  ×100)% of the time over the prediction horizon, using the following procedure:</p><ol><li>Split N available data points into two subsets: a training set and a calibration set.</li><li>The model is first trained on the training set. </li><li>After training, the model is applied to the calibration set to generate predictions and compute absolute errors at each time step, forming a distribution of residuals—known as conformity scores—for uncertainty quantification.</li><li>To quantify uncertainty, SCP selects an upper quantile of the residual distribution—corresponding to the desired miscoverage rate (e.g., the 90th percentile for 10% miscoverage)—and uses this value to construct symmetric prediction intervals around future forecasts.</li></ol><p>This results in intervals that are expected to contain the true value with the specified confidence level, assuming the calibration residuals are representative of future errors.</p><p><em>Note: In time series forecasting, SCP faces a key challenge: the assumption of data exchangeability (i.e., that data points are independent and identically distributed) is often violated due to temporal dependencies. This can affect the validity of the coverage guarantees.</em></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="experiments-and-results">Experiments and Results<a href="#experiments-and-results" class="hash-link" aria-label="Direct link to Experiments and Results" title="Direct link to Experiments and Results">​</a></h2><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="datasets">Datasets<a href="#datasets" class="hash-link" aria-label="Direct link to Datasets" title="Direct link to Datasets">​</a></h3><p>In this study, we used the ERCOT, NN5 Daily, NN5 Weekly, and M3 Monthly datasets as benchmarks. These datasets span different temporal granularities to ensure that the results accurately reflect industry-relevant contexts. We conducted experiments across three forecasting horizons: Short (S), Medium (M), and Long (L), with lengths varying by dataset. The details are provided in the table below.</p></div><div align="center"><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/Foundation_Models_2_Tab1-4626928a2218c331f16fa4ef5b795ee0.png" width="580" height="184" class="img_ev3q"></p><p>  Dataset description</p></div><div align="justify"><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="estimators">Estimators<a href="#estimators" class="hash-link" aria-label="Direct link to Estimators" title="Direct link to Estimators">​</a></h3><p>We evaluated three TSFM candidates: Amazon Chronos, Google TimesFM and Lag-Llama, against various TS forecasting methods, including the Naive method, Seasonal Naive method, LightGBM (LGBM), and a light version of StatisticalEnsemble. We selected Chronos, TimesFM, and Lag-Llama because they were not present in our benchmark data, enabling zero-shot evaluation. Chronos and TimesFM were chosen for their strong performance and frequent citations, while Lag-Llama’s smaller size allows us to explore size-performance trade-offs. For Chronos and TimesFM, we tested both the original versions, dubbed as Chronos and TimesFM, and the more recent ones, dubbed as Chronos Bolt and TimesFM2, respectively. We show later in this article that during just a short period, Chronos and TimesFM have improved their performance significantly with the updates. LGBM was selected as a representative of the Gradient Boosted Decision Trees (GBDT) family. StatisticalEnsemble is an ensemble of statistical models, consisting of the mean of forecasts from AutoARIMA, AutoETS, AutoCES, and DynamicOptimizedTheta. These models were chosen for their good performances in the M4 competition. However, due to its high computational complexity, AutoARIMA is not used in this study.</p></div><div align="center"><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/Foundation_Models_2_Tab2-891eb32360d257f17d93c3621d074f8f.png" width="601" height="274" class="img_ev3q"></p><p>  TSFMs setup description</p></div><div align="justify"><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="metrics">Metrics<a href="#metrics" class="hash-link" aria-label="Direct link to Metrics" title="Direct link to Metrics">​</a></h3><p>To assess the performance of forecasting models, three key metrics were used, offering a balanced view of each model’s accuracy, reliability, and precision in both forecasting and uncertainty quantification.</p><ul><li>Mean Coverage Rate (MCR)
This measures how often the true values fall within the model’s prediction intervals. It reflects the reliability of the uncertainty estimates. A good model should have an MCR close to the target confidence level (e.g., 90% for a 10% miscoverage rate).</li><li>Mean Scaled Interval Width (MSIW)
This evaluates how wide the prediction intervals are, relative to a naive baseline. Narrower intervals are better, as long as they still capture the true values. MSIW helps assess the precision of the model’s uncertainty estimates.</li><li>Mean Absolute Scaled Error (MASE)
This measures the accuracy of the point forecasts, scaled against a naive model. A lower MASE indicates better predictive performance.</li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="results-on-ercot">Results on ERCOT<a href="#results-on-ercot" class="hash-link" aria-label="Direct link to Results on ERCOT" title="Direct link to Results on ERCOT">​</a></h3><p>The ERCOT dataset, which contains hourly electricity demand data, was used to evaluate model performance under slightly more extensive and slightly more constrained data conditions. Two experimental setups were tested:</p><ul><li><strong>Scenario 1</strong>: 8760 data points (1 year of hourly data)</li><li><strong>Scenario 2</strong>: 2232 data points (about 3 months of data)</li></ul><p>In both scenarios, 20 windows were sampled from the historical data to simulate repeated forecasting conditions. Each model was evaluated across all windows to ensure robust and consistent results, with final performance metrics computed as the average over these runs. Additionally, each scenario was tested across three forecasting horizons: short (1 day), medium (3 days), and long (7 days).</p><p>Results in terms of MCR, MSIW, and MASE are shown in the figures below:</p></div><div align="center"><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/Foundation_Models_Chart_Ercot_8760-92fdf61bc2b524ecdfb38aaf569e8fd1.png" width="602" height="236" class="img_ev3q"></p><p>  Split conformal prediction results on ERCOT 8760 – Horizon S</p><br><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/Foundation_Models_Chart_Ercot_2232-3fddc027a2b960e00a0af3fa00a61736.png" width="602" height="236" class="img_ev3q"></p><p>  Split conformal prediction results on ERCOT 2232 – Horizon S</p><br></div><div align="justify"><p>The results clearly show that Time Series Foundation Models (TSFMs) such as Chronos, Chronos-Bolt, TimesFM, and TimesFM2 consistently outperformed traditional models like LightGBM and StatisticalEnsemble_light. This was particularly evident in the low-data scenario (ERCOT-2232), where TSFMs showed less dependence on training data volume and leveraged their zero-shot capabilities to prioritize calibration. This flexibility allowed them to produce more reliable and sharper prediction intervals, even when data was scarce.</p><p>In contrast, traditional models struggled with the trade-off between training and calibration data. LGBM_80_20, for instance, showed very good performance when more data was available for training, but its accuracy and interval quality deteriorated significantly in the 2232-point scenario. This effect is amplified by the need to generate lag features, which are essential for tabular models but reduce the effective training size.</p><p>The study also highlighted a key trade-off in conformal prediction: achieving high coverage often comes at the cost of wider intervals. Some models, like Seasonal Naive and certain LightGBM configurations, met the target coverage but did so by producing overly conservative intervals. These intervals, while technically valid, were too wide to be practically useful. On the other hand, TSFMs occasionally fell slightly short of the target coverage but offered much narrower and more informative intervals, making them more valuable in operational settings.</p><p>Among the TSFMs, Chronos-Bolt and TimesFM2 stood out as the most balanced models. They consistently delivered strong point forecast accuracy, maintained competitive interval widths, and achieved coverage rates close to or above the target. Their performance was particularly impressive in the low-data, short-horizon setting, where Chronos-Bolt achieved the best overall results.</p><p>Overall, the ERCOT experiments demonstrate that TSFMs are not only more robust in data-constrained environments but also more effective at balancing the competing demands of accuracy and reliability in conformal prediction. </p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="results-on-nn5-daily-nn5-weekly-and-m3-monthly">Results on NN5 Daily, NN5 Weekly and M3 Monthly<a href="#results-on-nn5-daily-nn5-weekly-and-m3-monthly" class="hash-link" aria-label="Direct link to Results on NN5 Daily, NN5 Weekly and M3 Monthly" title="Direct link to Results on NN5 Daily, NN5 Weekly and M3 Monthly">​</a></h3><p>The first experiment evaluated the performance of our models on an univariate timeseries dataset. Subsequently, we aimed to compare their effectiveness on multivariate time series notably because, in the multivariate context, the number of available data points is determined not only by the number of available time steps but also by the number of available series. In this section, we present the benchmarking results on three multivariate datasets: NN5 Daily, NN5 Weekly, and M3 Monthly. Here, the results were aggregated over all time series in each dataset, rather than over 20 sample windows as in the ERCOT experiment described in the previous section.</p><p>Results in terms of MCR, MSIW, and MASE are shown in the figures below:</p></div><div align="center"><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/Foundation_Models_Chart_NN5Daily-b3852b65ef473c8022f8ef0a86a77a29.png" width="602" height="236" class="img_ev3q"></p><p>  Split conformal prediction results on NN5 Daily – Horizon S</p><br><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/Foundation_Models_Chart_NN5Weekly-f19a365cb9b20cbad83a7d5eff875a66.png" width="602" height="236" class="img_ev3q"></p><p>  Split conformal prediction results on NN5 Weekly – Horizon S</p><br><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/Foundation_Models_Chart_NN5Monthly-f22abd57de7af7511db04dbefcc63fc6.png" width="602" height="236" class="img_ev3q"></p><p>  Split conformal prediction results on M3 Monthly – Horizon S</p><br></div><div align="justify"><p>The performance gap between TSFMs and other models was less pronounced here. A positive correlation was observed between MASE and MSIW, suggesting that models with more accurate predictions also produced narrower prediction intervals.</p><p>Chronos, ChronosBolt, TimesFM, and TimesFM2 consistently ranked among the top performers. For instance, in the NN5-daily-S setting, TimesFM2 achieved the best MASE and MSIW while maintaining the target coverage rate. LGBM models occasionally matched TSFMs but generally struggled due to limited training data and lack of exogenous variables. StatisticalEnsemble_light also performed well. Lag-Llama and SeasonalNaive showed inconsistent results.</p><p><em>Note: The quality of uncertainty quantification varied across datasets due to differences in data frequency. Smaller calibration sets led to imprecise estimation of coverage thresholds, impacting model performance.</em></p><p>In the NN5 Daily dataset, ChronosBolt led the performance, followed by TimesFM2, TimesFM, Chronos, and StatisticalEnsemble_light. LGBM models failed to adapt prediction intervals effectively, and Lag-Llama underperformed.</p><p>For NN5 Weekly, TimesFM and TimesFM2 delivered strong results with consistent coverage and top MASE and MSIW. LGBM models again struggled due to limited calibration data.</p><p>In the M3 Monthly dataset, StatisticalEnsemble_light, TimesFM, and Chronos-based models performed best, followed by SeasonalNaive. LGBM and Lag-Llama models performed poorly. The similarity in performance across LGBM variants was attributed to the low size of the calibration set, which hindered accurate error estimation and reduced coverage rates.</p><p>Overall, model accuracy declined at higher levels of granularity, particularly in the NN5 Weekly and M3 Monthly datasets. The conclusions remain consistent across different horizons, which enhances the robustness of the insights derived above.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="discussions-and-future-works">Discussions and future works<a href="#discussions-and-future-works" class="hash-link" aria-label="Direct link to Discussions and future works" title="Direct link to Discussions and future works">​</a></h2><p>This <a href="https://arxiv.org/pdf/2507.08858" target="_blank" rel="noopener noreferrer">paper</a> introduces time series foundation models (TSFMs) into the conformal prediction framework and evaluates their effectiveness compared to traditional statistical and gradient boosting methods.</p><p>The results show that:</p><ul><li>TSFMs, particularly TimesFM and the Chronos family, consistently outperform traditional approaches, especially in data-scarce scenarios. One key advantage is that TSFMs require data only for context rather than training, which allows more data to be allocated for calibration. This is particularly beneficial in conformal prediction, where the trade-off between training and calibration data could be critical.</li><li>Larger TSFMs tend to perform better, indicating that these models have not yet reached the limits of scaling. </li><li>Despite their size, optimized models like Chronos Bolt offer inference speeds that are at least on par with, if not better than, traditional statistical models.</li></ul><p>In the near future, it would be beneficial to conduct these tests on a broader range of datasets to enhance the robustness of the results and to gauge if there are performance differences in specific application domains. Regarding TSFMs, it would be valuable to include other methods that have proven their accuracy in prediction within this benchmark. Additionally, varying the amount of data allocated to context and calibration would be interesting to quantify the difficulty presented by this trade-off more precisely. For conformal prediction, other CP methods more suited to time series could be considered.</p></div></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/time-series">Time series</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/foundations-models">Foundations Models</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/generative-ai">Generative AI</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/conformal-prediction">Conformal Prediction</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/zero-shot-forecasting">Zero-shot forecasting</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/Wombat_HR_v2"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Retrieval Augmented Generation (RAG): Optimisation &amp; evaluation techniques</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/Foundations_Models_Time_Series_1"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Foundation models for time series forecasting (1/2)</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#application-of-foundation-models-in-conformal-prediction" class="table-of-contents__link toc-highlight">Application of foundation models in conformal prediction</a></li><li><a href="#conformal-prediction" class="table-of-contents__link toc-highlight">Conformal prediction</a></li><li><a href="#experiments-and-results" class="table-of-contents__link toc-highlight">Experiments and Results</a><ul><li><a href="#datasets" class="table-of-contents__link toc-highlight">Datasets</a></li><li><a href="#estimators" class="table-of-contents__link toc-highlight">Estimators</a></li><li><a href="#metrics" class="table-of-contents__link toc-highlight">Metrics</a></li><li><a href="#results-on-ercot" class="table-of-contents__link toc-highlight">Results on ERCOT</a></li><li><a href="#results-on-nn5-daily-nn5-weekly-and-m3-monthly" class="table-of-contents__link toc-highlight">Results on NN5 Daily, NN5 Weekly and M3 Monthly</a></li></ul></li><li><a href="#discussions-and-future-works" class="table-of-contents__link toc-highlight">Discussions and future works</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">About us</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://ekimetrics.com/who-we-are/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Who we are ?</a></li><li class="footer__item"><a href="https://ekimetrics.com/our-team/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Our team</a></li><li class="footer__item"><a href="https://ekimetrics.us13.list-manage.com/subscribe?u=85b8ce42caa0a733e98233bc4&amp;id=6355d0a6f9" target="_blank" rel="noopener noreferrer" class="footer__link-item">Subscribe to our newsletter</a></li></ul></div><div class="col footer__col"><div class="footer__title">Find us</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/ekimetrics" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://ekimetrics.com/careers/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Careers<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.welcometothejungle.com/fr/companies/ekimetrics" target="_blank" rel="noopener noreferrer" class="footer__link-item">Eki on Welcome to the jungle<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Contact</div><ul class="footer__items clean-list"><li class="footer__item"><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Get in touch with our teams<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div></div></footer></div>
<script src="/assets/js/runtime~main.d1e0badd.js"></script>
<script src="/assets/js/main.bd7b7e3c.js"></script>
</body>
</html>