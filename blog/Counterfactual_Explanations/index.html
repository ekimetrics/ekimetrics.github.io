<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Counterfactual Explanations: Enhancing Machine Learning Transparency and Delivering Actionable Insights | Eki.Lab</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://ekimetrics.github.io/blog/Counterfactual_Explanations"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Counterfactual Explanations: Enhancing Machine Learning Transparency and Delivering Actionable Insights | Eki.Lab"><meta data-rh="true" name="description" content="Discover what counterfactual explanations are and how illustrating changes that lead to different model outcomes enhances transparency, fairness, and actionable decision-making in machine learning."><meta data-rh="true" property="og:description" content="Discover what counterfactual explanations are and how illustrating changes that lead to different model outcomes enhances transparency, fairness, and actionable decision-making in machine learning."><meta data-rh="true" name="keywords" content="XAI,Explainability,Interpretability,Machine learning,Data science,Deep learning,Innovation,Transparency,AI,Model optimisation,Fairness,,Actionability,Code"><meta data-rh="true" property="og:image" content="https://ekimetrics.github.io/img/blog/Counterfactual_header.jpg"><meta data-rh="true" name="twitter:image" content="https://ekimetrics.github.io/img/blog/Counterfactual_header.jpg"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2025-04-16T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://www.linkedin.com/in/benjamin-wong-62a5b7189/,https://www.linkedin.com/in/milan-bhan-43133a102/"><meta data-rh="true" property="article:tag" content="XAI,explainability,Machine Learning,Counterfactuals"><link data-rh="true" rel="icon" href="/img/favicon.png"><link data-rh="true" rel="canonical" href="https://ekimetrics.github.io/blog/Counterfactual_Explanations"><link data-rh="true" rel="alternate" href="https://ekimetrics.github.io/blog/Counterfactual_Explanations" hreflang="en"><link data-rh="true" rel="alternate" href="https://ekimetrics.github.io/blog/Counterfactual_Explanations" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Eki.Lab RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Eki.Lab Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-124520099-9","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>




<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-124520099-9"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-124520099-9",{anonymize_ip:!0}),gtag("config","G-MQNYE0E8GE",{anonymize_ip:!0})</script><link rel="stylesheet" href="/assets/css/styles.bd97f456.css">
<link rel="preload" href="/assets/js/runtime~main.fa7e58fa.js" as="script">
<link rel="preload" href="/assets/js/main.2fca948b.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title text--truncate">.</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">About us</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/about">Ekilab</a></li><li><a class="dropdown__link" href="/about/ekimetrics">Ekimetrics</a></li><li><a class="dropdown__link" href="/about/stack">Technology stack</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Resources</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/resources/">Hackathons</a></li><li><a class="dropdown__link" href="/resources/trainings">Trainings</a></li></ul></div><a href="https://www.ekimetrics.com/fr/join-ekimetrics" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Careers</a></div><div class="navbar__items navbar__items--right"><a href="https://ekimetrics.com/fr/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Ekimetrics website</a><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Contact us!<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="searchBox_ZlJk"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input type="search" id="search_input_react" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><main class="col col--9 col--offset-1" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="image" content="https://ekimetrics.github.io/img/blog/Counterfactual_header.jpg"><header><h1 class="title_f1Hy" itemprop="headline">Counterfactual Explanations: Enhancing Machine Learning Transparency and Delivering Actionable Insights</h1><div class="container_mt6G margin-vert--md"><time datetime="2025-04-16T00:00:00.000Z" itemprop="datePublished">April 16, 2025</time> · <!-- -->11 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/benjamin-wong-62a5b7189/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Benjamin Wong</span></a></div><small class="avatar__subtitle" itemprop="description">Senior Consultant</small></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/milan-bhan-43133a102/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/authors/milan.bhan.png" alt="Milan Bhan"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/milan-bhan-43133a102/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Milan Bhan</span></a></div><small class="avatar__subtitle" itemprop="description">Domain Specialist</small></div></div></div></div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><div align="justify"><p>Counterfactual explanations are transforming how we interpret machine learning models by answering critical &#x27;what-if&#x27; questions. Instead of simply revealing why a model made a particular decision, counterfactuals show how to change the outcome, bridging the gap between algorithmic decisions and human understanding.<br>
<!-- -->In this article, we explore what counterfactuals explanations are, why they matter, how they can be generated, and their future role in explainable AI (XAI).</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="i-what-is-a-counterfactual-explanation-in-machine-learning">I. What is a Counterfactual Explanation in Machine Learning?<a href="#i-what-is-a-counterfactual-explanation-in-machine-learning" class="hash-link" aria-label="Direct link to I. What is a Counterfactual Explanation in Machine Learning?" title="Direct link to I. What is a Counterfactual Explanation in Machine Learning?">​</a></h2><p>Counterfactual explanations (or simply counterfactuals) describe how modifying specific input features could lead to a different model outcome. They provide minimal, actionable changes that would flip a prediction. They can be generated for both classification and regression problems. In the literature, the majority of studies have focused on classification problems, where counterfactuals suggest feature modifications to change a categorical outcome. Regression-based counterfactuals are now gaining more attention while facing specific issues related to continuous variable outcomes.</p><p>Examples of Counterfactuals:</p><ul><li><p><strong>Classification Example (Loan Approval)</strong>: If a model predicts that a loan application is denied, a counterfactual might suggest that increasing the applicant’s income by $10,000 or reducing their existing debt by $5,000 could change the outcome to approved.</p></li><li><p><strong>Regression Example (House Price Prediction)</strong>: If a model estimates a house&#x27;s value at $300,000, a counterfactual might suggest that increasing the lot size by 500 square feet or adding an extra bedroom could raise the predicted price to $350,000.</p></li></ul><p>Unlike traditional interpretability techniques which highlight which features most influence a prediction, counterfactuals focus on how to change the outcome. Feature importance methods can be categorized into global and local approaches: global feature importance (e.g., Gini index) assesses the overall impact of each feature on the model across all predictions, while local feature importance (e.g., SHAP) explains the contribution of features to a specific instance’s prediction. Counterfactuals, in contrast, provide instance-specific insights by suggesting changes needed to obtain a different outcome.</p><p>For example:</p><ul><li>Global feature importance tells us that income and credit score are the most important factors in a loan decision in general, not for a specific instance.</li><li>SHAP quantifies how much each feature contributed to the final prediction.</li><li>Counterfactuals go a step further by suggesting precise changes, such as increasing income by $10,000 to get the loan approved.</li></ul><p>This focus on actionability makes counterfactual explanations particularly valuable when users need clear next steps, rather than just a breakdown of feature contributions.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="ii-why-counterfactuals-matter-in-machine-learning">II. Why Counterfactuals Matter in Machine Learning<a href="#ii-why-counterfactuals-matter-in-machine-learning" class="hash-link" aria-label="Direct link to II. Why Counterfactuals Matter in Machine Learning" title="Direct link to II. Why Counterfactuals Matter in Machine Learning">​</a></h2><p>Counterfactual explanations can enhance AI transparency and fairness by addressing several key challenges:</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="actionable-insights">Actionable Insights<a href="#actionable-insights" class="hash-link" aria-label="Direct link to Actionable Insights" title="Direct link to Actionable Insights">​</a></h4><p>As mentioned, unlike traditional explainability methods that only highlight influential features, counterfactuals provide clear, practical steps to achieve a desired outcome. Instead of just showing that income is important for loan approval, counterfactuals tell users exactly how much income needs to increase for approval.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="trust-and-compliance">Trust and Compliance<a href="#trust-and-compliance" class="hash-link" aria-label="Direct link to Trust and Compliance" title="Direct link to Trust and Compliance">​</a></h4><p>As AI systems play a growing role in decision-making, <a href="https://dl.acm.org/doi/10.1145/3593013.3594069" target="_blank" rel="noopener noreferrer">regulations require that automated decisions be explainable and fair</a>. Counterfactuals help organizations justify decisions by demonstrating the exact changes that would have led to a different outcome.</p><p>This improves:</p><ul><li><strong>Transparency</strong> – Users understand why they received a particular decision.</li><li><strong>Fairness</strong> – Decision-making processes become more accountable.</li><li><strong>Trust</strong> – People are more likely to accept AI-driven outcomes if they can see how decisions are made.</li></ul><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="model-debugging-and-bias-detection">Model Debugging and Bias Detection<a href="#model-debugging-and-bias-detection" class="hash-link" aria-label="Direct link to Model Debugging and Bias Detection" title="Direct link to Model Debugging and Bias Detection">​</a></h4><p>Counterfactuals also help developers detect biases in machine learning models.
For example, if certain demographic groups need unrealistically high increases in income to get loan approvals, this may indicate a hidden bias in the model. By analyzing these patterns, developers can:</p><ul><li>Identify fairness issues</li><li>Refine the model to reduce bias</li><li>Improve model reliability and robustness</li></ul><p>By providing actionable recommendations, ensuring regulatory compliance, and improving model fairness, counterfactual explanations are essential for building trustworthy AI systems.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="iii-generating-counterfactuals-dice-and-mace">III. Generating Counterfactuals: DiCE and MACE<a href="#iii-generating-counterfactuals-dice-and-mace" class="hash-link" aria-label="Direct link to III. Generating Counterfactuals: DiCE and MACE" title="Direct link to III. Generating Counterfactuals: DiCE and MACE">​</a></h2><p>Counterfactual generation is a key step in understanding and improving machine learning models. Two widely used methods for generating counterfactuals are DiCE (Diverse Counterfactual Explanations) and MACE (Model-Agnostic Counterfactual Explanations with Constraints).</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="dice-diverse-counterfactual-explanations">DiCE (Diverse Counterfactual Explanations)<a href="#dice-diverse-counterfactual-explanations" class="hash-link" aria-label="Direct link to DiCE (Diverse Counterfactual Explanations)" title="Direct link to DiCE (Diverse Counterfactual Explanations)">​</a></h4><p><a href="https://arxiv.org/pdf/1905.07697" target="_blank" rel="noopener noreferrer">DiCE</a>, developed by Microsoft Research, is a powerful tool for generating diverse counterfactual explanations in machine learning. Unlike traditional counterfactual methods that focus on finding a single optimal explanation, DiCE emphasizes the importance of providing multiple, diverse alternatives.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="key-features-of-dice">Key Features of DiCE:<a href="#key-features-of-dice" class="hash-link" aria-label="Direct link to Key Features of DiCE:" title="Direct link to Key Features of DiCE:">​</a></h4><ol><li>Model-Agnostic Approach: DiCE can work with any black-box model, making it versatile across different machine learning architectures.</li><li>Diversity in Explanations: It generates a set of counterfactuals that are meaningfully different from each other, offering a broader perspective on possible changes.</li><li>Customizable Constraints: Users can specify feature ranges and immutability, ensuring the generated counterfactuals are realistic and actionable.</li><li>Multiple Generation Methods: DiCE employs various techniques including genetic algorithms, random sampling, and KD-tree search to efficiently explore the feature space.</li><li>Scalability: It&#x27;s designed to handle large datasets and complex models efficiently.</li></ol><p>DiCE solves a key limitation of single-counterfactual methods by offering multiple alternative solutions, which is especially useful when there are different ways to achieve the same outcome. This variety not only helps users explore more actionable options but also provides a clearer picture of the model’s decision boundaries.
That said, while DiCE is a major step forward in explainable AI, it isn’t perfect without the right constraints, it can sometimes suggest unrealistic changes. That’s why domain expertise is essential for setting meaningful boundaries and making sense of the results.</p><p>To better understand how DiCE works in practice, here is an example in Python demonstrating how to generate counterfactual explanations using a trained machine learning model:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> dice_ml </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> dice_ml </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> Dice</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Initialize a DiCE explainer with dataset details and model constraints</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">d </span><span class="token operator">=</span><span class="token plain"> dice_ml</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Data</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">dataframe</span><span class="token operator">=</span><span class="token plain">X_train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                 continuous_features</span><span class="token operator">=</span><span class="token plain">numerical_features</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                 outcome_name</span><span class="token operator">=</span><span class="token plain">target</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                 permitted_range</span><span class="token operator">=</span><span class="token plain">permitted_ranges</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Wrap the trained model for use with DiCE</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">m </span><span class="token operator">=</span><span class="token plain"> dice_ml</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">model</span><span class="token operator">=</span><span class="token plain">model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> backend</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;sklearn&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Create a DiCE explainer instance</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">exp </span><span class="token operator">=</span><span class="token plain"> Dice</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">d</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> m</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Select a single test instance (excluding the target column)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">query_instance </span><span class="token operator">=</span><span class="token plain"> X_test</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">drop</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">columns</span><span class="token operator">=</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">target</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">iloc</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Generate counterfactual explanations for the selected instance</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">counterfactuals </span><span class="token operator">=</span><span class="token plain"> exp</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">generate_counterfactuals</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">query_instance</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                                               total_CFs</span><span class="token operator">=</span><span class="token number">5</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Number of counterfactual examples to generate</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                                               desired_class</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;opposite&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Flip the predicted class</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                                               features_to_vary</span><span class="token operator">=</span><span class="token plain">actionable_features</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Features allowed to change</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Display counterfactuals, showing only feature differences</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">counterfactuals</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">visualize_as_dataframe</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">show_only_changes</span><span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><br><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="mace-model-agnostic-counterfactual-explanations-with-constraints">MACE (Model-Agnostic Counterfactual Explanations with Constraints)<a href="#mace-model-agnostic-counterfactual-explanations-with-constraints" class="hash-link" aria-label="Direct link to MACE (Model-Agnostic Counterfactual Explanations with Constraints)" title="Direct link to MACE (Model-Agnostic Counterfactual Explanations with Constraints)">​</a></h4><p><a href="https://arxiv.org/pdf/2205.15540" target="_blank" rel="noopener noreferrer">MACE (Model-Agnostic Counterfactual Explanations)</a> is an advanced approach to generating counterfactual explanations in machine learning, with a primary focus on ensuring the realism and feasibility of the generated explanations.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="key-features-of-mace">Key features of MACE<a href="#key-features-of-mace" class="hash-link" aria-label="Direct link to Key features of MACE" title="Direct link to Key features of MACE">​</a></h4><ol><li>Constraint Integration: MACE incorporates domain-specific constraints directly into the counterfactual generation process. This ensures that all suggested changes are not only mathematically valid but also practically feasible and logically consistent.</li><li>Model Agnosticism: Like other counterfactual methods, MACE can work with any type of machine learning model, making it versatile across different applications and model architectures.</li><li>Plausibility Enforcement: MACE prevents the generation of impossible or unrealistic counterfactuals. For instance, it won&#x27;t suggest changes like reducing age or altering immutable characteristics.</li><li>Customizable Rules: Users can define specific constraints tailored to their domain, allowing for fine-grained control over what types of changes are considered acceptable.</li><li>Handling Complex Data Types: MACE is designed to work effectively with both numerical and categorical features, addressing the challenges posed by mixed data types in real-world datasets.</li></ol><p>MACE stands out for its ability to generate realistic and actionable explanations. However, this realism comes at a cost. MACE is more computationally intensive than simpler counterfactual methods because it solves complex optimization problems with constraints.
Despite this, MACE has proven highly valuable in situations where explanation credibility and regulatory compliance matter most.
That said, the quality of MACE’s explanations still depends on well-defined constraints and high-quality data. Without these, even the most advanced counterfactual method can produce misleading or unhelpful results.</p><p>To better understand how MACE works in practice, here is an example in Python demonstrating how to generate counterfactual explanations using a trained machine learning model:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> omnixai</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">data</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">tabular </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> Tabular</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> omnixai</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">preprocessing</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">tabular </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> TabularTransform</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> omnixai</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">explainers</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">tabular </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> MACEExplainer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Load the dataset into an OmnixAI Tabular object</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">tabular_data </span><span class="token operator">=</span><span class="token plain"> Tabular</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">df</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    feature_columns</span><span class="token operator">=</span><span class="token plain">feature_names</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># List of feature column names</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    categorical_columns</span><span class="token operator">=</span><span class="token plain">categorical_features</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Specify categorical features</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    target_column</span><span class="token operator">=</span><span class="token plain">target  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Specify the target variable</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Fit a tabular transformer for preprocessing (e.g., encoding, scaling)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">transformer </span><span class="token operator">=</span><span class="token plain"> TabularTransform</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">fit</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">tabular_data</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">class_names </span><span class="token operator">=</span><span class="token plain"> transformer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">class_names  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Get class labels from the transformer</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Define a prediction function that applies the model after transformation</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">predict_function </span><span class="token operator">=</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">lambda</span><span class="token plain"> z</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">predict_proba</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">transformer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">transform</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">z</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Initialize the MACE counterfactual explainer</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">maceexplainer </span><span class="token operator">=</span><span class="token plain"> MACEExplainer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    training_data</span><span class="token operator">=</span><span class="token plain">tabular_data</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Provide the training dataset</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    predict_function</span><span class="token operator">=</span><span class="token plain">predict_function</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Use the defined prediction function</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ignored_features</span><span class="token operator">=</span><span class="token plain">features_to_ignore  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Specify features that should not be modified</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Select test instances (excluding the target column) for explanation</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">test_instances </span><span class="token operator">=</span><span class="token plain"> tabular_data</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">remove_target_column</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token number">5</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Generate counterfactual explanations for the selected test instances</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">explanations </span><span class="token operator">=</span><span class="token plain"> maceexplainer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">explain</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">test_instances</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Visualize the counterfactual explanation for the first test instance</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">explanations</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">ipython_plot</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">index</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> class_names</span><span class="token operator">=</span><span class="token plain">class_names</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="example-of-mace-application-to-the-give-me-some-credit-dataset">Example of MACE Application to the Give Me Some Credit Dataset<a href="#example-of-mace-application-to-the-give-me-some-credit-dataset" class="hash-link" aria-label="Direct link to Example of MACE Application to the Give Me Some Credit Dataset" title="Direct link to Example of MACE Application to the Give Me Some Credit Dataset">​</a></h4><p>To demonstrate how MACE can be used in a real-world setting, we applied it to the well-known <a href="https://github.com/DrIanGregory/Kaggle-GiveMeSomeCredit" target="_blank" rel="noopener noreferrer">Give Me Some Credit dataset from Kaggle</a>. This dataset was originally used in a 2011 competition to predict the likelihood of a borrower becoming seriously delinquent (90+ days late on a payment) within two years.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="dataset-overview">Dataset Overview<a href="#dataset-overview" class="hash-link" aria-label="Direct link to Dataset Overview" title="Direct link to Dataset Overview">​</a></h4><p>The dataset includes over 250,000 anonymized credit records, split into 150,000 training examples and 101,503 test instances. The target variable is SeriousDlqin2yrs (1 = default, 0 = no default), and each record contains 10 explanatory variables that capture an individual’s credit behavior, income, and financial obligations. Key features include:</p><ul><li>RevolvingUtilizationOfUnsecuredLines: Utilization ratio of unsecured lines (e.g., credit cards)</li><li>DebtRatio: Proportion of debt relative to income</li><li>MonthlyIncome: Self-reported monthly income</li><li>NumberOfOpenCreditLinesAndLoans: Total number of credit lines and loans</li><li>NumberOfTimes90DaysLate: Frequency of severe delinquency</li></ul><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="model-training">Model Training<a href="#model-training" class="hash-link" aria-label="Direct link to Model Training" title="Direct link to Model Training">​</a></h4><p>For this case study, we used XGBoost, a gradient boosting algorithm known for its ability to handle structured data and capture nonlinear relationships. XGBoost was trained on the preprocessed training data to predict the likelihood of loan default (SeriousDlqin2yrs).</p><p>After training, we applied MACE to generate counterfactual explanations for individuals predicted as high risk (i.e., default = 1). The goal was to understand what minimal and realistic changes could flip their classification to non-default.</p></div><div align="center"><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/Table-35ed507976f3c203ad0b08bbfb6944b0.png" width="604" height="108" class="img_ev3q"></p></div><div align="justify"><p>Two counterfactuals were generated for the individual originally predicted to default (label = 1). The original instance had a DebtRatio of 0.803 and a MonthlyIncome of 9120.0. The first counterfactual (CF 1) keeps the DebtRatio constant at 0.803 but increases the MonthlyIncome to 9422.625, resulting in a predicted label of 0 (non-default). The second counterfactual (CF 2) achieves the same label flip by simultaneously lowering the DebtRatio to 0.7993 and raising the MonthlyIncome to 9422.625. This demonstrates that modest, realistic adjustments to financial metrics can alter risk classification, highlighting specific and actionable paths to improve creditworthiness.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="iv-the-future-of-counterfactuals-and-explainable-ai">IV. The Future of Counterfactuals and Explainable AI<a href="#iv-the-future-of-counterfactuals-and-explainable-ai" class="hash-link" aria-label="Direct link to IV. The Future of Counterfactuals and Explainable AI" title="Direct link to IV. The Future of Counterfactuals and Explainable AI">​</a></h2><p>Counterfactual explanations are becoming an increasingly important tool for AI transparency and decision-making. As the field evolves, several key trends are shaping their future.</p><p>One major shift is the integration of causal reasoning into counterfactual methods. Instead of simply answering &quot;what-if&quot; questions, future approaches will identify real cause-and-effect relationships, helping distinguish meaningful factors from random correlations. This will make counterfactual explanations more reliable and actionable.</p><p>Another important development is the move toward automated constraints. Rather than relying on manually defined rules, new techniques will learn realistic constraints directly from data. This will ensure that counterfactual suggestions remain practical and achievable without requiring extensive human oversight.</p><p>Despite these advancements, challenges remain especially in scaling counterfactual methods for complex models like transformers and ensuring they work effectively across different languages and cultures.</p><p>To address these issues, we have been developing a counterfactual generator that prioritizes plausibility and proximity. By ensuring that suggested changes are both realistic and within the distribution, our approach aims to provide users with more trustworthy insights into AI-driven decisions.</p><p>Counterfactuals are playing a key role in shifting AI from an opaque &quot;black box&quot; to a transparent, user-friendly system. By making machine learning more explainable, accountable, and actionable, they will help shape the future of ethical and trustworthy AI.</p></div></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/xai">XAI</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/explainability">explainability</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/machine-learning">Machine Learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/counterfactuals">Counterfactuals</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/Dual_Impact_Communication"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Part 1: The Dual Impact of Communication: A Conceptual Framework for Understanding its Environmental Impact</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/Causal_Inference"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">MMM Opportunities of Using Causal Inference</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#i-what-is-a-counterfactual-explanation-in-machine-learning" class="table-of-contents__link toc-highlight">I. What is a Counterfactual Explanation in Machine Learning?</a></li><li><a href="#ii-why-counterfactuals-matter-in-machine-learning" class="table-of-contents__link toc-highlight">II. Why Counterfactuals Matter in Machine Learning</a></li><li><a href="#iii-generating-counterfactuals-dice-and-mace" class="table-of-contents__link toc-highlight">III. Generating Counterfactuals: DiCE and MACE</a></li><li><a href="#iv-the-future-of-counterfactuals-and-explainable-ai" class="table-of-contents__link toc-highlight">IV. The Future of Counterfactuals and Explainable AI</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">About us</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://ekimetrics.com/who-we-are/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Who we are ?</a></li><li class="footer__item"><a href="https://ekimetrics.com/our-team/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Our team</a></li><li class="footer__item"><a href="https://ekimetrics.us13.list-manage.com/subscribe?u=85b8ce42caa0a733e98233bc4&amp;id=6355d0a6f9" target="_blank" rel="noopener noreferrer" class="footer__link-item">Subscribe to our newsletter</a></li></ul></div><div class="col footer__col"><div class="footer__title">Find us</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/ekimetrics" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://ekimetrics.com/careers/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Careers<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.welcometothejungle.com/fr/companies/ekimetrics" target="_blank" rel="noopener noreferrer" class="footer__link-item">Eki on Welcome to the jungle<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Contact</div><ul class="footer__items clean-list"><li class="footer__item"><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Get in touch with our teams<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div></div></footer></div>
<script src="/assets/js/runtime~main.fa7e58fa.js"></script>
<script src="/assets/js/main.2fca948b.js"></script>
</body>
</html>