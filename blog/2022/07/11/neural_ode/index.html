<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Exploring neural ordinary differential equations for time series forecasting applications | Eki.Lab</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="http://ekimetrics.github.io/img/10-cubecube03.jpg"><meta data-rh="true" name="twitter:image" content="http://ekimetrics.github.io/img/10-cubecube03.jpg"><meta data-rh="true" property="og:url" content="https://ekimetrics.github.io/blog/2022/07/11/neural_ode"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Exploring neural ordinary differential equations for time series forecasting applications | Eki.Lab"><meta data-rh="true" name="description" content="Enhance your knowledge on Deep Learning techniques by understanding what neural ODEs are and how we could benefit from them."><meta data-rh="true" property="og:description" content="Enhance your knowledge on Deep Learning techniques by understanding what neural ODEs are and how we could benefit from them."><meta data-rh="true" name="keywords" content="Data Science,EkiLab,Ekimetrics,Eki.Lab,Eki,Machine Learning,Artificial Intelligence,Data Science for business,Time Series Forecasting,Sales Prediction,Neural Ordinary Differential Equations,Deep Learning,Newspaper Industry"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2022-07-11T00:00:00.000Z"><meta data-rh="true" property="article:author" content="mailto:inno@ekimetrics.com"><meta data-rh="true" property="article:tag" content="Time Series Forecasting,Sales Prediction,Neural Ordinary Differential Equations,Deep Learning,Newspaper Industry"><link data-rh="true" rel="icon" href="/img/favicon.png"><link data-rh="true" rel="canonical" href="https://ekimetrics.github.io/blog/2022/07/11/neural_ode"><link data-rh="true" rel="alternate" href="https://ekimetrics.github.io/blog/2022/07/11/neural_ode" hreflang="en"><link data-rh="true" rel="alternate" href="https://ekimetrics.github.io/blog/2022/07/11/neural_ode" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Eki.Lab RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Eki.Lab Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-124520099-9","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>




<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-124520099-9"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-124520099-9",{anonymize_ip:!0}),gtag("config","G-MQNYE0E8GE",{anonymize_ip:!0})</script><link rel="stylesheet" href="/assets/css/styles.47419826.css">
<link rel="preload" href="/assets/js/runtime~main.32be2126.js" as="script">
<link rel="preload" href="/assets/js/main.e411d8bc.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title text--truncate">.</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/publications">Publications</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">About us</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/about">Ekilab</a></li><li><a class="dropdown__link" href="/about/ekimetrics">Ekimetrics</a></li><li><a class="dropdown__link" href="/about/stack">Technology stack</a></li></ul></div><a href="https://www.ekimetrics.com/fr/join-ekimetrics" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Careers</a></div><div class="navbar__items navbar__items--right"><a href="https://ekimetrics.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Ekimetrics website</a><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Contact us!<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="searchBox_ZlJk"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input type="search" id="search_input_react" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><main class="col col--9 col--offset-1" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="title_f1Hy" itemprop="headline">Exploring neural ordinary differential equations for time series forecasting applications</h1><div class="container_mt6G margin-vert--md"><time datetime="2022-07-11T00:00:00.000Z" itemprop="datePublished">July 11, 2022</time> ¬∑ <!-- -->11 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Miguel Omenaca Muro</span></a></div><small class="avatar__subtitle" itemprop="description">Data Scientist Consultant</small></div></div></div></div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><div align="center"><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/neural_ode_cover-d93f3ae869aeba9fcfc6c2b522a9665e.png" width="815" height="543" class="img_ev3q"></p></div><div align="justify"><p>For decades, time series forecasting has been a popular topic among the scientific community related to data science and artificial intelligence (AI). The reason behind this is that time series, data measured over time, are omnipresent in our day-to-day life and are used in a wide range of industries. For instance, in the retail industry, forecasting is a crucial task to optimize processes and increase efficiency. Many examples can be found in the literature mainly focusing on demand forecasting <!-- -->[1]<!-- --> and sales forecasting <!-- -->[2]<!-- -->.</p><p>In the past, retail companies have relied on traditional time series forecasting approaches based on statistics. More recently, companies and researchers have grown interest in machine learning and deep learning techniques and algorithms to predict the demand more accurately among other requirements. To evolve as a leader in data science, at Ekimetrics, we keep an eye on the state-of-the-art of time series forecasting and investigate new techniques to eventually, adopt them and improve our solutions in the long run.</p><p>This article will focus on our journey with <strong>neural ordinary differential equations</strong> (neural ODEs) applied to time series forecasting and specifically focused on a client‚Äôs use case.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="selling-magazines">Selling magazines<a href="#selling-magazines" class="hash-link" aria-label="Direct link to Selling magazines" title="Direct link to Selling magazines">‚Äã</a></h2><p>Before entering into the subject, if you have not read our article on how we use Bayesian inference to increase our predictions of magazines sales have a look at it <a href="https://ekimetrics.github.io/blog/2022/06/14/bayesian_inference/" target="_blank" rel="noopener noreferrer">here</a>. It is an interesting application of a Bayesian framework to enhance sales prediction for a publisher. Our exploration of neural ODEs focuses on the same use case.</p><p>In the world of newspapers and magazines, it is crucial to be able to estimate the final volume of sales for accounting and management purposes. Indeed, publishers adjust their production and distribution of issues based on these forecasts. Conventionally, the projections rely strongly on the domain expertise of the people in charge. But nowadays, with all recent advances in the field of data science and improvements with regards to data availability, publishers can leverage modern forecasting techniques to enhance their predictions.  </p><p>The figure below, Fig. 1, represents the cumulative sales of a magazine composed by a set of 14 different issues. Note that the data have been anonymized for confidentiality purposes. Our task is to use the observed data, including the sales curves of all historical issues and the beginning part of the current issue‚Äôs curve, to predict the final sales of the current issue.</p><p><img loading="lazy" alt="screenshot-app" src="/assets/images/image_1_bis-3e321c685521a1b2a048616b9c8b7bfd.png" width="1498" height="472" class="img_ev3q"></p><div align="center"> Fig. 1: Example of magazine sales curves</div><br><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="introduction-to-neural-odes">Introduction to neural ODEs<a href="#introduction-to-neural-odes" class="hash-link" aria-label="Direct link to Introduction to neural ODEs" title="Direct link to Introduction to neural ODEs">‚Äã</a></h2><p>In this section we provide an overview of what neural ODEs are, and what makes them so special. For the curious readers, complementary resources and blog posts that present this topic in detail, are provided at the end of this article.</p><p>To understand neural ODEs, we need to introduce some basic concepts on neural networks (NNs). In essence, NNs are a succession of input, hidden and output layers originally inspired by the human brain. The Multilayer Perceptron (MLP) is one the most popular feedforward neural network due to its simplicity. By means of activation functions and linear combinations of the input data, these networks introduce non linearities and become universal approximators <!-- -->[3]<!-- -->. The equation h(t+1) = f(ht, Œ∏t), captures the evolution of the hidden layers of a MLP network with ht referring to the previous layer and Œ∏t to a parameter of the network. Without entering too much into the details, these networks are usually trained by minimizing a loss function and backpropagation, propagating the computed error, and updating the weights accordingly.</p><p>What we must keep in mind here is that these networks have a limited number of layers and thus, of evaluation points. Could we achieve an infinite number of evaluation points for time continuous applications? The instinctive answer is no since we cannot have an infinite number of layers. However, we are going to review some interesting properties of residual networks (ResNet) that will help us answer this question.</p><div align="center"><p><img loading="lazy" alt="screenshot-app" src="/assets/images/image_2-0a89ff1fb52a6ccd12d1667b711b9f23.png" width="385" height="216" class="img_ev3q"></p><p>Fig. 2: ResNet schema <!-- -->[4]</p></div><br><p>A ResNet is a neural network that has an architecture based on the pattern pictured in Fig. 2 which entails that the network follows the equation h<sub>t+1</sub> = h<sub>t</sub> + f(h<sub>t</sub>, Œ∏<sub>t</sub>). This equation might be familiar to some readers with a background in mathematics since it resembles Euler‚Äôs method. In short, this method is useful to solve initial value problems, a problem modelled by an ordinary differential equation with an initial condition. Interestingly, a residual network adds hidden states between the input and the output and discretizes the continuous relationship between them, which is similar to Euler&#x27;s method. In <!-- -->[5]<!-- --> the authors take a different approach by considering the continuous limit of each discrete layer of the network. Thus, instead of having a discrete number of layers, the progression of the hidden states is continuous, obtaining the following equation where h(t) is the value of the hidden state evaluated for some t.</p><div align="center"> d‚Ñé(ùë°)/ùëëùë° = ùëì(‚Ñé(ùë°), ùúÉ<sub>t</sub>, ùë°)</div><br><p>Then, in a neural ODE the hidden state dynamic can be parametrized by the equation above where ùëì(‚Ñé(ùë°), ùúÉ<sub>t</sub>, ùë°) is a neural network parametrized by ùúÉ<sub>t</sub> at layer t. Therefore, it is possible to solve this ODE by solving its integral.</p><div align="center"> h(t) = ‚à´ f(h(t), ùúÉ<sub>t</sub>, t)</div><br><p>By means of a numerical ODE method, it is possible to evaluate the network at any desired depth. And thus, it is possible to approximate functions over these hidden state dynamics by using ODE solvers such as:</p><div align="center"> ≈∑ = h(t<sub>1</sub>) = ODESolve(h(t<sub>0</sub>), t<sub>0</sub>, t<sub>1</sub>, ùúÉ<sub>t</sub>, f)</div><br><p>Now, if we go back to our initial question regarding the possibility of having an infinite or quasi-infinite number of evaluation points, we can state that neural ODEs enable us to achieve that Fig. 3 illustrates this idea by comparing the vector field created by a traditional residual network and an ODE network. In essence, an ODE network defines a continuous vector field since this network can be evaluated at any depth. Whereas, on the other hand, the residual network is limited to a discrete number of layers.</p><div align="center"><p><img loading="lazy" alt="screenshot-app" src="/assets/images/image_3-2d9dce2581ec5d66cb7908b0f4c091bb.png" width="472" height="333" class="img_ev3q"></p><p>Fig. 3: Comparison between a ResNet and an ODE network vector fields transformations <!-- -->[5]</p></div><br><p>Before moving on to the applications of neural ODEs, it is important to note the endeavor of performing backpropagation. Essentially, the more evaluation points you have in your network, the higher the number of intermediate forward passes to store. To overcome this, the authors of the original paper <!-- -->[5]<!-- --> which received the 2018 NeurIPS best paper award, introduced a mathematical trick known as the Adjoint method. We will not get into the details here, but you can dig deeper into this concept by checking the resources we have left at the end of this article.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="applications-of-neural-odes">Applications of neural ODEs<a href="#applications-of-neural-odes" class="hash-link" aria-label="Direct link to Applications of neural ODEs" title="Direct link to Applications of neural ODEs">‚Äã</a></h2><p>The main advantage of neural ODEs is the possibility of working with continuous-time series models. In addition, they are generally more memory efficient than other networks such as the MLP and can gain from adaptive computation since modern ODE solvers allow to monitor the level of error and adapt the evaluation strategy. For example, we can reduce accuracy for low power applications.</p><p>All these benefits make neural ODEs a great tool for applications dealing with continuous time systems, irregularly sampled data, and scalable and invertible normalizing flows. Besides, neural ODEs are very interesting for time series forecasting too. Basically, they can be used to fit time series and then extrapolate them. Since 2018, we have seen an increasing number of scientific papers presenting neural ODEs to deal with forecasting challenges in the energy <!-- -->[6]<!-- --> and the healthcare <!-- -->[7]<!-- --> sectors.</p><p>Coming back to our specific use case, although Fig. 1 introduced at the beginning of this article shows that applying a curve fitting model does not seem like a feasible option, we considered our sales curves as trajectories to employ neural ODE models to fit the curves and forecast the final volumes of sales. We can formulate our problem with the following equation.</p><div align="center"> xŒ∏<sub>t+1</sub> = xŒ∏<sub>0</sub> + ‚à´ b(xŒ∏<sub>u</sub>, u) du</div><br><p>Where x is an issue belonging to a magazine and b in our case is a neural network, something resembling to b(xŒ∏<sub>u</sub>, u) = MLP(xŒ∏<sub>u</sub>), with its corresponding parameters.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="results">Results<a href="#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results">‚Äã</a></h2><p>Initially, we have used a standard neural ODE network to deal with our time series forecasting use case. The figure below, Fig. 4, is an animation representing the fitting of a curve of sales of a specific issue. Bear in mind that the data have been anonymized for privacy purposes.</p><p>In this figure, we can observe that the model is able to fit the curve successfully after some iterations. The idea then is to fit the sales curves from all historical issues and the beginning part of the current issue‚Äôs curve to predict the final sales by extrapolation. Although we have obtained promising results, they are not good enough. The main reason being that neural ODEs are well suited for deterministic systems and in our case, we deal with a non-deterministic one.</p><div align="center"><p><img loading="lazy" alt="screenshot-app" src="/assets/images/curve_fitting-caed00a370c6fac7f7475e43da4b16aa.gif" width="864" height="288" class="img_ev3q"></p><p>Fig. 4: Curve fitting of the sales curve of an issue</p></div><br><p>Inspired by the ideas presented in <!-- -->[8]<!-- -->, instead of a standard neural ODE network like the one introduced before, we have been recently working with stochastic differential neural networks (SDEs). SDEs are a type of continous neural network enabling to introduce a stochastic component and consequently, work with non-deterministic systems and consider external factors. We have obtained promising preliminary results with this procedure, but they require further analysis.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">‚Äã</a></h2><p>In this article, we have introduced you into the world of neural ordinary differential equations applied to time series forecasting. We have gone through a short theoretical explanation and presented you our exploration with neural ODEs to strengthen predictions for a magazine publisher.</p><p>At Ekimetrics, we accompany a large portfolio of clients across a wide range of industries to help them steer their data opportunity, build capabilities, and deploy actionable DS solutions to power up a sustainable growth. As a leader in the field of data science, we perform recurring technological watches and stay tuned on the state-of-the-art of the fields of machine learning and deep learning. As stated during this article, we are particularly interested in time series and investigate recent advances on the subject to eventually, embrace them and expand our solutions.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="references">References<a href="#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References">‚Äã</a></h2><p>[1]<!-- --> J. Wang, G. Q. Liu, and L. Liu, &quot;A selection of advanced technologies for demand forecasting in the retail industry&quot;, <a href="https://ieeexplore.ieee.org/document/8713196" target="_blank" rel="noopener noreferrer">A Selection of Advanced Technologies for Demand Forecasting in the Retail Industry | IEEE Conference Publication | IEEE Xplore.</a></p><p>[2]<!-- --> X. dairu and Z. Shilong, &quot;Machine learning model for sales forecasting by using xgboost&quot;, <a href="https://ieeexplore.ieee.org/document/9342304" target="_blank" rel="noopener noreferrer">Machine Learning Model for Sales Forecasting by Using XGBoost | IEEE Conference Publication | IEEE Xplore.</a></p><p>[3]<!-- --> K. Hornik, M. Stinchcombe, H. White, ‚ÄúMultilayer feedforward networks are universal approximators‚Äù, <a href="https://www.sciencedirect.com/science/article/abs/pii/0893608089900208" target="_blank" rel="noopener noreferrer">Multilayer feedforward networks are universal approximators.</a></p><p>[4]<!-- --> Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, &quot;Deep Residual Learning for Image Recognition&quot;, <a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener noreferrer">Deep Residual Learning for Image Recognition.</a></p><p>[5]<!-- --> Ricky T. Q. Chen, Yulia Rubanova, Jesse Bettencourt, David Duvenaud, &quot;Neural ordinary differential equations&quot;, <a href="https://arxiv.org/abs/1806.07366" target="_blank" rel="noopener noreferrer">Neural Ordinary Differential Equations.</a></p><p>[6]<!-- --> X. Xie, A. K. Parlikad, and R. Puri, &quot;A neural ordinary differential equations based approach for demand forecasting within power grid digital twins&quot;, <a href="https://ieeexplore.ieee.org/document/8909789" target="_blank" rel="noopener noreferrer">A Neural Ordinary Differential Equations Based Approach for Demand Forecasting within Power Grid Digital Twins | IEEE Conference Publication | IEEE Xplore.</a></p><p>[7]<!-- --> Intae Moon, Stefan Groha, Alexander Gusev, &quot;SurvLatent ODE : A Neural ODE based time-to-event model with competing risks for longitudinal data improves cancer-associated Deep Vein Thrombosis (DVT) prediction&quot;, <a href="https://arxiv.org/pdf/2204.09633.pdf" target="_blank" rel="noopener noreferrer">2204.09633.pdf (arxiv.org).</a> </p><p>[8]<!-- --> Xuechen Li, Ting-Kam Leonard Wong, Ricky T. Q. Chen, David Duvenaud, &quot;Scalable Gradients for Stochastic Differential Equations&quot;, <a href="https://arxiv.org/abs/2001.01328" target="_blank" rel="noopener noreferrer">Scalable Gradients for Stochastic Differential Equations.</a></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="additional-resources">Additional resources<a href="#additional-resources" class="hash-link" aria-label="Direct link to Additional resources" title="Direct link to Additional resources">‚Äã</a></h2><ul><li><p>In-depth blog post: <a href="https://jontysinai.github.io/jekyll/update/2019/01/18/understanding-neural-odes.html" target="_blank" rel="noopener noreferrer">Understanding Neural ODE&#x27;s - Jonty Sinai</a></p></li><li><p>Presentation on mathematics behind neural ODEs: <a href="https://voletiv.github.io/docs/presentations/20200402_Guelph_Neural_ODEs_tutorial.pdf" target="_blank" rel="noopener noreferrer">20200402_Guelph_Neural_ODEs_tutorial.pdf (voletiv.github.io)</a></p></li><li><p>Interesting blog post: <a href="https://towardsdatascience.com/neural-odes-breakdown-of-another-deep-learning-breakthrough-3e78c7213795" target="_blank" rel="noopener noreferrer">Neural ODEs: breakdown of another deep learning breakthrough | by Alexandr Honchar | Towards Data Science</a></p></li><li><p>Neural ODEs Github repository: <a href="https://github.com/msurtsukov/neural-ode" target="_blank" rel="noopener noreferrer">GitHub - msurtsukov/neural-ode: Jupyter notebook with Pytorch implementation of Neural Ordinary Differential Equations</a></p></li><li><p>SDEs Github repository: <a href="https://github.com/google-research/torchsde" target="_blank" rel="noopener noreferrer">GitHub - google-research/torchsde: Differentiable SDE solvers with GPU support and efficient sensitivity analysis.</a></p></li></ul></div></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/time-series-forecasting">Time Series Forecasting</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/sales-prediction">Sales Prediction</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/neural-ordinary-differential-equations">Neural Ordinary Differential Equations</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/deep-learning">Deep Learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/newspaper-industry">Newspaper Industry</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/2022/08/27/traditional_or"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Deep RL and Optimization applied to Operations Research problem - 1/2 Traditional Optimization techniques</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/2022/07/05/newsletter_June-2022"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Newsletter for June 2022</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#selling-magazines" class="table-of-contents__link toc-highlight">Selling magazines</a></li><li><a href="#introduction-to-neural-odes" class="table-of-contents__link toc-highlight">Introduction to neural ODEs</a></li><li><a href="#applications-of-neural-odes" class="table-of-contents__link toc-highlight">Applications of neural ODEs</a></li><li><a href="#results" class="table-of-contents__link toc-highlight">Results</a></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a></li><li><a href="#additional-resources" class="table-of-contents__link toc-highlight">Additional resources</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">About us</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://ekimetrics.com/who-we-are/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Who we are ?</a></li><li class="footer__item"><a href="https://ekimetrics.com/our-team/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Our team</a></li><li class="footer__item"><a href="https://ekimetrics.us13.list-manage.com/subscribe?u=85b8ce42caa0a733e98233bc4&amp;id=6355d0a6f9" target="_blank" rel="noopener noreferrer" class="footer__link-item">Subscribe to our newsletter</a></li></ul></div><div class="col footer__col"><div class="footer__title">Find us</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/ekimetrics" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://ekimetrics.com/careers/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Careers<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.welcometothejungle.com/fr/companies/ekimetrics" target="_blank" rel="noopener noreferrer" class="footer__link-item">Eki on Welcome to the jungle<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Contact</div><ul class="footer__items clean-list"><li class="footer__item"><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Get in touch with our teams<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div></div></footer></div>
<script src="/assets/js/runtime~main.32be2126.js"></script>
<script src="/assets/js/main.e411d8bc.js"></script>
</body>
</html>