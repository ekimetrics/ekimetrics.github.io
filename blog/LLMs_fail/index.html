<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Where LLMs still fail | Eki.Lab</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://ekimetrics.github.io/blog/LLMs_fail"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Where LLMs still fail | Eki.Lab"><meta data-rh="true" name="description" content="An exploration of current limitations in Large Language Models (LLM) through concrete examples, revealing their surprising struggles with seemingly simple tasks."><meta data-rh="true" property="og:description" content="An exploration of current limitations in Large Language Models (LLM) through concrete examples, revealing their surprising struggles with seemingly simple tasks."><meta data-rh="true" name="keywords" content="Generative AI,LLM,NLP,Innovation,Data Science,Large Language Models (LLM),LLM limitations,ChatGPT,o1,o1-preview,Artificial Intelligence,Misguided attention,Next-token prediction,Natural Language Processing,Language model biases,Generative AI limitations,LLM errors,Machine learning challenges,Deep learning weaknesses,GPT limitations,Natural language processing issues,Chain-of-thought prompting,Ekimetrics AI,OpenAI,LLM tokenization,AI numeric processing,Language model reasoning"><meta data-rh="true" property="og:image" content="https://ekimetrics.github.io/img/blog/LLMs_fail_header.png"><meta data-rh="true" name="twitter:image" content="https://ekimetrics.github.io/img/blog/LLMs_fail_header.png"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2024-11-25T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://www.linkedin.com/in/jeanlelong/"><meta data-rh="true" property="article:tag" content="Generative AI,LLM,NLP"><link data-rh="true" rel="icon" href="/img/favicon.png"><link data-rh="true" rel="canonical" href="https://ekimetrics.github.io/blog/LLMs_fail"><link data-rh="true" rel="alternate" href="https://ekimetrics.github.io/blog/LLMs_fail" hreflang="en"><link data-rh="true" rel="alternate" href="https://ekimetrics.github.io/blog/LLMs_fail" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Eki.Lab RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Eki.Lab Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-124520099-9","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>




<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-124520099-9"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-124520099-9",{anonymize_ip:!0}),gtag("config","G-MQNYE0E8GE",{anonymize_ip:!0})</script><link rel="stylesheet" href="/assets/css/styles.29261950.css">
<link rel="preload" href="/assets/js/runtime~main.3db47f18.js" as="script">
<link rel="preload" href="/assets/js/main.d660de0c.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title text--truncate">.</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">About us</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/about">Ekilab</a></li><li><a class="dropdown__link" href="/about/ekimetrics">Ekimetrics</a></li><li><a class="dropdown__link" href="/about/stack">Technology stack</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Resources</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/resources/">Hackathons</a></li><li><a class="dropdown__link" href="/resources/trainings">Trainings</a></li></ul></div><a href="https://ekimetrics.com/fr/carrieres/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Careers</a></div><div class="navbar__items navbar__items--right"><a href="https://ekimetrics.com/fr/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Ekimetrics website</a><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Contact us!<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="searchBox_ZlJk"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input type="search" id="search_input_react" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><main class="col col--9 col--offset-1" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="image" content="https://ekimetrics.github.io/img/blog/LLMs_fail_header.png"><header><h1 class="title_f1Hy" itemprop="headline">Where LLMs still fail</h1><div class="container_mt6G margin-vert--md"><time datetime="2024-11-25T00:00:00.000Z" itemprop="datePublished">November 25, 2024</time> Â· <!-- -->10 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/jeanlelong/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/authors/jean_lelong.jpg" alt="Jean LELONG"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/jeanlelong/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jean LELONG</span></a></div><small class="avatar__subtitle" itemprop="description">Senior Consultant</small></div></div></div></div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><div align="justify"><p>The field of Natural Language Processing (NLP) has experienced an unprecedented explosion in recent years, and at the heart of this revolution are Large Language Models (LLMs). These powerful tools have transformed our understanding of what machines can achieve, rivalling human cognition in many areas. In just a few short years, LLMs have evolved from generating pseudo-coherent text in English (GPT-2; 2019) to enormous models that possess knowledge besting most human experts in specific domains (o1, claude 3.5; 2024).</p><p>At Ekimetrics, we&#x27;re thrilled to be working with clients to harness the potential of these new technologies, exploring exciting applications such as Retrieval-Augmented Generation (RAG), KPI extraction, or social media content generation. We use LLMs to manage and format knowledge in all its forms.</p><p>Our team has witnessed first-hand the incredible capabilities of LLMs, and we&#x27;re eager to continue pushing the boundaries of what&#x27;s possible. However, despite their impressive abilities, even the best LLMs are still not without weaknesses.</p><p>In this article, we&#x27;ll delve into concrete examples of LLMs struggling with seemingly trivial tasks and attempt to understand the underlying reasons for these failures. By exploring the limitations of LLMs, we hope to gain a deeper appreciation for their capabilities and develop strategies to overcome their weaknesses, ultimately unlocking their full potential.</p><p>The observations and insights shared in this article are purely my personal perspective, drawn from extensive experience working with Large Language Models (LLMs) in both research and production environments. As someone deeply immersed in this field at Ekimetrics, I recognize that LLMs are fundamentally complex &quot;black box&quot; systems. The examples and analysis that follow represent my professional observations and interpretations, but they are not definitive scientific conclusions.</p><p>All the examples below are generated using the latest version of ChatGPT available as of October 21, 2024. I chose ChatGPT because it is the most widely used and well-known access to an LLMs for most people, and it hosts state-of-the-art models from OpenAI. All messages you see are the first answers I got from ChatGPT, there are no previous messages, and no system prompt.</p><p>As a bonus, see o1 answers at the end of the article. It only get 1 out of the 3 examples right.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="misguided-attention">Misguided Attention<a href="#misguided-attention" class="hash-link" aria-label="Direct link to Misguided Attention" title="Direct link to Misguided Attention">â</a></h2><p>In the realm of large language models (LLMs), one intriguing phenomenon that often leads to errors is what we could refer to as <a href="https://github.com/cpldcpu/MisguidedAttention" target="_blank" rel="noopener noreferrer">misguided attention</a>. This occurs when a LLM encounters a problem or prompt that closely resembles a well-known scenario it has encountered during its training. The model, recognizing the familiar pattern, may prematurely jump to conclusions without fully processing the nuances of the current situation. This is akin to a human cognitive bias known as the <a href="https://en.wikipedia.org/wiki/Einstellung_effect" target="_blank" rel="noopener noreferrer">Einstellung effect</a>, where prior experience with similar problems causes individuals to apply previously learned solutions inappropriately.</p><p>A classic example of this is the &quot;Dead SchrÃ¶dinger&#x27;s cat&quot; scenario. In this twist on <a href="https://en.wikipedia.org/wiki/Schr%C3%B6dinger&#x27;s_cat" target="_blank" rel="noopener noreferrer">the famous thought experiment</a>, a dead cat is placed into a box alongside a nuclear isotope, a vial of poison, and a radiation detector. If the detector picks up radiation, it releases the poison. The question is: &quot;What is the probability of the cat being alive when the box is opened a day later?&quot;</p></div><div align="center"><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/Schrodinger_cat-133e0c6b0aed6cf20c81577cc5a7c8a5.jpg" width="800" height="426" class="img_ev3q"></p></div><p>Now watch what happens if we ask ChatGPT this simple question:</p><div align="center"><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/Chat_GPT_question-c43eda3ecc0acab4d8f9f484795624fb.jpg" width="696" height="800" class="img_ev3q"></p></div><div align="justify"><p>Almost all LLMs, upon encountering this problem, default to their learned response from SchrÃ¶dinger&#x27;s original paradox, which involves a living cat in a superposition of states. They fail to consider the critical twistâthat the cat starts out dead. This oversight occurs because the model&#x27;s attention latches onto the familiar elements of the problem and neglects to process the new information. Some kind of &quot;Oh! I already know this one!&quot; effect.</p><p>This phenomenon is intricately tied to the way these models are trained. LLMs are trained on massive datasets comprising diverse text inputs from the internet, books, articles, and other sources. During this training process, the models learn to identify patterns, structures, and associations within the data. They use these patterns to generate predictions about the next token in a sequence, based on the context provided by preceding tokens. This ability to predict and generate text is largely driven by statistical correlations rather than true understanding or reasoning.</p><p>As a result, LLMs develop a keen sense for recognizing familiar patterns and scenarios that resemble those they have encountered during training. This can lead them to quickly latch onto well-known narratives or problem templates, even when subtle differences or new information require a different approach. The reliance on pattern recognition means that when a LLM encounters a prompt that closely mirrors a familiar scenario, it may default to the response it has learned for that scenario, without noticing new elements in the context. Even when new elements can be as critical as in this example. This is akin to how humans sometimes rely on heuristics or mental shortcuts based on past experiences, potentially leading to errors in judgment when faced with novel situations. Understanding this aspect of LLM training helps illuminate why misguided attention occurs and underscores the importance of developing strategies to mitigate its effects.</p><p>The challenge of misguided attention highlights both the potential and the pitfalls of LLMs. While their power lies in pattern recognition, enabling them to draw from vast reserves of knowledge, this same reliance can sometimes become their worst enemy when they encounter novel twists on familiar themes. By understanding these limitations and refining how we use LLMs, we can continue to enhance their reasoning capabilities, all the while mitigating risks such as hallucinations for our clients, thus unlocking even more sophisticated applications in natural language processing.</p><br><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="following-instructions">Following instructions<a href="#following-instructions" class="hash-link" aria-label="Direct link to Following instructions" title="Direct link to Following instructions">â</a></h2><p>LLMs are fundamentally constrained by their next-token prediction mechanism, generating text one token at a time without the ability to revise previous output. Unlike humans, who can reflect on and adjust their thoughts during writing, LLMs are locked into a linear, sequential process. This limitation can lead to inconsistencies or unintended outputs, especially when handling specific formatting requirements.</p><p>In the next example, I ask the model to write sentences that end with a particular word.</p><div align="center"><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/Ask_sentence-3d17ab22776dd61e9a3daf82ade431ba.jpg" width="800" height="468" class="img_ev3q"></p></div><p>To give you an idea of how bad LLMs are at this task, I couldnât even use one to reflect on the error, because they do not see any problem and consider the task completed with success.</p><div align="center"><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/Grade_task-f7f9c0aa56383b38519f60368482ac5a.jpg" width="800" height="441" class="img_ev3q"></p></div><p>We can only try to guess why LLMs fail so spectacularly at this task. Here is my guess. While writing the sentence, the LLMs can only predict the next token. They âknowâ they must include âhousesâ in the sentence but the sense of writing nice sentences seems to overtake their will to respect the user instructions. Often the sentence could have ended after the token âhousesâ, as if the model had planned to stop, but it canât help but adding a few more words for the sentence to sound nice. When using ChatGPT through the API, we can observe this behavior but cannot directly modify the model&#x27;s output process. However, if we were to work with a local model where we have more control, we could potentially address this by forcing the model to stop at the desired word by manually inserting end-of-sentence tokens like &quot;.\n&quot; immediately after the target word. We could also investigate on the learned probabilities to select the next tokens in those situations, to estimate the willingness of the model to follow instructions over writing nice sentences.</p><br><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="numbers">Numbers<a href="#numbers" class="hash-link" aria-label="Direct link to Numbers" title="Direct link to Numbers">â</a></h2><p>LLMs perceive language as a sequence of tokens, rather than words and numbers. This tokenization process can lead to difficulties when processing numbers or proper nouns, as the model struggles to understand the context and relationships between these entities. For instance, when faced with mathematical equations, LLMs may falter, as they&#x27;re forced to rely on statistical patterns rather than true comprehension of the operations to make.</p><div align="center"><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/Numbers-1580f35c35e2f01189208290bb9acf00.jpg" width="800" height="297" class="img_ev3q"></p></div><p>The numerical comparison error in the image illustrates an interesting limitation of LLMs. In this instance, the model incorrectly concludes that 3.11 is greater than 3.9. The reason for this error may lie in how software version numbers are typically formatted - for example, Python releases follow a sequence like 2.0, 2.1, ..., 2.9, 2.10. Since the model has frequently encountered version numbers where 3.9 precedes 3.11, and commonly sees phrases like &quot;version 3.9 or higher&quot; (which includes 3.10 and 3.11), this pattern may have influenced its numerical reasoning. The model has thus learned this relationship between these numbers but struggles to discern that context matters and that by default the number 3.9 remains larger than the number 3.11. This also helps explain why it seems confused in its explanation &quot;since 90 is bigger than 11, 3.9 is smaller than 3.11&quot;. It&#x27;s almost like the model &quot;knows&quot; his first take was wrong but is too afraid to look bad by correcting itself.</p><p>This example is perfect to explain why chain-of-thoughts -before answering- are crucial for LLMs. Asking the model to explain its reasoning after it already gave its answer is just glorified post-hoc rationalization. However, prompting the model to write a justification before its answer can help it navigate the complexity of the task more effectively, leading to a more accurate final response.</p><br><p>Despite their remarkable achievements, LLMs continue to exhibit vulnerabilities in seemingly simple tasks. Through our exploration of misguided attention, next-token prediction limitations, and tokenization challenges, we&#x27;ve seen how these powerful models can still stumble in unexpected ways. These limitations remind us that LLMs process language very differently from humans. Understanding these shortcomings is crucial not just for academic interest, but for practical applications in business settings. At Ekimetrics, this knowledge helps us design more robust solutions by anticipating potential pitfalls and implementing appropriate guardrails, such as chain-of-thought prompting. As the field continues to evolve, with models like OpenAI&#x27;s o1 showing promising improvements, we remain both optimistic about the future potential of LLMs and mindful of their current limitations. This balanced perspective is essential for anyone working to harness these powerful tools effectively.</p><br><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="bonus-o1-answers">Bonus: o1 answers<a href="#bonus-o1-answers" class="hash-link" aria-label="Direct link to Bonus: o1 answers" title="Direct link to Bonus: o1 answers">â</a></h2><p><a href="https://openai.com/index/introducing-openai-o1-preview/" target="_blank" rel="noopener noreferrer">o1</a> is the latest model by OpenAI and nÂ°1 LLM on most -and especially logical- benchmarks. It uses chain-of-thought techniques to process user requests, decomposing and analyzing information before giving its final answer. One might think this state-of-the-art model, made to think, reflect, and perform complex tasks, would ace those examples. This is also what I thought, before testing the model on those same prompts. Of the three tricky examples I chose, they only got 3.9 &gt; 3.11 correct.</p><p>Below are o1-preview answers.</p><div align="center"><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/o1_answer_1-8f58c033e9afe9ea641490c11990dad1.jpg" width="800" height="540" class="img_ev3q"></p></div><div align="center"><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/o1_answer_2-da82975d052366266e86ee0a14905250.jpg" width="592" height="404" class="img_ev3q"></p></div><div align="center"><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/o1_answer_3-57e035afbe789b68e623747c7b6cbe02.jpg" width="754" height="653" class="img_ev3q"></p></div></div></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/generative-ai">Generative AI</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/llm">LLM</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/nlp">NLP</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/Talk_to_Data_App"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">How We Created Our First Talk-to-Data (Text-to-SQL) Application in Production</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/Wombat_HR"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Optimizing Chatbot Performance: A Two-Phase Methodology for Enhanced Performance in HR Policy Responses</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#misguided-attention" class="table-of-contents__link toc-highlight">Misguided Attention</a></li><li><a href="#following-instructions" class="table-of-contents__link toc-highlight">Following instructions</a></li><li><a href="#numbers" class="table-of-contents__link toc-highlight">Numbers</a></li><li><a href="#bonus-o1-answers" class="table-of-contents__link toc-highlight">Bonus: o1 answers</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">About us</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://ekimetrics.com/who-we-are/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Who we are ?</a></li><li class="footer__item"><a href="https://ekimetrics.com/our-team/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Our team</a></li><li class="footer__item"><a href="https://ekimetrics.us13.list-manage.com/subscribe?u=85b8ce42caa0a733e98233bc4&amp;id=6355d0a6f9" target="_blank" rel="noopener noreferrer" class="footer__link-item">Subscribe to our newsletter</a></li></ul></div><div class="col footer__col"><div class="footer__title">Find us</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/ekimetrics" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://ekimetrics.com/careers/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Careers<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.welcometothejungle.com/fr/companies/ekimetrics" target="_blank" rel="noopener noreferrer" class="footer__link-item">Eki on Welcome to the jungle<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Contact</div><ul class="footer__items clean-list"><li class="footer__item"><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Get in touch with our teams<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div></div></footer></div>
<script src="/assets/js/runtime~main.3db47f18.js"></script>
<script src="/assets/js/main.d660de0c.js"></script>
</body>
</html>