<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Exploring the links between creative execution and marketing effectiveness - Part II Custom trained Detectron2 for OD | Eki.Lab</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="http://ekimetrics.github.io/img/10-cubecube03.jpg"><meta data-rh="true" name="twitter:image" content="http://ekimetrics.github.io/img/10-cubecube03.jpg"><meta data-rh="true" property="og:url" content="https://ekimetrics.github.io/blog/2022/11/30/creative_execution_and_marketing_effectiveness_part_II"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Exploring the links between creative execution and marketing effectiveness - Part II Custom trained Detectron2 for OD | Eki.Lab"><meta data-rh="true" name="description" content="In this Part II we explore the methodology for training Detectron2 models to detect brand-specific object in creative images."><meta data-rh="true" property="og:description" content="In this Part II we explore the methodology for training Detectron2 models to detect brand-specific object in creative images."><meta data-rh="true" name="keywords" content="Data Science,EkiLab,Ekimetrics,Eki.Lab,Eki,Machine Learning,Artificial Intelligence,Data Science for business,Operational Research,Optimization,Knapsack problem,Deep Reinforcement Learning"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2022-11-30T00:00:00.000Z"><meta data-rh="true" property="article:author" content="mailto:inno@ekimetrics.com"><meta data-rh="true" property="article:tag" content="Object Detection,Optical Character Recognition,Marketing Mix Modelling,Deep Learning,Tesseract"><link data-rh="true" rel="icon" href="/img/favicon.png"><link data-rh="true" rel="canonical" href="https://ekimetrics.github.io/blog/2022/11/30/creative_execution_and_marketing_effectiveness_part_II"><link data-rh="true" rel="alternate" href="https://ekimetrics.github.io/blog/2022/11/30/creative_execution_and_marketing_effectiveness_part_II" hreflang="en"><link data-rh="true" rel="alternate" href="https://ekimetrics.github.io/blog/2022/11/30/creative_execution_and_marketing_effectiveness_part_II" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Eki.Lab RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Eki.Lab Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-124520099-9","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>




<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-124520099-9"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-124520099-9",{anonymize_ip:!0}),gtag("config","G-MQNYE0E8GE",{anonymize_ip:!0})</script><link rel="stylesheet" href="/assets/css/styles.47419826.css">
<link rel="preload" href="/assets/js/runtime~main.04f2449c.js" as="script">
<link rel="preload" href="/assets/js/main.1dd7753c.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title text--truncate">.</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/publications">Publications</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">About us</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/about">Ekilab</a></li><li><a class="dropdown__link" href="/about/ekimetrics">Ekimetrics</a></li><li><a class="dropdown__link" href="/about/stack">Technology stack</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Resources</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/resources/trainings">Trainings</a></li><li><a class="dropdown__link" href="/resources/">Hackathons</a></li></ul></div><a href="https://www.ekimetrics.com/fr/join-ekimetrics" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Careers</a></div><div class="navbar__items navbar__items--right"><a href="https://ekimetrics.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Ekimetrics website</a><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Contact us!<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="searchBox_ZlJk"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input type="search" id="search_input_react" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><main class="col col--9 col--offset-1" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="title_f1Hy" itemprop="headline">Exploring the links between creative execution and marketing effectiveness - Part II Custom trained Detectron2 for OD</h1><div class="container_mt6G margin-vert--md"><time datetime="2022-11-30T00:00:00.000Z" itemprop="datePublished">November 30, 2022</time> · <!-- -->7 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Marina Bermejo Sarmiento, Monica Brondholt Sorensen, Karin Sasaki</span></a></div><small class="avatar__subtitle" itemprop="description">Data Scientist Consultant</small></div></div></div></div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><div align="center"><p>  <img loading="lazy" alt="screenshot-app " src="/assets/images/Eki_Meta_part_II-34e9070bebe22829eed217b330dd3164.png" width="4928" height="3264" class="img_ev3q"></p></div><div align="justify"><p>This article is <strong>Part II</strong> of a set of five technical articles that accompany a <a href="https://ekimetrics.com/news-and-events/exploring-the-links-between-creative-execution-and-marketing-effectiveness-exclusivepreview" target="_blank" rel="noopener noreferrer">whitepaper</a> written in collaboration between Meta and Ekimetrics. Object Detection (OD) and Optical Character Recognition (OCR) were used to detect specific features in creative images, such as faces, smiles, text, brand logos, etc. Then, in combination with impressions data, marketing mix models were used to investigate what objects, or combinations of objects in creative images in marketing campaigns, drive higher ROIs.
In this Part II we explore the methodology for training Detectron2 models to detect brand-specific object in creative images.</p></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="why-you-should-read-this">Why you should read this<a href="#why-you-should-read-this" class="hash-link" aria-label="Direct link to Why you should read this" title="Direct link to Why you should read this">​</a></h2><div align="justify">This article is mostly directed to machine learning practitioners. Here you will find a practical application of object detection algorithms; we present different open-source resources, comparisons and trade-offs in model selection for specific objects, methodology to improve performance for custom datasets, and how the object detection is then used to make inferences on the impact of creatives in marketing strategies.</div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="dataset">Dataset<a href="#dataset" class="hash-link" aria-label="Direct link to Dataset" title="Direct link to Dataset">​</a></h2><div align="justify">Our dataset contained &gt;50k image and video creatives across four different brands. The main goal of the custom object detection (OD) was to detect three types of brand-specific objects - logo, product and brand cue - as well as faces and smiles. Initially, faces and smiles were detected by pre-trained algorithms such as Haar cascades and Dlib, but due to the poor performance, it was decided to use a custom algorithm.<p>Before beginning the OD process, videos were converted to images by extracting every tenth frame. Training and Validation sets were then created using the Microsoft Azure Machine Learning Studio labelling tool. The labels were then converted to COCO format, and registered in Detectron as custom COCO libraries. Read more about this in <a href="https://ekimetrics.github.io/blog/2022/11/10/creative_execution_and_marketing_effectiveness_part_I" target="_blank" rel="noopener noreferrer">Part I</a>. </p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">## Registering COCO format datasets</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from detectron2.data.datasets import register_coco_instances</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">register_coco_instances(train, {&#x27;thing_classes&#x27;: train_metadata.thing_classes, &#x27;thing_dataset_id_to_contiguous_id&#x27;: train_metadata.thing_dataset_id_to_contiguous_id}, train_json_path, TRAINING_IMAGES_PATH)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">register_coco_instances(valid, {&#x27;thing_classes&#x27;: valid_metadata.thing_classes, &#x27;thing_dataset_id_to_contiguous_id&#x27;: valid_metadata.thing_dataset_id_to_contiguous_id}, valid_json_path, VALID_IMAGES_PATH)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="algorithm">Algorithm<a href="#algorithm" class="hash-link" aria-label="Direct link to Algorithm" title="Direct link to Algorithm">​</a></h2><div align="justify">The Faster Region-based Convolutional Neural Network (R-CNN) model, Faster R-CNN X 101 32x8d FPN 3x, was used for the custom OD model.<p>One model was trained per object per brand using the manually labelled training sets. For detecting faces and smiles, the training set consisted of creatives from all four brands, but each model was developed separately for face and smile per brand. In total there were, thus, 19 custom models. The validation set was used to tune hyperparameters of each model, with accuracy as the main metric. The final models were then used to detect objects in the unlabelled images for all four brands. The training, validation and final detections were all done using a single node GPU (CUDA) on Databricks.</p></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="hyperparameter-tuning">Hyperparameter Tuning<a href="#hyperparameter-tuning" class="hash-link" aria-label="Direct link to Hyperparameter Tuning" title="Direct link to Hyperparameter Tuning">​</a></h2><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="process">Process<a href="#process" class="hash-link" aria-label="Direct link to Process" title="Direct link to Process">​</a></h3><div align="justify">While Detectron2 allows for the customization of many configurations, including learning rate, backbone, image size, and number of images per batch, we limited the scope to just three parameters due to time constraints. These are summarized in Table 1 along with the parameter values tested. The choice of parameters was based on those deemed to be the most influential in performance. In addition to these parameters, the learning rate – the rate at which the algorithm converges to a solution   – was customized.  Rather than using the default value of 0.001, the learning rate was determined by the linear learning rate scaling rule. This was done in order to facilitate training on larger batch sizes.</div><p> </p><div align="center"><p> <img loading="lazy" alt="screenshot-app" src="/assets/images/1-63bf2e1d86f975c672b49017135f6ec8.png" width="1015" height="268" class="img_ev3q"></p><p>Table 1: Parameters Tested in Custom Models</p></div><br><p>Example Code</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">## Parameters values to test</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">parameters = {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &#x27;SOLVER.MAX_ITER&#x27;: [300, 500, 1000],</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    &#x27;ROI_HEADS.BATCH_SIZE_PER_IMAGE&#x27;: [265, 512, 1024]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">## Configuring the algorithmn</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def config_detectron(train_dataset, max_iter, batchsize):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    classes = MetadataCatalog.get(train_dataset).thing_classes</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    num_classes = len(classes)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(f&quot;Number of classes in dataset: {num_classes}&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cfg = get_cfg()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cfg.merge_from_file(model_zoo.get_config_file(&quot;COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml&quot;))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cfg.DATASETS.TRAIN = (train_dataset, )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cfg.DATASETS.TEST = ()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cfg.DATALOADER.NUM_WORKERS = 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(&quot;COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml&quot;) # Let training initialize from model zoo</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cfg.SOLVER.IMS_PER_BATCH = 2 ## # How many images per batch? The original models were trained on 8 GPUs with 16 images per batch, since we have 1 GPUs: 16/8 = 2 (we actually have 2 GPUs but we cannot use both as we do not have enough CUDA memory)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cfg.SOLVER.BASE_LR = 0.00125 # We do the same calculation with the learning rate as the GPUs, the original model used 0.01, so we&#x27;ll divide by 8: 0.01/8 = 0.00125. </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cfg.SOLVER.MAX_ITER = max_iter   # How many iterations are we going for? </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = batchsize</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    print(dbutils.fs.ls(cfg.OUTPUT_DIR))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return cfg</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">### Training</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def train_detectron(config):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    trainer = DefaultTrainer(config)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    trainer.resume_or_load(resume=False)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    trainer.train()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return trainer</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div align="justify">Exhaustive Grid Search was used to determine the combination of Max Iterations and Batch Size that yielded the highest accuracy on the validation set for each model. The results were visualized on a heat map, with confidence thresholds of 20%, 40%, 60%, and 80%. An example is shown in Figure 1. In this example, the model with Max Iteration of 1000 and a Batch Size of 265 performed the best, and the results did not improve beyond a confidence threshold of 40%. Confusion Matrices (see example in Figure 2) were also used to gain insight into the False Positive vs. False Negative rate.</div><p> </p><div align="center"><p> <img loading="lazy" alt="screenshot-app" src="/assets/images/3-59df6df54647bdb3ecb7a9625ce33b5c.png" width="417" height="347" class="img_ev3q"></p><p>Figure 1 : Example Results of Grid Search</p></div><br><div align="center"><p> <img loading="lazy" alt="screenshot-app" src="/assets/images/4_2-cfad45d3ddbbd7a950805c077bd28cb1.png" width="1082" height="373" class="img_ev3q"></p><p>Figure 2 : Example Confusion Matrices for Best Performing Model with 80% Confidence Threshold</p></div><br><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">## Prediction</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def prediction(config, test_dataset, date_string, threshold):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cfg = config</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cfg.MODEL.WEIGHTS = f&#x27;/dbfs/mnt/trd/{brand}/objectdetection/custom_output/GPU/{date_string}/model_final.pth&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = threshold # set the testing threshold for this model</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cfg.DATASETS.TEST = (test_dataset, )</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    predictor = DefaultPredictor(cfg)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return predictor</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def evaluation(config, test_dataset, trainer):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Setup an evaluator, we use COCO because it&#x27;s one of the standards for object detection: https://detectron2.readthedocs.io/modules/evaluation.html#detectron2.evaluation.COCOEvaluator</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    evaluator = COCOEvaluator(dataset_name=test_dataset, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                              cfg=config, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                              distributed=False, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                              output_dir=&quot;./output/&quot;)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Create a dataloader to load in the test data (cmaker-fireplace-valid)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    val_loader = build_detection_test_loader(config, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                                             dataset_name=test_dataset)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Make inference on the validation dataset: https://detectron2.readthedocs.io/tutorials/evaluation.html</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    inference = inference_on_dataset(model=trainer, # get the model from the trainer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                         data_loader=val_loader, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                         evaluator=evaluator)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return inference</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">## Make Predictions</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">def get_predictions(predictor, imagePath):</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Get predictions</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    image = cv2.imread(imagePath)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    predictions = predictor(image)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    instances = predictions[&quot;instances&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    class_indexes = instances.pred_classes</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    prediction_boxes = instances.pred_boxes</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    class_catalog = valid_metadata.thing_classes</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    class_labels = [class_catalog[i] for i in class_indexes] </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    class_scores = instances.scores</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return class_indexes, prediction_boxes, class_labels, class_scores</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="results">Results<a href="#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results">​</a></h3><div align="justify">The best performing model was then used to determine the optimal threshold for each object type, at 1% intervals ranging from 20% to 99%. The threshold yielding the highest accuracy for each object class per model was then selected. The results are summarized in Table 2. Following these results, the best custom-trained model per object per brand was used to detect object in the unlabelled dataset in batches of 200 creatives. This was done in order to limit the CUDA memory and ensure that work was saved along the way should something happen. The total detection time for each brand ranged between 72-168 hours.</div><p> </p><div align="center"><p><img loading="lazy" alt="screenshot-app" src="/assets/images/2-2d2d4dac8274023a1627443f50d359e9.png" width="723" height="460" class="img_ev3q"></p><p>Table 2: Final Custom Models</p></div><br><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="useful-links">Useful links<a href="#useful-links" class="hash-link" aria-label="Direct link to Useful links" title="Direct link to Useful links">​</a></h3><ul><li><a href="https://github.com/facebookresearch/detectron2" target="_blank" rel="noopener noreferrer">Detectron2 - Github</a></li><li><a href="https://detectron2.readthedocs.io/en/latest/index.html" target="_blank" rel="noopener noreferrer">Detectron2 - Documentation</a></li><li><a href="https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md" target="_blank" rel="noopener noreferrer">Detectron2 - ModelZoo</a></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="other-useful-code">Other useful code<a href="#other-useful-code" class="hash-link" aria-label="Direct link to Other useful code" title="Direct link to Other useful code">​</a></h3><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="imports">Imports<a href="#imports" class="hash-link" aria-label="Direct link to Imports" title="Direct link to Imports">​</a></h4><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Install Detectron2 dependencies: https://detectron2.readthedocs.io/tutorials/install.html (use cu100 because colab is on CUDA 10.0)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">!pip install cython pyyaml==5.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">!pip install -U &#x27;git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI&#x27;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">!pip install awscli # you&#x27;ll need this if you want to download images from Open Images (we&#x27;ll see this later)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Make sure we can import PyTorch (what Detectron2 is built with)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import torch, torchvision</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">torch.__version__</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">!gcc --version</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Setup detectron2 logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">import detectron2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from detectron2.utils.logger import setup_logger</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">setup_logger() # this logs Detectron2 information such as what the model is doing when it&#x27;s training# import some common detectron2 utilities</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Other detectron2 imports</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from detectron2.engine import DefaultTrainer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from detectron2.evaluation import COCOEvaluator, inference_on_dataset</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from detectron2.data import build_detection_test_loader</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from detectron2 import model_zoo </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from detectron2.engine import DefaultPredictor </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from detectron2.config import get_cfg</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from detectron2.utils.visualizer import Visualizer </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">from detectron2.data import MetadataCatalog </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="next-article">Next article<a href="#next-article" class="hash-link" aria-label="Direct link to Next article" title="Direct link to Next article">​</a></h2><p>In the next article, we will showcase Tesseract, a open-source optical character recognition (OCR) Engine, and the image-processing methods we developed to raise the baseline performance of this library, from 68% accuracy, by up to 28 percentage points.</p></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/object-detection">Object Detection</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/optical-character-recognition">Optical Character Recognition</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/marketing-mix-modelling">Marketing Mix Modelling</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/deep-learning">Deep Learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/tesseract">Tesseract</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/2022/12/13/creative_execution_and_marketing_effectiveness_part_III"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Exploring the links between creative execution and marketing effectiveness - Part III: Tesseract Pre-Trained Optical Character Recognition Models</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/2022/11/10/creative_execution_and_marketing_effectiveness_part_I"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Exploring the links between creative execution and marketing effectiveness - Part I: Detectron2 Pre-Trained Object Detection Models</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#why-you-should-read-this" class="table-of-contents__link toc-highlight">Why you should read this</a></li><li><a href="#dataset" class="table-of-contents__link toc-highlight">Dataset</a></li><li><a href="#algorithm" class="table-of-contents__link toc-highlight">Algorithm</a></li><li><a href="#hyperparameter-tuning" class="table-of-contents__link toc-highlight">Hyperparameter Tuning</a><ul><li><a href="#process" class="table-of-contents__link toc-highlight">Process</a></li><li><a href="#results" class="table-of-contents__link toc-highlight">Results</a></li><li><a href="#useful-links" class="table-of-contents__link toc-highlight">Useful links</a></li><li><a href="#other-useful-code" class="table-of-contents__link toc-highlight">Other useful code</a></li></ul></li><li><a href="#next-article" class="table-of-contents__link toc-highlight">Next article</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">About us</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://ekimetrics.com/who-we-are/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Who we are ?</a></li><li class="footer__item"><a href="https://ekimetrics.com/our-team/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Our team</a></li><li class="footer__item"><a href="https://ekimetrics.us13.list-manage.com/subscribe?u=85b8ce42caa0a733e98233bc4&amp;id=6355d0a6f9" target="_blank" rel="noopener noreferrer" class="footer__link-item">Subscribe to our newsletter</a></li></ul></div><div class="col footer__col"><div class="footer__title">Find us</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/ekimetrics" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://ekimetrics.com/careers/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Careers<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.welcometothejungle.com/fr/companies/ekimetrics" target="_blank" rel="noopener noreferrer" class="footer__link-item">Eki on Welcome to the jungle<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Contact</div><ul class="footer__items clean-list"><li class="footer__item"><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Get in touch with our teams<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div></div></footer></div>
<script src="/assets/js/runtime~main.04f2449c.js"></script>
<script src="/assets/js/main.1dd7753c.js"></script>
</body>
</html>